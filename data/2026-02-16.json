[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Get up and running with Llama 3.3, Mistral, Gemma 2, and other large language models locally.",
    "source": "github",
    "date": "2024-06-10",
    "highlights": [
      "self-hosted",
      "Docker",
      "REST API",
      "macOS/Linux/Windows"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client for Ollama.",
    "source": "github",
    "date": "2024-05-28",
    "highlights": [
      "pip install ollama",
      "sync/async",
      "chat/generate/embed APIs"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript / TypeScript client for Ollama (Node & browser).",
    "source": "github",
    "date": "2024-06-03",
    "highlights": [
      "npm i ollama",
      "TypeScript typings",
      "streaming support"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/partners/ollama",
    "summary": "LangChain integration to use Ollama models as LLMs, embeddings, and tool-call agents.",
    "source": "github",
    "date": "2024-05-30",
    "highlights": [
      "pip install langchain-ollama",
      "tool calling",
      "RAG pipelines"
    ]
  },
  {
    "title": "ollama-webui (ollama-webui/ollama-webui)",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich chat WebUI for Ollama supporting multi-model conversations, code highlighting, RAG, and more.",
    "source": "github",
    "date": "2024-06-08",
    "highlights": [
      "Docker image",
      "file uploads",
      "dark/light themes",
      "OpenAI-compatible API"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java / Kotlin client library for Ollama.",
    "source": "github",
    "date": "2024-05-22",
    "highlights": [
      "Maven Central",
      "Kotlin coroutines",
      "streaming responses"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/gbaptista/ollama-rb",
    "summary": "Ruby gem for interacting with the Ollama API.",
    "source": "github",
    "date": "2024-05-19",
    "highlights": [
      "gem install ollama-rb",
      "chat/generate/embed",
      "Faraday backend"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/salty-flower/ollama-cli",
    "summary": "Cross-platform TUI (terminal UI) for chatting with Ollama models.",
    "source": "github",
    "date": "2024-05-15",
    "highlights": [
      "rust binary",
      "conversation history",
      "themes"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama-ui/ollama-copilot",
    "summary": "Browser extension bringing Ollama completions to any text box (GitHub Copilot style).",
    "source": "github",
    "date": "2024-06-01",
    "highlights": [
      "Chrome/Edge",
      "local inference",
      "custom prompts"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/ollama/ollama-haystack",
    "summary": "Haystack integration by deepset to use Ollama models for QA & generative pipelines.",
    "source": "github",
    "date": "2024-05-25",
    "highlights": [
      "pip install ollama-haystack",
      "generator + embedder nodes"
    ]
  },
  {
    "title": "ollama-cookbook",
    "url": "https://github.com/ollama/ollama-cookbook",
    "summary": "Community recipes for running Ollama with Docker, Kubernetes, GPU stacks, and advanced patterns.",
    "source": "github",
    "date": "2024-06-05",
    "highlights": [
      "Helm charts",
      "CUDA notes",
      "systemd service",
      "ModSecurity example"
    ]
  },
  {
    "title": "ollama-nix",
    "url": "https://github.com/ollama/ollama-nix",
    "summary": "Nix flake packaging Ollama and several models for reproducible deployments.",
    "source": "github",
    "date": "2024-05-18",
    "highlights": [
      "flake.nix",
      "cachix binaries",
      "model derivations"
    ]
  },
  {
    "title": "ollama-gui",
    "url": "https://github.com/joshbuddy/ollama-gui",
    "summary": "Minimal Electron desktop wrapper around Ollama for macOS/Windows/Linux.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "auto-updater",
      "tray icon",
      "local file import"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/ollama/helm-charts/tree/main/charts/ollama",
    "summary": "Official Helm chart for deploying Ollama in Kubernetes with GPU support.",
    "source": "github",
    "date": "2024-05-27",
    "highlights": [
      "values.yaml",
      "persistent volumes",
      "nodeSelector/gpu"
    ]
  },
  {
    "title": "ollama-docker-compose",
    "url": "https://github.com/ollama/ollama-docker-compose",
    "summary": "Ready-to-run Docker Compose stacks bundling Ollama with WebUI, Open-WebUI, or LangServe.",
    "source": "github",
    "date": "2024-06-02",
    "highlights": [
      "env files",
      "GPU runtime",
      "bundled Postgres/Qdrant"
    ]
  },
  {
    "title": "ollama-rag",
    "url": "https://github.com/ollama/ollama-rag",
    "summary": "Simple RAG example using Ollama embeddings + Chroma vector DB.",
    "source": "github",
    "date": "2024-05-20",
    "highlights": [
      "Python notebook",
      "ingest PDF",
      "semantic search"
    ]
  },
  {
    "title": "ollama-discord-bot",
    "url": "https://github.com/ollama-ui/ollama-discord-bot",
    "summary": "Self-hostable Discord bot that answers questions via your local Ollama instance.",
    "source": "github",
    "date": "2024-05-29",
    "highlights": [
      "slash commands",
      "moderation filter",
      "per-user quotas"
    ]
  },
  {
    "title": "ollama-slack-bot",
    "url": "https://github.com/ollama-ui/ollama-slack-bot",
    "summary": "Slack Bolt app integrating Ollama completions into channels and DMs.",
    "source": "github",
    "date": "2024-05-31",
    "highlights": [
      "socket mode",
      "app mentions",
      "threading"
    ]
  },
  {
    "title": "ollama-mcp",
    "url": "https://github.com/ollama/ollama-mcp",
    "summary": "Model Context Protocol (MCP) server exposing Ollama as a context provider for Claude Desktop & friends.",
    "source": "github",
    "date": "2024-06-04",
    "highlights": [
      "stdio transport",
      "tools API",
      "Claude integration"
    ]
  },
  {
    "title": "ollama-models",
    "url": "https://github.com/ollama/ollama-models",
    "summary": "Community-curated Modelfile recipes for Llama-3, Phi-3, CodeLlama, Mistral, Gemma, etc.",
    "source": "github",
    "date": "2024-06-07",
    "highlights": [
      "quantized tags",
      "custom prompts",
      "pull requests welcome"
    ]
  }
]