[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Get up and running with Llama 3, Mistral, Gemma 2, and other large language models locally.",
    "source": "github",
    "date": "2024-06-10",
    "highlights": [
      "self-hosted LLM runner",
      "macOS/Linux/Windows",
      "Docker images",
      "REST & CLI APIs"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client for Ollama. Chat with local models in a few lines of code.",
    "source": "github",
    "date": "2024-06-05",
    "highlights": [
      "pip install ollama",
      "sync/async APIs",
      "streaming support",
      "embeddings endpoint"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript / TypeScript client for Ollama. Works in Node and browsers.",
    "source": "github",
    "date": "2024-06-07",
    "highlights": [
      "npm i ollama",
      "Promise-based",
      "TypeScript defs",
      "chat & generate helpers"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/partners/ollama",
    "summary": "LangChain integration to use any Ollama model as an LLM or embeddings provider.",
    "source": "github",
    "date": "2024-06-08",
    "highlights": [
      "pip install langchain-ollama",
      "LLM & Embeddings classes",
      "tool calling beta"
    ]
  },
  {
    "title": "ollama-webui (Ollama-WebUI)",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich web interface for Ollama (now renamed Open WebUI). ChatGPT-style UI, file uploads, RAG, admin panel.",
    "source": "github",
    "date": "2024-06-09",
    "highlights": [
      "Docker image",
      "multi-user",
      "RAG with uploaded docs",
      "light/dark themes"
    ]
  },
  {
    "title": "ollama4j \u2013 Java Client",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Unofficial Java/Kotlin client for Ollama with builder-style fluent API.",
    "source": "github",
    "date": "2024-06-04",
    "highlights": [
      "Maven Central",
      "async & sync",
      "streaming chat",
      "Kotlin extensions"
    ]
  },
  {
    "title": "ollama-cli (rich TUI)",
    "url": "https://github.com/saltyorg/ollama-cli",
    "summary": "Terminal dashboard for Ollama with model browsing, chat history and markdown rendering.",
    "source": "github",
    "date": "2024-06-03",
    "highlights": [
      "rich text UI",
      "interactive model picker",
      "chat logs",
      "keyboard shortcuts"
    ]
  },
  {
    "title": "ollama-copilot.nvim",
    "url": "https://github.com/yetone/ollama-copilot.nvim",
    "summary": "Neovim plugin bringing local Ollama models as inline Copilot-style code suggestions.",
    "source": "github",
    "date": "2024-06-06",
    "highlights": [
      "inline completion",
      "configurable shortcuts",
      "uses Ollama generate API"
    ]
  },
  {
    "title": "ollama-rag",
    "url": "https://github.com/ivanfioravivi/ollama-rag",
    "summary": "Minimal RAG template using Ollama embeddings + Chroma vector DB + Streamlit UI.",
    "source": "github",
    "date": "2024-06-02",
    "highlights": [
      "PDF ingestion",
      "Chroma DB",
      "Streamlit chat",
      "one-command docker"
    ]
  },
  {
    "title": "Ollama Reddit Community",
    "url": "https://www.reddit.com/r/ollama/",
    "summary": "Active subreddit for model recommendations, troubleshooting and ecosystem showcase.",
    "source": "reddit",
    "date": "2024-06-10",
    "highlights": [
      "model release posts",
      "GPU tuning",
      "integration showcases",
      "weekly Q&A"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/deepset-ai/haystack-integrations/tree/main/integrations/ollama",
    "summary": "Haystack integration to use Ollama models as generators or embedders in pipelines.",
    "source": "github",
    "date": "2024-06-05",
    "highlights": [
      "pip install farm-haystack[ollama]",
      "pipeline nodes",
      "embeddings support"
    ]
  },
  {
    "title": "ollama-camunda-worker",
    "url": "https://github.com/camunda-community-hub/ollama-camunda-worker",
    "summary": "Camunda 8 job worker that executes service tasks using local Ollama models.",
    "source": "github",
    "date": "2024-06-01",
    "highlights": [
      "Zeebe client",
      "BPMN injection",
      "configurable model/prompt",
      "Docker ready"
    ]
  },
  {
    "title": "ollama-nim-client",
    "url": "https://github.com/canarddu38/ollama-nim",
    "summary": "Unofficial Nim language client for Ollama REST API with async support.",
    "source": "github",
    "date": "2024-05-30",
    "highlights": [
      "Nimble package",
      "async/await",
      "streaming chat",
      "generate & embed"
    ]
  },
  {
    "title": "ollama-rust",
    "url": "https://github.com/pepperoni21/ollama-rust",
    "summary": "Community Rust crate wrapping Ollama REST endpoints with Tokio async client.",
    "source": "github",
    "date": "2024-06-07",
    "highlights": [
      "crates.io",
      "async client",
      "chat streaming",
      "embeddings"
    ]
  },
  {
    "title": "ollama-csharp",
    "url": "https://github.com/awaescher/Ollama",
    "summary": ".NET 8 community SDK for Ollama with strongly-typed request/response models.",
    "source": "github",
    "date": "2024-06-04",
    "highlights": [
      "NuGet package",
      "Dependency injection friendly",
      "streaming support"
    ]
  }
]