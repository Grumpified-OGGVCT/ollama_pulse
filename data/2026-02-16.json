[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo \u2013 CLI and Go library to pull, run, and expose GGUF models as a local OpenAI-compatible API server.",
    "source": "github",
    "date": "2024-06-10",
    "highlights": [
      "self-contained binary",
      "OpenAI-compatible /chat & /embed endpoints",
      "model registry with 70+ GGUFs"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "First-party async/sync Python client for the Ollama API; installable via PyPI.",
    "source": "github",
    "date": "2024-06-07",
    "highlights": [
      "pip install ollama",
      "streaming & JSON mode",
      "built-in embeddings helper"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Node & browsers; published on npm.",
    "source": "github",
    "date": "2024-06-05",
    "highlights": [
      "npm i ollama",
      "TypeScript definitions",
      "browser-compatible fetch"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/partners/ollama",
    "summary": "LangChain adapter giving Ollama models Chat, LLM, and Embeddings interfaces.",
    "source": "github",
    "date": "2024-06-09",
    "highlights": [
      "pip install langchain-ollama",
      "drop-in replacement for OpenAI in chains",
      "native async"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Full-featured ChatGPT-style web UI for any Ollama model; runs in Docker.",
    "source": "github",
    "date": "2024-06-08",
    "highlights": [
      "markdown & code highlighting",
      "multi-user auth",
      "RAG via uploaded docs"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java/Kotlin client for Ollama with Android support; available on Maven Central.",
    "source": "github",
    "date": "2024-06-04",
    "highlights": [
      "Java 8+ compatible",
      "Android example app",
      "reactive streaming"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/ollama/ollama-rb",
    "summary": "Community-maintained Ruby gem wrapping the Ollama REST API.",
    "source": "github",
    "date": "2024-06-03",
    "highlights": [
      "bundle add ollama",
      "Rack-style middleware",
      "Rails demo"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/saltyorg/ollama-cli",
    "summary": "Rust-based interactive CLI with syntax highlighting and conversation history.",
    "source": "github",
    "date": "2024-06-02",
    "highlights": [
      "cross-platform binary",
      "readline-style repl",
      "context window indicator"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama-copilot/ollama-copilot",
    "summary": "VS Code extension that routes GitHub Copilot calls to a local Ollama model.",
    "source": "github",
    "date": "2024-06-06",
    "highlights": [
      "transparent proxy",
      "supports Code Llama",
      "zero config after install"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/deepset-ai/haystack-integrations/tree/main/integrations/ollama",
    "summary": "Haystack integration providing OllamaGenerator and OllamaEmbedder nodes.",
    "source": "github",
    "date": "2024-06-05",
    "highlights": [
      "pip install ollama-haystack",
      "RAG pipelines",
      "compatible with Haystack 2.0"
    ]
  },
  {
    "title": "ollama-cookbook",
    "url": "https://github.com/ollama/ollama-cookbook",
    "summary": "Community recipes for running Ollama on edge devices, Kubernetes, and more.",
    "source": "github",
    "date": "2024-06-09",
    "highlights": [
      "Jetson Nano guide",
      "Helm chart",
      "Function-calling example"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/otwld/ollama-helm",
    "summary": "Production-ready Helm chart for deploying Ollama on Kubernetes with GPU support.",
    "source": "github",
    "date": "2024-06-07",
    "highlights": [
      "autoscaling HPA",
      "PVC model cache",
      "Prometheus metrics"
    ]
  },
  {
    "title": "ollama-docker",
    "url": "https://github.com/ollama/ollama/tree/main/docker",
    "summary": "Official container images (CPU & CUDA) published to Docker Hub.",
    "source": "github",
    "date": "2024-06-10",
    "highlights": [
      "multi-arch",
      "rootless",
      "CUDA 12 image"
    ]
  },
  {
    "title": "ollama-gpt4all",
    "url": "https://github.com/nomic-ai/gpt4all/tree/main/gpt4all-backend/ollama",
    "summary": "GPT4All UI can now boot Ollama as its local backend instead of llmodel.",
    "source": "github",
    "date": "2024-06-04",
    "highlights": [
      "unified GUI",
      "model gallery",
      "offline installer"
    ]
  },
  {
    "title": "ollama-discord-bot",
    "url": "https://github.com/ollama-discord/ollama-discord-bot",
    "summary": "Self-hostable Discord bot that brings any Ollama model into a server slash-command.",
    "source": "github",
    "date": "2024-06-03",
    "highlights": [
      "threaded conversations",
      "mod tools",
      "role-based model access"
    ]
  },
  {
    "title": "ollama-node",
    "url": "https://www.npmjs.com/package/ollama-node",
    "summary": "Zero-dependency Node.js wrapper around the Ollama REST API (community package).",
    "source": "github",
    "date": "2024-06-06",
    "highlights": [
      "TypeScript first",
      "ESM & CommonJS",
      "auto-retry"
    ]
  },
  {
    "title": "ollama-mcp",
    "url": "https://github.com/ollama-mcp/ollama-mcp",
    "summary": "Model Context Protocol server exposing Ollama functions to AI agents.",
    "source": "github",
    "date": "2024-06-08",
    "highlights": [
      "OpenAI functions compatible",
      "auto tool discovery",
      "Docker image"
    ]
  },
  {
    "title": "ollama-obsidian",
    "url": "https://github.com/hinterdup/ollama-obsidian",
    "summary": "Obsidian plugin that adds a \u201cAsk Ollama\u201d command to summarize or rewrite notes locally.",
    "source": "github",
    "date": "2024-06-05",
    "highlights": [
      "offline vault processing",
      "custom prompts in frontmatter",
      "streaming into pane"
    ]
  }
]