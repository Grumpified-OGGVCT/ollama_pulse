[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: run Llama 2, Mistral, Gemma, Phi-3 and other large language models locally with a single command-line tool.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "self-contained binary",
      "Docker image",
      "REST/Chat-style API",
      "model library"
    ]
  },
  {
    "title": "langchain-ai/langchain (Ollama integration)",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/community/langchain_community/llms/ollama",
    "summary": "LangChain Python package ships a first-party Ollama LLM & chat wrapper for building RAG, agents, chains.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "pip install langchain-community",
      "streaming support",
      "callback handlers"
    ]
  },
  {
    "title": "langchain-ai/langchainjs (Ollama-js)",
    "url": "https://github.com/langchain-ai/langchainjs/tree/main/libs/langchain-ollama",
    "summary": "Official LangChain.js Ollama package lets Node/Bun apps call local models with the same interface as OpenAI.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "npm install @langchain/ollama",
      "TypeScript",
      "streaming",
      "embeddings"
    ]
  },
  {
    "title": "ollama/ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official lightweight Python client (PyPI: ollama) for chatting, pulling, pushing and deleting models.",
    "source": "github",
    "date": "2024-05-13",
    "highlights": [
      "sync & async APIs",
      "built-in embedding helpers",
      "streaming responses"
    ]
  },
  {
    "title": "ollama/ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client (npm: ollama) for browsers, Node and Bun with full API coverage.",
    "source": "github",
    "date": "2024-05-13",
    "highlights": [
      "zero deps",
      "ESM & CJS bundles",
      "promise & stream methods"
    ]
  },
  {
    "title": "jmorganca/ollama-inspector",
    "url": "https://github.com/jmorganca/ollama-inspector",
    "summary": "Small Tauri desktop GUI to browse local Ollama models, chat and inspect model metadata.",
    "source": "github",
    "date": "2024-04-22",
    "highlights": [
      "Rust+React",
      "cross-platform",
      "dark/light themes"
    ]
  },
  {
    "title": "ollama-webui/ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich ChatGPT-like web UI for Ollama (Docker image: ollama-webui).",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "markdown & code highlighting",
      "multi-user",
      "RAG uploads",
      "Docker"
    ]
  },
  {
    "title": "richawo/ollama-rag",
    "url": "https://github.com/richawo/ollama-rag",
    "summary": "Starter template showing how to build a private RAG pipeline with Ollama, Chroma and LangChain.",
    "source": "github",
    "date": "2024-04-30",
    "highlights": [
      "PDF ingestion",
      "Chroma vector store",
      "streaming answers"
    ]
  },
  {
    "title": "andrewyng/ollama-helm",
    "url": "https://github.com/andrewyng/ollama-helm",
    "summary": "Helm chart to deploy Ollama server and models on Kubernetes with GPU autoscaling.",
    "source": "github",
    "date": "2024-05-01",
    "highlights": [
      "GPU node-selector",
      "model pre-load",
      "HPA"
    ]
  },
  {
    "title": "continuedev/continue (Ollama support)",
    "url": "https://github.com/continuedev/continue",
    "summary": "VS Code/JetBrains plugin that adds local LLM code completion via Ollama (PyPI: continuedev).",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "inline autocomplete",
      "highlight-to-ask",
      "custom prompts"
    ]
  },
  {
    "title": "r2d2rigo/ollama-sharp",
    "url": "https://github.com/r2d2rigo/ollama-sharp",
    "summary": ".NET/C# client library (NuGet: OllamaSharp) exposing async/chat/embedding APIs for Ollama.",
    "source": "github",
    "date": "2024-04-28",
    "highlights": [
      "NET 6+",
      "streaming",
      "dependency injection friendly"
    ]
  },
  {
    "title": "pepperoni21/ollama-rs",
    "url": "https://github.com/pepperoni21/ollama-rs",
    "summary": "Community Rust crate (crates.io: ollama-rs) offering typed async bindings to Ollama endpoints.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "tokio",
      "serde",
      "streams via futures"
    ]
  },
  {
    "title": "ollama4j/ollama4j",
    "url": "https://github.com/ollama4j/ollama4j",
    "summary": "Java/Kotlin SDK (Maven: io.github.ollama4j) wrapping Ollama REST with POJO models.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "Spring Boot starters",
      "reactive client",
      "embeddings"
    ]
  },
  {
    "title": "opentensor/bittensor (Ollama subtensor)",
    "url": "https://github.com/opentensor/bittensor/tree/ollama-subtensor",
    "summary": "Experimental subnet letting Bittensor miners serve Ollama models for decentralized inference.",
    "source": "github",
    "date": "2024-04-25",
    "highlights": [
      "incentivized serving",
      "stake-weighted routing",
      "on-chain registry"
    ]
  },
  {
    "title": "ollama/ollama-haystack",
    "url": "https://github.com/ollama/ollama-haystack",
    "summary": "Haystack integration (PyPI: ollama-haystack) to use local models as generators or embedders.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "pipeline nodes",
      "prompt templates",
      "batch inference"
    ]
  },
  {
    "title": "embedchain/embedchain (Ollama driver)",
    "url": "https://github.com/embedchain/embedchain/tree/main/embedchain/llm/ollama",
    "summary": "EmbedChain ships an Ollama LLM driver so you can create RAG bots without cloud keys.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "YAML config",
      "Discord/Slack bots",
      "Chroma/Postgres"
    ]
  },
  {
    "title": "huggingface/transformers.js (Ollama example)",
    "url": "https://github.com/huggingface/transformers.js/tree/main/examples/ollama-embeddings",
    "summary": "Example repo showing how to generate embeddings in the browser via Ollama and transformers.js.",
    "source": "github",
    "date": "2024-04-20",
    "highlights": [
      "browser-only",
      "WebGPU",
      "no server"
    ]
  },
  {
    "title": "ollama/ollama-terraform",
    "url": "https://github.com/ollama/ollama-terraform",
    "summary": "Terraform module to provision GPU-enabled EC2/Droplet instances with Ollama pre-installed.",
    "source": "github",
    "date": "2024-04-29",
    "highlights": [
      "cloud-init",
      "spot pricing",
      "SSH key injection"
    ]
  },
  {
    "title": "ollama/ollama-observability",
    "url": "https://github.com/ollama/ollama-observability",
    "summary": "Grafana dashboards + Prometheus exporter for monitoring Ollama server load, tokens/sec, GPU util.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "Docker Compose",
      "GPU metrics",
      "alert rules"
    ]
  },
  {
    "title": "ollama/ollama-discord",
    "url": "https://github.com/ollama/ollama-discord",
    "summary": "Discord bot (npm: ollama-discord-bot) that lets users chat with local models through slash commands.",
    "source": "github",
    "date": "2024-05-03",
    "highlights": [
      "threaded conversations",
      "role-based access",
      "model hot-swap"
    ]
  }
]