[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repository: get up and running with Llama 3.3, Phi-3, Mistral, Gemma 2, and other large language models locally.",
    "source": "github",
    "date": "2024-05-20",
    "highlights": [
      "self-hosted LLM inference",
      "Docker & CLI",
      "model library",
      "macOS/Linux/Windows"
    ]
  },
  {
    "title": "ollama/ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Ollama.",
    "source": "github",
    "date": "2024-05-15",
    "highlights": [
      "npm package",
      "Promise-based API",
      "chat & embed endpoints",
      "TypeScript types"
    ]
  },
  {
    "title": "ollama/ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client and library for Ollama.",
    "source": "github",
    "date": "2024-05-18",
    "highlights": [
      "PyPI package",
      "sync/async APIs",
      "chat/embed/generate",
      "streaming support"
    ]
  },
  {
    "title": "langchain-ai/langchain/ollama",
    "url": "https://python.langchain.com/docs/integrations/llms/ollama",
    "summary": "LangChain integration for Ollama models enabling chains, agents and retrieval.",
    "source": "blog",
    "date": "2024-04-10",
    "highlights": [
      "LangChain LLM interface",
      "chat models",
      "embeddings",
      "tool calling"
    ]
  },
  {
    "title": "jmorganca/ollama-webui (now Open WebUI)",
    "url": "https://github.com/open-webui/open-webui",
    "summary": "Feature-rich web interface for Ollama with chat UI, RAG, and admin controls.",
    "source": "github",
    "date": "2024-05-22",
    "highlights": [
      "self-hosted UI",
      "document upload/RAG",
      "user management",
      "dark theme"
    ]
  },
  {
    "title": "ollama-webui/ollama-webui-lite",
    "url": "https://github.com/ollama-webui/ollama-webui-lite",
    "summary": "Lightweight React frontend for chatting with Ollama models.",
    "source": "github",
    "date": "2024-03-12",
    "highlights": [
      "React SPA",
      "responsive",
      "easy Docker deploy",
      "chat history"
    ]
  },
  {
    "title": "sglang/ollama-sglang-bridge",
    "url": "https://github.com/sgl-project/sglang/tree/main/ollama",
    "summary": "Bridge to run SGLang programs on Ollama backends for structured generation.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "structured outputs",
      "JSON schema",
      "regex constraints",
      "batching"
    ]
  },
  {
    "title": "embedding/ollama-embeddings",
    "url": "https://github.com/ollama/ollama-embeddings",
    "summary": "Community repo showcasing embedding workflows with Ollama models.",
    "source": "github",
    "date": "2024-04-28",
    "highlights": [
      "sentence-transformers",
      "vector DB examples",
      "RAG snippets"
    ]
  },
  {
    "title": "ollama-nix",
    "url": "https://github.com/ollama-nix/ollama-nix",
    "summary": "Nix flake packaging Ollama and its models for reproducible deployments.",
    "source": "github",
    "date": "2024-05-01",
    "highlights": [
      "Nix flake",
      "declarative models",
      "systemd service",
      "cache"
    ]
  },
  {
    "title": "ollama-rust",
    "url": "https://github.com/ollama-rs/ollama-rs",
    "summary": "Rust client crate for Ollama with async/tokio support.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "async Rust",
      "crates.io",
      "chat/generate/embed",
      "SSE streaming"
    ]
  },
  {
    "title": "ollama-cli-chat",
    "url": "https://github.com/thinkall/ollama-cli-chat",
    "summary": "Interactive CLI chat wrapper with conversation memory and syntax highlighting.",
    "source": "github",
    "date": "2024-04-15",
    "highlights": [
      "rich terminal UI",
      "conversation save/load",
      "markdown",
      "keybindings"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/fostermaier/ollama-copilot",
    "summary": "VS Code extension bringing local Ollama models as GitHub Copilot replacement.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "VS Code extension",
      "inline suggestions",
      "custom prompts",
      "local only"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/otwld/ollama-helm",
    "summary": "Helm chart to deploy Ollama on Kubernetes with GPU and autoscaling support.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "Kubernetes Helm",
      "GPU nodes",
      "HPA",
      "PVC for models"
    ]
  },
  {
    "title": "ollama-dify",
    "url": "https://github.com/langgenius/dify/tree/main/integrations/ollama",
    "summary": "Dify integration enabling no-code LLM apps backed by Ollama.",
    "source": "github",
    "date": "2024-05-19",
    "highlights": [
      "Dify plugin",
      "prompt IDE",
      "RAG pipeline",
      "agent orchestration"
    ]
  },
  {
    "title": "ollama-rag-chatbot",
    "url": "https://github.com/peterw/ollama-rag-chatbot",
    "summary": "Streamlit chatbot template with PDF ingestion and local Ollama embeddings.",
    "source": "github",
    "date": "2024-04-22",
    "highlights": [
      "Streamlit UI",
      "PDF loader",
      "Chroma vector DB",
      "streaming answers"
    ]
  },
  {
    "title": "reddit/r/ollama",
    "url": "https://www.reddit.com/r/ollama/",
    "summary": "Active subreddit for sharing models, tips, and troubleshooting Ollama.",
    "source": "reddit",
    "date": "2024-05-21",
    "highlights": [
      "community support",
      "model recommendations",
      "feature requests"
    ]
  },
  {
    "title": "Hacker News: Ollama 0.1.34 release",
    "url": "https://news.ycombinator.com/item?id=40473891",
    "summary": "Discussion thread covering new features like tool use and vision models.",
    "source": "hackernews",
    "date": "2024-05-17",
    "highlights": [
      "tool calling",
      "vision support",
      "performance notes",
      "comparisons"
    ]
  },
  {
    "title": "ollama-npm",
    "url": "https://www.npmjs.com/package/ollama",
    "summary": "Official npm package providing JavaScript bindings for Ollama.",
    "source": "npm",
    "date": "2024-05-15",
    "highlights": [
      "npm install ollama",
      "ESM/CommonJS",
      "typedoc",
      "100% API coverage"
    ]
  },
  {
    "title": "ollama-pypi",
    "url": "https://pypi.org/project/ollama/",
    "summary": "Official PyPI package for Python integration with Ollama.",
    "source": "pypi",
    "date": "2024-05-18",
    "highlights": [
      "pip install ollama",
      "PEP-561 types",
      "asyncio support",
      "examples"
    ]
  },
  {
    "title": "ollama-vscode",
    "url": "https://github.com/lf-/ollama-vscode",
    "summary": "Lightweight VS Code extension to run and chat with Ollama inside the editor.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "sidebar chat",
      "status bar indicator",
      "configurable model",
      "no telemetry"
    ]
  }
]