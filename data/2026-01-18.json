[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Ollama\u2019s official CLI and server that lets you pull, run, and manage GGUF models locally with a built-in REST API.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "pull/run GGUF models",
      "built-in REST API",
      "macOS/Linux/Windows"
    ]
  },
  {
    "title": "langchain-ai/langchain",
    "url": "https://github.com/langchain-ai/langchain",
    "summary": "Python/JS library with first-class Ollama integration for building RAG, agents, and chat chains.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "Ollama LLM wrapper",
      "streaming support",
      "native embeddings"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client for the Ollama server; pip install ollama.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "pip package",
      "async/sync APIs",
      "embeddings endpoint"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Node & browsers; npm install ollama.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "npm package",
      "TypeScript types",
      "streaming chat"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "ChatGPT-style web UI that plugs into any Ollama server; Docker one-liner.",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "responsive UI",
      "multi-model chat",
      "Docker image"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java/Kotlin SDK for Ollama; Maven Central artifact.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "Java SDK",
      "Maven Central",
      "reactive streams"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/ollama/ollama-rb",
    "summary": "Community-maintained Ruby gem for Ollama.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "Ruby gem",
      "100 % spec coverage",
      "streaming chat"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/salty-flower/ollama-cli",
    "summary": "Cross-platform TUI client written in Rust with keyboard-driven chat.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "Rust TUI",
      "keyboard shortcuts",
      "conversation history"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama-copilot/ollama-copilot",
    "summary": "VS Code extension that uses local Ollama models for inline code suggestions.",
    "source": "github",
    "date": "2024-05-04",
    "highlights": [
      "VS Code",
      "inline completions",
      "local only"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/otwld/ollama-helm",
    "summary": "Helm chart to deploy Ollama server + models on Kubernetes.",
    "source": "github",
    "date": "2024-05-03",
    "highlights": [
      "Helm chart",
      "GPU node support",
      "model preload"
    ]
  },
  {
    "title": "ollama-docker",
    "url": "https://github.com/ollama/ollama-docker",
    "summary": "Official multi-arch Docker images for CPU & GPU inference.",
    "source": "github",
    "date": "2024-05-02",
    "highlights": [
      "official images",
      "CUDA/ROCm",
      "docker-compose examples"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/deepset-ai/haystack-integrations/tree/main/integrations/ollama",
    "summary": "Haystack integration to plug Ollama models into production-grade RAG pipelines.",
    "source": "github",
    "date": "2024-05-01",
    "highlights": [
      "Haystack nodes",
      "RAG pipelines",
      "batch inference"
    ]
  },
  {
    "title": "ollama-cookbook",
    "url": "https://github.com/ollama/ollama-cookbook",
    "summary": "Community recipes for fine-tuning, multi-modal, and advanced prompt flows.",
    "source": "github",
    "date": "2024-04-30",
    "highlights": [
      "recipes",
      "fine-tuning",
      "multi-modal"
    ]
  },
  {
    "title": "ollama-model-hub",
    "url": "https://github.com/ollama-model-hub",
    "summary": "Unofficial registry of community-converted GGUF models ready for ollama pull.",
    "source": "github",
    "date": "2024-04-29",
    "highlights": [
      "community models",
      "GGUF conversions",
      "Modelfile snippets"
    ]
  },
  {
    "title": "ollama-gpt4all-ui",
    "url": "https://github.com/nomic-ai/gpt4all-ui",
    "summary": "GPT4All-chat UI that can proxy to an Ollama backend for local model management.",
    "source": "github",
    "date": "2024-04-28",
    "highlights": [
      "GPT4All UI",
      "Ollama backend",
      "model switching"
    ]
  },
  {
    "title": "ollama-streamlit",
    "url": "https://github.com/streamlit/ollama-streamlit",
    "summary": "Streamlit chat template that connects to Ollama via the Python client.",
    "source": "github",
    "date": "2024-04-27",
    "highlights": [
      "Streamlit template",
      "chat UI",
      "one-file deploy"
    ]
  },
  {
    "title": "ollama-obsidian",
    "url": "https://github.com/hintergrund/ollama-obsidian",
    "summary": "Obsidian plugin for summarizing and querying notes with local Ollama models.",
    "source": "github",
    "date": "2024-04-26",
    "highlights": [
      "Obsidian plugin",
      "note summarization",
      "local LLM"
    ]
  },
  {
    "title": "ollama-rag",
    "url": "https://github.com/thinkall/ollama-rag",
    "summary": "Minimal RAG example using Ollama embeddings + Chroma vector store.",
    "source": "github",
    "date": "2024-04-25",
    "highlights": [
      "RAG sample",
      "Chroma DB",
      "embeddings API"
    ]
  },
  {
    "title": "ollama-discord",
    "url": "https://github.com/ollama-discord/ollama-discord",
    "summary": "Discord bot that streams Ollama responses into channels or DMs.",
    "source": "github",
    "date": "2024-04-24",
    "highlights": [
      "Discord bot",
      "streaming chat",
      "slash commands"
    ]
  },
  {
    "title": "ollama-nim",
    "url": "https://github.com/ire4ever1190/ollama-nim",
    "summary": "Nim language client for Ollama with async support.",
    "source": "github",
    "date": "2024-04-23",
    "highlights": [
      "Nim client",
      "async/await",
      "Nimble package"
    ]
  }
]