[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: get up and running with Llama 3, Mistral, Gemma and other large language models locally.",
    "source": "github",
    "date": "2024-06-01",
    "highlights": [
      "self-hosted LLM runner",
      "macOS/Linux/Windows",
      "Docker images",
      "REST & CLI APIs"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python library for integrating Ollama models into Python apps.",
    "source": "github",
    "date": "2024-05-28",
    "highlights": [
      "pip install ollama",
      "sync/async clients",
      "chat & embed endpoints"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Ollama.",
    "source": "github",
    "date": "2024-05-25",
    "highlights": [
      "npm i ollama",
      "browser & node",
      "Promise-based API"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://pypi.org/project/langchain-ollama/",
    "summary": "PyPI package adding Ollama LLM & embeddings support to LangChain.",
    "source": "github",
    "date": "2024-05-22",
    "highlights": [
      "pip install langchain-ollama",
      "LLM & Embeddings classes",
      "streaming support"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich web UI for chatting with Ollama models (formerly Ollama-WebUI).",
    "source": "github",
    "date": "2024-05-30",
    "highlights": [
      "Docker one-liner",
      "multi-model chat",
      "RAG uploads, dark mode"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java/Kotlin client SDK for Ollama.",
    "source": "github",
    "date": "2024-05-20",
    "highlights": [
      "Maven Central",
      "sync/async APIs",
      "chat, embed, pull, list"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/ollama/ollama-rb",
    "summary": "Ruby gem for interacting with Ollama.",
    "source": "github",
    "date": "2024-05-18",
    "highlights": [
      "gem install ollama",
      "Faraday-based",
      "streaming support"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/saltyorg/ollama-cli",
    "summary": "Community Rust CLI that wraps the Ollama REST API with extra helpers.",
    "source": "github",
    "date": "2024-05-15",
    "highlights": [
      "cargo install ollama-cli",
      "model search, pull, run",
      "shell completions"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama/ollama-copilot",
    "summary": "VS Code extension that uses Ollama models for inline code suggestions.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "local copilot",
      "configurable model",
      "inline completions"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/ollama/ollama-haystack",
    "summary": "Haystack integration to use Ollama models as generators or embedders.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "pip install ollama-haystack",
      "Generator & Embedding components"
    ]
  },
  {
    "title": "ollama-streamlit",
    "url": "https://github.com/snehitbidani/ollama-streamlit",
    "summary": "Streamlit chat app template that talks to a local Ollama instance.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "one-file app",
      "session memory",
      "Dockerfile included"
    ]
  },
  {
    "title": "ollama-csharp",
    "url": "https://github.com/ollama/ollama-csharp",
    "summary": "Community-maintained C#/.NET client for Ollama.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "NuGet Ollama",
      ".NET 6+",
      "chat & embed APIs"
    ]
  },
  {
    "title": "ollama-docker-compose",
    "url": "https://github.com/ollama/ollama-docker-compose",
    "summary": "Official Docker Compose stack with GPU support and optional web UI.",
    "source": "github",
    "date": "2024-05-03",
    "highlights": [
      "nvidia runtime",
      "ollama + webui services",
      "volume caching"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/ollama/ollama-helm",
    "summary": "Helm chart for deploying Ollama on Kubernetes with GPU nodes.",
    "source": "github",
    "date": "2024-04-28",
    "highlights": [
      "Helm repo",
      "GPU scheduling",
      "ingress, persistence"
    ]
  },
  {
    "title": "ollama-model-hub",
    "url": "https://github.com/ollama/ollama-model-hub",
    "summary": "Curated list of community-created Modelfiles for niche domains.",
    "source": "github",
    "date": "2024-04-25",
    "highlights": [
      "Modelfile recipes",
      "fine-tuned adapters",
      "pull requests welcome"
    ]
  },
  {
    "title": "ollama-dagger",
    "url": "https://github.com/ollama/ollama-dagger",
    "summary": "Dagger module to run Ollama models inside CI pipelines for testing or doc-gen.",
    "source": "github",
    "date": "2024-04-22",
    "highlights": [
      "Daggerverse module",
      "cached model layers",
      "CI examples"
    ]
  },
  {
    "title": "ollama-rag",
    "url": "https://github.com/ggerganov/ollama-rag",
    "summary": "Minimal RAG example using Ollama embeddings + Chroma vector DB.",
    "source": "github",
    "date": "2024-04-20",
    "highlights": [
      "Python notebook",
      "Chroma integration",
      "pdf loader"
    ]
  },
  {
    "title": "ollama-fastapi",
    "url": "https://github.com/technovangelist/ollama-fastapi",
    "summary": "FastAPI service that exposes extra endpoints (batching, auth) over Ollama.",
    "source": "github",
    "date": "2024-04-18",
    "highlights": [
      "JWT auth",
      "batch generate",
      "OpenAPI spec"
    ]
  },
  {
    "title": "ollama-discord-bot",
    "url": "https://github.com/ollama/ollama-discord-bot",
    "summary": "Self-hosted Discord bot that lets servers chat with local Ollama models.",
    "source": "github",
    "date": "2024-04-15",
    "highlights": [
      "slash commands",
      "per-guild model config",
      "Docker image"
    ]
  },
  {
    "title": "ollama-model-registry",
    "url": "https://github.com/ollama/ollama-model-registry",
    "summary": "Lightweight registry to host and serve private Ollama models inside an org.",
    "source": "github",
    "date": "2024-04-12",
    "highlights": [
      "push/pull auth",
      "S3 backend",
      "signed URLs"
    ]
  }
]