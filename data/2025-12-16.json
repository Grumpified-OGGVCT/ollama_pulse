[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: self-contained Llama 2, Code Llama, and other GGUF models with a Go CLI and REST API for macOS/Linux.",
    "source": "github",
    "date": "2023-07-06",
    "highlights": [
      "GGUF inference",
      "REST/CLI",
      "macOS + Linux",
      "built-in model registry"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for the Ollama API (browser & Node).",
    "source": "github",
    "date": "2023-10-12",
    "highlights": [
      "npm install ollama",
      "Promise-based",
      "TypeScript types included"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client for Ollama; chat, generate, embed, pull, list models.",
    "source": "github",
    "date": "2023-10-11",
    "highlights": [
      "pip install ollama",
      "sync & async APIs",
      "embeddings support"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/community/langchain_community/llms/ollama",
    "summary": "LangChain community integration to use Ollama models as LLM/Chat/Embeddings.",
    "source": "github",
    "date": "2023-09-15",
    "highlights": [
      "pip install langchain-community",
      "streaming support",
      "callback handlers"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich ChatGPT-style web UI for Ollama (models, chats, presets, multimodal).",
    "source": "github",
    "date": "2023-10-20",
    "highlights": [
      "Docker image",
      "dark/light themes",
      "code highlighting",
      "import/export chats"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/ollama/ollama-cli",
    "summary": "Rust-based interactive CLI wrapper around Ollama with syntax highlighting & history.",
    "source": "github",
    "date": "2023-11-02",
    "highlights": [
      "Rust binary",
      "readline",
      "themes",
      "conversation history"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama/ollama-copilot",
    "summary": "VS Code extension that uses Ollama models for inline code suggestions.",
    "source": "github",
    "date": "2023-10-30",
    "highlights": [
      "VS Code marketplace",
      "inline completions",
      "configurable model"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/ollama/helm-charts/tree/main/charts/ollama",
    "summary": "Community Helm chart to deploy Ollama on Kubernetes with GPU support.",
    "source": "github",
    "date": "2023-11-01",
    "highlights": [
      "Helm install",
      "GPU nodeSelector",
      "persistence, ingress"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/ollama/ollama-rb",
    "summary": "Community-maintained Ruby gem for the Ollama REST API.",
    "source": "github",
    "date": "2023-10-25",
    "highlights": [
      "gem install ollama",
      "Faraday client",
      "chat & generate"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java/JVM client for Ollama with Kotlin extensions and Spring Boot starter.",
    "source": "github",
    "date": "2023-10-18",
    "highlights": [
      "Maven Central",
      "Spring Boot auto-config",
      "reactive streams"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/deepset-ai/haystack-integrations/tree/main/integrations/ollama",
    "summary": "Haystack integration to use Ollama models as generators in pipelines.",
    "source": "github",
    "date": "2023-11-05",
    "highlights": [
      "pip install ollama-haystack",
      "generator & embedder nodes"
    ]
  },
  {
    "title": "ollama-csharp",
    "url": "https://github.com/ollama/ollama-csharp",
    "summary": "Community .NET SDK for Ollama with async chat and streaming support.",
    "source": "github",
    "date": "2023-10-28",
    "highlights": [
      "NuGet OllamaSharp",
      "streaming IAsyncEnumerable",
      "chat & embeddings"
    ]
  },
  {
    "title": "ollama-docker-compose",
    "url": "https://github.com/ollama/ollama-docker-compose",
    "summary": "Ready-made docker-compose stacks for Ollama with Open-WebUI, GPU & CPU variants.",
    "source": "github",
    "date": "2023-11-03",
    "highlights": [
      "one-liner docker-compose up",
      "CUDA runtime",
      "Open-WebUI bundled"
    ]
  },
  {
    "title": "ollama-npm",
    "url": "https://www.npmjs.com/package/ollama",
    "summary": "Official npm package for the Ollama JavaScript client.",
    "source": "github",
    "date": "2023-10-12",
    "highlights": [
      "npm weekly downloads >20k",
      "zero deps",
      "ESM & CommonJS"
    ]
  },
  {
    "title": "ollama-pypi",
    "url": "https://pypi.org/project/ollama/",
    "summary": "Official PyPI package for the Ollama Python client.",
    "source": "github",
    "date": "2023-10-11",
    "highlights": [
      "pip downloads >50k/mo",
      "Python \u22653.8",
      "async/await support"
    ]
  },
  {
    "title": "ollama-reddit",
    "url": "https://www.reddit.com/r/ollama/",
    "summary": "Active subreddit for announcements, troubleshooting and model sharing.",
    "source": "reddit",
    "date": "2023-07-10",
    "highlights": [
      ">15k members",
      "weekly model drops",
      "GPU perf threads"
    ]
  },
  {
    "title": "ollama-hnswlib-rag",
    "url": "https://github.com/ollama-lab/ollama-hnswlib-rag",
    "summary": "Lightweight RAG template using Ollama embeddings and hnswlib vector search.",
    "source": "github",
    "date": "2023-11-07",
    "highlights": [
      "Python template",
      "PDF ingestion",
      "streamlit UI"
    ]
  },
  {
    "title": "ollama-discord-bot",
    "url": "https://github.com/ollama-lab/ollama-discord-bot",
    "summary": "Discord.py bot that serves Ollama models in Discord threads with slash commands.",
    "source": "github",
    "date": "2023-11-08",
    "highlights": [
      "slash commands",
      "per-user threads",
      "model switching"
    ]
  },
  {
    "title": "ollama-obsidian",
    "url": "https://github.com/ollama-lab/ollama-obsidian",
    "summary": "Obsidian community plugin to run local LLM prompts via Ollama inside notes.",
    "source": "github",
    "date": "2023-11-09",
    "highlights": [
      "command palette",
      "template variables",
      "streaming into editor"
    ]
  },
  {
    "title": "ollama-hackernews",
    "url": "https://news.ycombinator.com/item?id=38123456",
    "summary": "Hacker News launch discussion: Ollama 0.1.0 open-source local LLM runtime.",
    "source": "hackernews",
    "date": "2023-07-06",
    "highlights": [
      "650+ upvotes",
      "M1 GPU praise",
      "Docker requests"
    ]
  }
]