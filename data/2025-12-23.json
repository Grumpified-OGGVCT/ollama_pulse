[
  {
    "title": "Ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Get up and running with Llama 3, Mistral, Gemma, and other large language models locally.",
    "source": "github",
    "date": "2024-04-19",
    "highlights": [
      "Run Llama 3 and other models locally",
      "Simple command-line interface",
      "macOS, Linux, Windows support"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Python library for Ollama, enabling easy integration of local LLMs into Python applications.",
    "source": "github",
    "date": "2024-04-15",
    "highlights": [
      "Official Python client",
      "Async support",
      "Streaming responses"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "JavaScript/TypeScript library for Ollama, allowing Node.js and browser integration with local LLMs.",
    "source": "github",
    "date": "2024-04-10",
    "highlights": [
      "Official JavaScript client",
      "TypeScript definitions",
      "Browser and Node.js support"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://pypi.org/project/langchain-ollama/",
    "summary": "LangChain integration for Ollama, providing a standardized interface for local LLM interactions.",
    "source": "pypi",
    "date": "2024-04-12",
    "highlights": [
      "LangChain compatibility",
      "Chain orchestration",
      "Tool integration"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich web UI for Ollama, offering ChatGPT-like interface for local LLM interactions.",
    "source": "github",
    "date": "2024-04-18",
    "highlights": [
      "ChatGPT-like interface",
      "Model management",
      "Multi-user support"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java library for Ollama, enabling Java applications to interact with local LLMs.",
    "source": "github",
    "date": "2024-03-28",
    "highlights": [
      "Java client library",
      "Spring Boot integration",
      "Async operations"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/jparkerweb/ollama-haystack",
    "summary": "Haystack integration for Ollama, allowing use of local LLMs in Haystack pipelines.",
    "source": "github",
    "date": "2024-04-05",
    "highlights": [
      "Haystack pipeline integration",
      "RAG support",
      "Document search"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama/ollama-copilot",
    "summary": "VS Code extension bringing Ollama-powered AI assistance to the editor.",
    "source": "github",
    "date": "2024-04-08",
    "highlights": [
      "VS Code integration",
      "Code completion",
      "Inline chat"
    ]
  },
  {
    "title": "ollama-models",
    "url": "https://github.com/ollama/ollama-models",
    "summary": "Curated collection of models optimized for Ollama, with setup instructions.",
    "source": "github",
    "date": "2024-04-14",
    "highlights": [
      "Model collection",
      "Optimization guides",
      "Community contributions"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://www.npmjs.com/package/ollama-cli",
    "summary": "Command-line interface tool for interacting with Ollama models from npm.",
    "source": "npm",
    "date": "2024-04-11",
    "highlights": [
      "NPM package",
      "CLI tool",
      "Cross-platform"
    ]
  },
  {
    "title": "ollama-streamlit",
    "url": "https://github.com/simeonovp/ollama-streamlit",
    "summary": "Streamlit app for Ollama, providing a web interface for local LLM interactions.",
    "source": "github",
    "date": "2024-04-09",
    "highlights": [
      "Streamlit integration",
      "Web interface",
      "Real-time streaming"
    ]
  },
  {
    "title": "ollama-docker",
    "url": "https://github.com/ollama/ollama-docker",
    "summary": "Docker containers for Ollama, enabling easy deployment in containerized environments.",
    "source": "github",
    "date": "2024-04-13",
    "highlights": [
      "Docker support",
      "GPU acceleration",
      "Kubernetes ready"
    ]
  },
  {
    "title": "ollama-rag",
    "url": "https://github.com/gabacode/ollama-rag",
    "summary": "Implementation of RAG (Retrieval-Augmented Generation) using Ollama and local models.",
    "source": "github",
    "date": "2024-04-07",
    "highlights": [
      "RAG implementation",
      "Local document search",
      "Vector database integration"
    ]
  },
  {
    "title": "ollama-discord",
    "url": "https://github.com/ollama-discord/ollama-discord",
    "summary": "Discord bot integration for Ollama, bringing local LLM capabilities to Discord servers.",
    "source": "github",
    "date": "2024-04-06",
    "highlights": [
      "Discord bot",
      "Server integration",
      "Custom commands"
    ]
  },
  {
    "title": "ollama-fastapi",
    "url": "https://github.com/ollama-fastapi/ollama-fastapi",
    "summary": "FastAPI wrapper for Ollama, providing REST API endpoints for local LLM interactions.",
    "source": "github",
    "date": "2024-04-04",
    "highlights": [
      "FastAPI integration",
      "REST endpoints",
      "OpenAPI docs"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/ollama-helm/ollama-helm",
    "summary": "Helm charts for deploying Ollama on Kubernetes clusters.",
    "source": "github",
    "date": "2024-04-03",
    "highlights": [
      "Kubernetes deployment",
      "Helm charts",
      "Scaling support"
    ]
  },
  {
    "title": "ollama-obsidian",
    "url": "https://github.com/hinterdupfinger/ollama-obsidian",
    "summary": "Obsidian plugin for Ollama, enabling AI-powered note-taking and content generation.",
    "source": "github",
    "date": "2024-04-02",
    "highlights": [
      "Obsidian integration",
      "Note assistance",
      "Content generation"
    ]
  },
  {
    "title": "ollama-slack",
    "url": "https://github.com/ollama-slack/ollama-slack",
    "summary": "Slack integration for Ollama, allowing teams to interact with local LLMs in Slack.",
    "source": "github",
    "date": "2024-04-01",
    "highlights": [
      "Slack bot",
      "Team collaboration",
      "Thread support"
    ]
  },
  {
    "title": "ollama-telegram",
    "url": "https://github.com/raphaelmansuy/ollama-telegram",
    "summary": "Telegram bot for Ollama, bringing local LLM capabilities to Telegram chats.",
    "source": "github",
    "date": "2024-03-31",
    "highlights": [
      "Telegram bot",
      "Group chat support",
      "Voice message handling"
    ]
  },
  {
    "title": "ollama-rust",
    "url": "https://github.com/ollama-rust/ollama-rust",
    "summary": "Rust client library for Ollama, enabling Rust applications to interact with local LLMs.",
    "source": "github",
    "date": "2024-03-30",
    "highlights": [
      "Rust client",
      "Async/await support",
      "Type safety"
    ]
  }
]