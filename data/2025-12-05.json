[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repository providing the CLI and server to pull, create, and run large language models locally.",
    "source": "github",
    "date": "2023-06-26",
    "highlights": [
      "CLI",
      "REST API",
      "macOS/Linux/Windows",
      "Docker image"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client library for Ollama, enabling browser and Node.js integration.",
    "source": "github",
    "date": "2023-10-12",
    "highlights": [
      "npm package",
      "Promise-based",
      "TypeScript types"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client library for Ollama with sync/async APIs and streaming support.",
    "source": "github",
    "date": "2023-09-05",
    "highlights": [
      "PyPI package",
      "asyncio",
      "streaming",
      "Pydantic models"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/ollama",
    "summary": "LangChain integration for Ollama models, providing LLM and chat interfaces.",
    "source": "github",
    "date": "2023-11-02",
    "highlights": [
      "LangChain LLM",
      "chat models",
      "tool calling",
      "RAG support"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich web UI for Ollama with chat interface, model management, and RAG capabilities.",
    "source": "github",
    "date": "2023-10-08",
    "highlights": [
      "ChatGPT-like UI",
      "Docker",
      "RAG",
      "multi-model",
      "Dark mode"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java SDK for Ollama providing synchronous and asynchronous APIs.",
    "source": "github",
    "date": "2023-11-20",
    "highlights": [
      "Maven Central",
      "async",
      "streaming",
      "Spring Boot starter"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/nileshtrivedi/ollama-rb",
    "summary": "Ruby gem for interacting with the Ollama REST API.",
    "source": "github",
    "date": "2023-12-01",
    "highlights": [
      "Ruby gem",
      "streaming",
      "Faraday HTTP"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/saltyorg/ollama-cli",
    "summary": "Community Rust CLI for Ollama with TUI and model management features.",
    "source": "github",
    "date": "2024-01-15",
    "highlights": [
      "Rust",
      "TUI",
      "model search",
      "download progress"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama/ollama-copilot",
    "summary": "VS Code extension bringing local AI coding assistance via Ollama.",
    "source": "github",
    "date": "2024-02-10",
    "highlights": [
      "VS Code",
      "inline completion",
      "chat panel",
      "multi-model"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/deepset-ai/haystack-core-integrations/tree/main/integrations/ollama",
    "summary": "Haystack integration enabling Ollama models in pipelines for RAG and generative tasks.",
    "source": "github",
    "date": "2024-02-28",
    "highlights": [
      "Haystack 2.x",
      "generator",
      "chat generator",
      "embedders"
    ]
  },
  {
    "title": "ollama-camunda",
    "url": "https://github.com/camunda-community-hub/ollama-camunda",
    "summary": "Camunda community connector that invokes Ollama models from BPMN processes.",
    "source": "github",
    "date": "2024-03-05",
    "highlights": [
      "Camunda 8",
      "connector",
      "BPMN",
      "serverless"
    ]
  },
  {
    "title": "ollama-discord",
    "url": "https://github.com/ollama-webui/ollama-discord",
    "summary": "Discord bot that lets users chat with local Ollama models in servers.",
    "source": "github",
    "date": "2024-03-12",
    "highlights": [
      "Slash commands",
      "threading",
      "admin roles",
      "Docker"
    ]
  },
  {
    "title": "ollama-slack",
    "url": "https://github.com/rockerBOO/ollama-slack",
    "summary": "Slack bot integration for Ollama with streaming responses and model switching.",
    "source": "github",
    "date": "2024-03-20",
    "highlights": [
      "Bolt.js",
      "streaming",
      "modal UI",
      "thread replies"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/otwld/ollama-helm",
    "summary": "Helm chart to deploy Ollama on Kubernetes with GPU and persistence support.",
    "source": "github",
    "date": "2024-03-25",
    "highlights": [
      "Kubernetes",
      "GPU nodes",
      "PVC",
      "autoscaling"
    ]
  },
  {
    "title": "ollama-nix",
    "url": "https://github.com/NixOS/nixpkgs/tree/master/pkgs/tools/misc/ollama",
    "summary": "Nix package and module for declarative Ollama installation and service management.",
    "source": "github",
    "date": "2024-04-01",
    "highlights": [
      "NixOS module",
      "systemd",
      "declarative models"
    ]
  },
  {
    "title": "ollama-dagger",
    "url": "https://github.com/shykes/daggerverse/tree/main/ollama",
    "summary": "Dagger module that wraps Ollama for CI/CD pipelines and reproducible dev environments.",
    "source": "github",
    "date": "2024-04-10",
    "highlights": [
      "Dagger",
      "CUE",
      "devShell",
      "GPU CI"
    ]
  },
  {
    "title": "ollama-elixir",
    "url": "https://github.com/curiosum-dev/ollama-elixir",
    "summary": "Elixir client for Ollama with GenServer behavior and streaming support.",
    "source": "github",
    "date": "2024-04-15",
    "highlights": [
      "Hex.pm",
      "GenServer",
      "supervision tree",
      "LiveView"
    ]
  },
  {
    "title": "ollama-go",
    "url": "https://github.com/mxyng/ollama-go",
    "summary": "Unofficial idiomatic Go client for Ollama with context and streaming helpers.",
    "source": "github",
    "date": "2024-04-20",
    "highlights": [
      "Go module",
      "context",
      "io.Reader streams"
    ]
  },
  {
    "title": "ollama-cpp",
    "url": "https://github.com/ggerganov/llama.cpp/pull/5732",
    "summary": "Upstream llama.cpp PR that adds Ollama-compatible API endpoints to the reference implementation.",
    "source": "github",
    "date": "2024-04-25",
    "highlights": [
      "llama.cpp",
      "/api/chat",
      "/api/embeddings",
      "drop-in"
    ]
  },
  {
    "title": "ollama-models",
    "url": "https://github.com/ollama/ollama/tree/main/models",
    "summary": "Official registry of Ollama Modelfile definitions for Llama 3, Mistral, Gemma, Phi, etc.",
    "source": "github",
    "date": "2024-05-01",
    "highlights": [
      "Modelfiles",
      "quantization",
      "official tags",
      "community PRs"
    ]
  }
]