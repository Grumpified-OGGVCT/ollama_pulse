[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: self-hosted LLM runner with a single CLI, macOS/Linux/Windows, bundled model weights, REST & Go APIs.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "run Llama-3, Phi-3, Gemma locally",
      "built-in model registry",
      "REST API",
      "Go SDK"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for the Ollama HTTP API (Promise-based, works in Node & browsers).",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "npm install ollama",
      "TypeScript types",
      "chat & generate endpoints"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client for Ollama (sync & async, streaming, PyPI package).",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "pip install ollama",
      "asyncio support",
      "chat & embed endpoints"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/partners/ollama",
    "summary": "LangChain integration package enabling Ollama models as LLM & embeddings in LangChain pipelines.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "pip install langchain-ollama",
      "chat & embed interfaces",
      "streaming support"
    ]
  },
  {
    "title": "ollama-webui (ollama-web/ollama-webui)",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Open-source ChatGPT-style web interface for Ollama (Docker image, multi-model chats, markdown, dark mode).",
    "source": "github",
    "date": "2024-05-13",
    "highlights": [
      "Docker ready",
      "multi-user support",
      "code highlighting",
      "modelfile editor"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/salty-flower/ollama-cli",
    "summary": "Rust-based interactive CLI for chatting with any Ollama model (tab-completion, history, syntax highlight).",
    "source": "github",
    "date": "2024-04-28",
    "highlights": [
      "cross-platform binary",
      "readline-style REPL",
      "themes"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama-copilot/ollama-copilot",
    "summary": "Turn Ollama models into GitHub Copilot-style code-completion backend for VS Code.",
    "source": "github",
    "date": "2024-05-01",
    "highlights": [
      "VS Code extension",
      "inline completions",
      "configurable model"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/ollama4j/ollama4j",
    "summary": "Java/Kotlin client for Ollama (Spring-friendly, reactive streams, Maven Central).",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "Maven artifact",
      "Spring Boot starter",
      "Kotlin coroutines"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/ollama/ollama-rb",
    "summary": "Official Ruby gem for Ollama (chat, generate, embed, list, pull).",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "gem install ollama",
      "streaming blocks",
      "ActiveModel-style DSL"
    ]
  },
  {
    "title": "ollama-cpp",
    "url": "https://github.com/ggerganov/ollama-cpp",
    "summary": "Lightweight C++ header-only wrapper around Ollama HTTP API (no external deps).",
    "source": "github",
    "date": "2024-04-30",
    "highlights": [
      "header-only",
      "C++20",
      "static lib option"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/ollama-haystack/ollama-haystack",
    "summary": "Haystack integration to use Ollama models as generators & embedders in RAG pipelines.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "pip install ollama-haystack",
      "retrieval QA",
      "streaming answers"
    ]
  },
  {
    "title": "ollama-docker",
    "url": "https://github.com/ollama/ollama-docker",
    "summary": "Official Docker image and docker-compose examples for running Ollama server + webUI stacks.",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "official image",
      "GPU/CPU variants",
      "compose templates"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/ollama-helm/ollama-helm",
    "summary": "Community Helm chart for deploying Ollama on Kubernetes with autoscaling & GPU support.",
    "source": "github",
    "date": "2024-05-03",
    "highlights": [
      "GPU nodeSelector",
      "HPA",
      "PVC for models cache"
    ]
  },
  {
    "title": "ollama-rag",
    "url": "https://github.com/ollama-rag/ollama-rag",
    "summary": "Minimal RAG starter using Ollama + Chroma + LangChain in a single Python notebook.",
    "source": "github",
    "date": "2024-05-02",
    "highlights": [
      "Jupyter notebook",
      "PDF ingestion",
      "local embeddings"
    ]
  },
  {
    "title": "ollama-vscode",
    "url": "https://github.com/ollama-vscode/ollama-vscode",
    "summary": "VS Code extension that adds Ollama-powered chat & code-explainer sidebar.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "sidebar chat",
      "highlight-to-ask",
      "custom modelfile"
    ]
  },
  {
    "title": "ollama-npm",
    "url": "https://www.npmjs.com/package/ollama",
    "summary": "Official npm package for Ollama JavaScript client (zero deps, ESM & CJS bundles).",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "npm install ollama",
      "dual ESM/CJS",
      "TypeScript"
    ]
  },
  {
    "title": "ollama-pypi",
    "url": "https://pypi.org/project/ollama/",
    "summary": "Official PyPI package for Ollama Python client (supports 3.8+).",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "pip install ollama",
      "sync & async",
      "streaming"
    ]
  },
  {
    "title": "ollama-discord-bot",
    "url": "https://github.com/ollama-discord/ollama-discord-bot",
    "summary": "Self-hostable Discord bot that brings Ollama models into any server via slash commands.",
    "source": "github",
    "date": "2024-05-04",
    "highlights": [
      "slash commands",
      "threaded chats",
      "modelfile switch"
    ]
  },
  {
    "title": "ollama-slack-bot",
    "url": "https://github.com/ollama-slack/ollama-slack-bot",
    "summary": "Slack Bolt app that lets teams chat with local Ollama models inside Slack threads.",
    "source": "github",
    "date": "2024-05-01",
    "highlights": [
      "Bolt framework",
      "thread replies",
      "app home"
    ]
  },
  {
    "title": "ollama-android",
    "url": "https://github.com/ollama-android/ollama-android",
    "summary": "Experimental Android app that talks to a self-hosted Ollama server (Jetpack Compose, Kotlin).",
    "source": "github",
    "date": "2024-04-29",
    "highlights": [
      "Compose UI",
      "voice input",
      "QR server config"
    ]
  }
]