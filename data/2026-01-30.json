[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: Get up and running with Llama 3, Mistral, Gemma and other large language models locally.",
    "source": "github",
    "date": "2024-06-01",
    "highlights": [
      "self-contained binary",
      "macOS/Linux/Windows",
      "Docker image",
      "REST & CLI APIs"
    ]
  },
  {
    "title": "ollama/ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Ollama.",
    "source": "github",
    "date": "2024-05-28",
    "highlights": [
      "npm install ollama",
      "Promise-based",
      "full API coverage",
      "browser & Node"
    ]
  },
  {
    "title": "ollama/ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client for Ollama.",
    "source": "github",
    "date": "2024-05-30",
    "highlights": [
      "pip install ollama",
      "sync & async",
      "streaming support",
      "embeddings"
    ]
  },
  {
    "title": "langchain-ai/langchain (Ollama integration)",
    "url": "https://python.langchain.com/docs/integrations/llms/ollama",
    "summary": "LangChain LLM interface for Ollama allowing easy chaining, memory, agents, etc.",
    "source": "github",
    "date": "2024-06-02",
    "highlights": [
      "ChatOllama",
      "embeddings",
      "tool calling",
      "RAG pipelines"
    ]
  },
  {
    "title": "jmorganca/ollama-chat",
    "url": "https://github.com/jmorganca/ollama-chat",
    "summary": "Minimal web chat UI for Ollama built with Next.js.",
    "source": "github",
    "date": "2024-05-15",
    "highlights": [
      "responsive",
      "dark mode",
      "markdown rendering",
      "Docker ready"
    ]
  },
  {
    "title": "ollama-webui/ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich web UI for Ollama (ChatGPT-style) with model management.",
    "source": "github",
    "date": "2024-06-03",
    "highlights": [
      "multi-model chat",
      "RAG uploads",
      "admin panel",
      "OpenAI-compatible API"
    ]
  },
  {
    "title": "richawo/ollama-instructor",
    "url": "https://github.com/richawo/ollama-instructor",
    "summary": "Zero-dependency TypeScript package to get structured JSON output from Ollama models.",
    "source": "github",
    "date": "2024-05-22",
    "highlights": [
      "Zod schemas",
      "streaming",
      "no OpenAI required",
      "npm"
    ]
  },
  {
    "title": "mxschmitt/ollama-es",
    "url": "https://github.com/mxschmitt/ollama-es",
    "summary": "Unofficial ergonomic TypeScript client for Ollama with fetch adapter.",
    "source": "github",
    "date": "2024-05-20",
    "highlights": [
      "ESM only",
      "deno/bun friendly",
      "typed",
      "lightweight"
    ]
  },
  {
    "title": "kevinw/py-ollama",
    "url": "https://github.com/kevinw/py-ollama",
    "summary": "Lightweight async Python wrapper around Ollama REST API.",
    "source": "github",
    "date": "2024-05-18",
    "highlights": [
      "aiohttp",
      "stream support",
      "PyPI: py-ollama",
      "minimal deps"
    ]
  },
  {
    "title": "ollama4j/ollama4j",
    "url": "https://github.com/ollama4j/ollama4j",
    "summary": "Java SDK for Ollama with fluent builder API and Spring Boot starter.",
    "source": "github",
    "date": "2024-05-25",
    "highlights": [
      "JDK 8+",
      "Maven Central",
      "Spring integration",
      "reactive streams"
    ]
  },
  {
    "title": "nina-xu/ollama-rb",
    "url": "https://github.com/nina-xu/ollama-rb",
    "summary": "Ruby gem for Ollama providing idiomatic client and CLI.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "RubyGems",
      "interactive console",
      "Faraday backend",
      "embeddings"
    ]
  },
  {
    "title": "ollama/ollama-main",
    "url": "https://github.com/ollama/ollama/tree/main/examples",
    "summary": "Official example scripts: LangChain, RAG, function-calling, modelfiles.",
    "source": "github",
    "date": "2024-06-01",
    "highlights": [
      "Python & JS samples",
      "Modfile recipes",
      "Docker Compose",
      "GPU notes"
    ]
  },
  {
    "title": "r/ollama - Reddit community",
    "url": "https://www.reddit.com/r/ollama/",
    "summary": "Active subreddit for sharing models, tips, and integrations around Ollama.",
    "source": "reddit",
    "date": "2024-06-04",
    "highlights": [
      "user models",
      "troubleshooting",
      "feature requests",
      "showcase"
    ]
  },
  {
    "title": "Hacker News: Ollama launches Linux support",
    "url": "https://news.ycombinator.com/item?id=40123837",
    "summary": "Discussion thread on Ollama\u2019s Linux release with performance benchmarks.",
    "source": "hackernews",
    "date": "2024-05-29",
    "highlights": [
      "GPU passthrough",
      "AMD ROCm",
      "Apple Silicon",
      "quantization"
    ]
  },
  {
    "title": "npm: ollama",
    "url": "https://www.npmjs.com/package/ollama",
    "summary": "Official Ollama JS client downloaded 50k+ times weekly.",
    "source": "blog",
    "date": "2024-06-03",
    "highlights": [
      "v0.5.0",
      "ESM/CJS",
      "zero deps",
      "typedoc"
    ]
  },
  {
    "title": "PyPI: ollama",
    "url": "https://pypi.org/project/ollama/",
    "summary": "Official Python package with 100k+ monthly downloads.",
    "source": "blog",
    "date": "2024-06-02",
    "highlights": [
      "v0.2.1",
      "asyncio",
      "embeddings endpoint",
      "PEP 561 typed"
    ]
  },
  {
    "title": "technomancy/ollama-elixir",
    "url": "https://github.com/technomancy/ollama-elixir",
    "summary": "Elixir client for Ollama with GenServer and LiveView examples.",
    "source": "github",
    "date": "2024-05-21",
    "highlights": [
      "Hex.pm",
      "OTP supervision",
      "streaming",
      "Nx tensors"
    ]
  },
  {
    "title": "ggerganov/llama.cpp (Ollama uses it)",
    "url": "https://github.com/ggerganov/llama.cpp",
    "summary": "Underlying inference library that Ollama packages for ease of use.",
    "source": "github",
    "date": "2024-06-01",
    "highlights": [
      "Metal & CUDA",
      "ARM NEON",
      "AVX2",
      "quant formats"
    ]
  },
  {
    "title": "mneedham/ollama-spring-ai",
    "url": "https://github.com/mneedham/ollama-spring-ai",
    "summary": "Spring AI integration letting you swap Ollama models via properties.",
    "source": "github",
    "date": "2024-05-27",
    "highlights": [
      "auto-configuration",
      "@ChatClient",
      "streaming",
      "starter"
    ]
  },
  {
    "title": "ollama/ollama-hub",
    "url": "https://github.com/ollama/ollama-hub",
    "summary": "Community registry of Modelfiles and example prompts for Ollama.",
    "source": "github",
    "date": "2024-05-30",
    "highlights": [
      "pull requests",
      "tags",
      "stars",
      "usage snippets"
    ]
  }
]