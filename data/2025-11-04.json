[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Get up and running with Llama 3.3, Mistral, Gemma 2, and other large language models locally.",
    "source": "github",
    "date": "2024-12-19",
    "highlights": [
      "self-hosted",
      "Docker",
      "REST API",
      "model library"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client for Ollama, allowing easy integration of local LLMs into Python apps.",
    "source": "github",
    "date": "2024-12-19",
    "highlights": [
      "PyPI",
      "async/sync",
      "streaming",
      "embeddings"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Ollama, works in Node and browsers.",
    "source": "github",
    "date": "2024-12-19",
    "highlights": [
      "npm",
      "TypeScript",
      "streaming",
      "browser support"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/partners/ollama",
    "summary": "LangChain integration for Ollama, enabling local LLM chains, agents, and RAG.",
    "source": "github",
    "date": "2024-12-18",
    "highlights": [
      "RAG",
      "agents",
      "chat models",
      "embeddings"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Open-source ChatGPT-style web UI for Ollama, supports multi-model chats and document upload.",
    "source": "github",
    "date": "2024-12-19",
    "highlights": [
      "Docker",
      "document QA",
      "voice input",
      "dark mode"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java/Kotlin client for Ollama with Spring Boot starters and fluent API.",
    "source": "github",
    "date": "2024-12-15",
    "highlights": [
      "Maven Central",
      "Spring Boot",
      "Kotlin DSL",
      "streaming"
    ]
  },
  {
    "title": "ollama-rails",
    "url": "https://github.com/nileshtrivedi/ollama-rails",
    "summary": "Ruby gem that wraps Ollama\u2019s REST API for Rails and Ruby apps.",
    "source": "github",
    "date": "2024-12-10",
    "highlights": [
      "RubyGems",
      "ActiveRecord-like",
      "streaming",
      "embeddings"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama-copilot/ollama-copilot",
    "summary": "VS Code extension bringing local LLM code completion via Ollama.",
    "source": "github",
    "date": "2024-12-17",
    "highlights": [
      "VS Code",
      "inline completion",
      "custom models",
      "FIM templates"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/saltyorg/ollama-cli",
    "summary": "Rich CLI wrapper around Ollama with chat history, syntax highlighting, and plugins.",
    "source": "github",
    "date": "2024-12-16",
    "highlights": [
      "REPL",
      "plugins",
      "themes",
      "history"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/deepset-ai/haystack-ollama",
    "summary": "Haystack integration to use Ollama models for semantic search and generative QA pipelines.",
    "source": "github",
    "date": "2024-12-14",
    "highlights": [
      "Haystack",
      "pipelines",
      "embeddings",
      "retrieval"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/otwld/ollama-helm",
    "summary": "Production-ready Helm chart for deploying Ollama on Kubernetes with GPU support.",
    "source": "github",
    "date": "2024-12-18",
    "highlights": [
      "Helm",
      "GPU nodes",
      "autoscaling",
      "persistent storage"
    ]
  },
  {
    "title": "ollama-chatbot-ui",
    "url": "https://github.com/jakobhoeg/ollama-chatbot-ui",
    "summary": "Minimal Next.js chatbot UI wired to Ollama with streaming and markdown support.",
    "source": "github",
    "date": "2024-12-17",
    "highlights": [
      "Next.js",
      "streaming",
      "markdown",
      "Docker"
    ]
  },
  {
    "title": "ollama-csharp",
    "url": "https://github.com/awaescher/ollama-csharp",
    "summary": ".NET SDK for Ollama with LINQ-style fluent API and dependency-injection helpers.",
    "source": "github",
    "date": "2024-12-15",
    "highlights": [
      "NuGet",
      "DI",
      "streaming",
      "async enumerable"
    ]
  },
  {
    "title": "ollama-obsidian",
    "url": "https://github.com/hinterdupinger/ollama-obsidian",
    "summary": "Obsidian plugin that lets you run local LLM prompts on your notes via Ollama.",
    "source": "github",
    "date": "2024-12-13",
    "highlights": [
      "Obsidian",
      "templates",
      "hotkeys",
      "offline"
    ]
  },
  {
    "title": "ollama-gui",
    "url": "https://github.com/TannerGilbert/ollama-gui",
    "summary": "Cross-platform Flutter desktop app for chatting with Ollama models.",
    "source": "github",
    "date": "2024-12-12",
    "highlights": [
      "Flutter",
      "desktop",
      "Windows/macOS/Linux",
      "themes"
    ]
  },
  {
    "title": "ollama-dagger",
    "url": "https://github.com/shykes/ollama-dagger",
    "summary": "Dagger module that spins up Ollama as a CI service for testing LLM-powered features.",
    "source": "github",
    "date": "2024-12-11",
    "highlights": [
      "Dagger",
      "CI",
      "caching",
      "testcontainers"
    ]
  },
  {
    "title": "ollama-n8n",
    "url": "https://github.com/n8n-io/n8n-nodes-ollama",
    "summary": "n8n community node to integrate Ollama into no-code automation workflows.",
    "source": "github",
    "date": "2024-12-16",
    "highlights": [
      "n8n",
      "no-code",
      "webhooks",
      "workflow"
    ]
  },
  {
    "title": "ollama-rag",
    "url": "https://github.com/Peter-De-Antonio/ollama-rag",
    "summary": "Minimal RAG template using Ollama embeddings + ChromaDB + Streamlit.",
    "source": "github",
    "date": "2024-12-14",
    "highlights": [
      "RAG",
      "ChromaDB",
      "Streamlit",
      "PDF ingestion"
    ]
  },
  {
    "title": "ollama-discord",
    "url": "https://github.com/mxyng/ollama-discord",
    "summary": "Discord bot that brings Ollama models into any server with slash commands.",
    "source": "github",
    "date": "2024-12-13",
    "highlights": [
      "Discord.py",
      "slash commands",
      "threads",
      "moderation"
    ]
  },
  {
    "title": "ollama-mcp",
    "url": "https://github.com/ollama-mcp/ollama-mcp",
    "summary": "Model Context Protocol server exposing Ollama functions to Claude Desktop and other MCP clients.",
    "source": "github",
    "date": "2024-12-18",
    "highlights": [
      "MCP",
      "Claude Desktop",
      "tools",
      "functions"
    ]
  }
]