[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Ollama\u2019s official CLI and server for downloading, running, and managing local LLMs with a single command.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "pull/run any GGUF model",
      "built-in Modelfile DSL",
      "REST & OpenAI-compatible endpoints"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official async Python client for the Ollama API\u2014install via pip install ollama.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "async/await support",
      "streaming responses",
      "chat & embeddings helpers"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Node & browsers, published on npm as ollama.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "zero dependencies",
      "TypeScript types included",
      "browser & Node support"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://pypi.org/project/langchain-ollama/",
    "summary": "PyPI package adding Ollama LLM & embeddings integrations to LangChain.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "drop-in LangChain LLM",
      "embeddings interface",
      "streaming tokens"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Community-built ChatGPT-style web UI that proxies to any local Ollama instance.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "markdown & code highlighting",
      "multi-model chats",
      "Docker one-liner"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/ollama/haystack-ollama",
    "summary": "Haystack integration letting you use Ollama models as generators or embedders in pipelines.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "Haystack 2.0 ready",
      "prompt node replacement",
      "embedding provider"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java/JVM client library for Ollama, available on Maven Central.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "Java 8+ support",
      "fluent API builder",
      "reactive streaming"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/ollama/ollama-rb",
    "summary": "Community Ruby gem for interacting with the Ollama REST API.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "Ruby 3.x compatible",
      "Faraday-based",
      "RSpec test suite"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama/ollama-copilot",
    "summary": "VS Code extension that turns any Ollama model into a local GitHub Copilot alternative.",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "inline completions",
      "custom model pick",
      "zero config install"
    ]
  },
  {
    "title": "ollama-docker",
    "url": "https://github.com/ollama/ollama-docker",
    "summary": "Official Docker image with CUDA & ROCm variants and docker-compose examples.",
    "source": "github",
    "date": "2024-05-13",
    "highlights": [
      "GPU acceleration",
      "multi-arch",
      "compose stacks for CPU/GPU"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/ollama/helm-charts",
    "summary": "Community Helm chart for deploying Ollama on Kubernetes with autoscaling.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "GPU node selector",
      "PVC model cache",
      "HPA support"
    ]
  },
  {
    "title": "ollama-cli-chat",
    "url": "https://github.com/sigma67/ollama-cli-chat",
    "summary": "Rich-terminal chat client with history, syntax highlighting, and markdown rendering.",
    "source": "github",
    "date": "2024-05-04",
    "highlights": [
      "prompt history",
      "keybinding shortcuts",
      "local storage"
    ]
  },
  {
    "title": "ollama-gpt-script",
    "url": "https://github.com/gptscript-ai/ollama-tools",
    "summary": "GPTScript provider letting you call Ollama models as tools in agent scripts.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "tool use support",
      "function calling",
      "agent loops"
    ]
  },
  {
    "title": "ollama-csharp",
    "url": "https://github.com/ollama/ollama-csharp",
    "summary": "Unofficial C#/.NET SDK published on NuGet for integrating Ollama into .NET apps.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      ".NET 6+ target",
      "System.Text.Json",
      "async enumerable streaming"
    ]
  },
  {
    "title": "ollama-dagger",
    "url": "https://github.com/ollama/dagger-ollama",
    "summary": "Dagger module that spins up Ollama sidecars in CI pipelines for testing LLM features.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "CI caching",
      "model pre-seed",
      "Dagger 0.9+"
    ]
  },
  {
    "title": "ollama-obsidian",
    "url": "https://github.com/hintergrund/ollama-obsidian",
    "summary": "Obsidian plugin that adds Ollama-powered summarization and Q&A commands inside notes.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "command palette",
      "template variables",
      "offline operation"
    ]
  },
  {
    "title": "ollama-nix",
    "url": "https://github.com/NixOS/nixpkgs/pull/302614",
    "summary": "Nix flake adding Ollama service with automatic model fetching and GPU drivers.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "declarative models",
      "CUDA/ROCm",
      "systemd service"
    ]
  },
  {
    "title": "ollama-rust",
    "url": "https://github.com/ollama/ollama-rust",
    "summary": "Community Rust crate providing strongly-typed bindings to the Ollama REST API.",
    "source": "github",
    "date": "2024-05-03",
    "highlights": [
      "tokio client",
      "Serde models",
      "cargo install"
    ]
  },
  {
    "title": "ollama-elixir",
    "url": "https://github.com/ollama/ollama-elixir",
    "summary": "Elixir library wrapping Ollama for Phoenix and LiveView applications.",
    "source": "github",
    "date": "2024-05-04",
    "highlights": [
      "GenServer behavior",
      "LiveView hooks",
      "OTP supervision"
    ]
  },
  {
    "title": "ollama-discord-bot",
    "url": "https://github.com/ollama/discord-bot",
    "summary": "Self-hostable Discord bot that streams Ollama replies into any channel.",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "slash commands",
      "streaming messages",
      "role-based access"
    ]
  }
]