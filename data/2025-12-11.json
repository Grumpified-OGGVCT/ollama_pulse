[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official CLI and Python/JS libraries to pull and run Llama 2, Mistral, Gemma, CodeLlama and 30+ other GGUF models locally with GPU/Metal acceleration.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "self-contained binary",
      "built-in model registry",
      "REST API",
      "concurrent prompt handling"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official TypeScript/JavaScript SDK for Ollama\u2014chat, generate, pull, push, list and delete models from Node or the browser.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "Promise-based",
      "ESM & CJS bundles",
      "browser support",
      "typed definitions"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client with sync & async APIs; chat, stream, embeddings, vision, JSON mode and tool-calling support.",
    "source": "github",
    "date": "2024-05-13",
    "highlights": [
      "async/await",
      "Pydantic models",
      "streaming",
      "vision",
      "tools"
    ]
  },
  {
    "title": "langchain-ollama (PyPI)",
    "url": "https://pypi.org/project/langchain-ollama/",
    "summary": "LangChain adapter that plugs Ollama models into chains, agents, retrieval and tool-calling pipelines.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "ChatOllama",
      "OllamaEmbeddings",
      "tool calling",
      "streaming tokens"
    ]
  },
  {
    "title": "ollama-webui (ollama-webui/ollama-webui)",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich web UI (Open-WebUI) for Ollama\u2014chat, file upload, RAG, multi-user, model manager, plugins.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "PWA",
      "RAG over documents",
      "role-based auth",
      "plugin marketplace"
    ]
  },
  {
    "title": "ollama-cli (npm)",
    "url": "https://www.npmjs.com/package/ollama-cli",
    "summary": "Lightweight CLI wrapper around the Ollama REST API; chat, generate, list, pull and delete models from the terminal.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "global install",
      "interactive chat",
      "auto-completion",
      "no Python needed"
    ]
  },
  {
    "title": "ollama-copilot (github)",
    "url": "https://github.com/ollama-copilot/ollama-copilot",
    "summary": "VS Code extension that turns any Ollama model into a GitHub-Copilot-like inline code assistant.",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "inline completions",
      "FIM templates",
      "configurable model",
      "status-bar toggle"
    ]
  },
  {
    "title": "ollama4j (Java)",
    "url": "https://github.com/ollama4j/ollama4j",
    "summary": "Java/Kotlin SDK for Ollama\u2014sync/async chat, generate, pull, list, embeddings and vision endpoints.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "Java 8+",
      "Kotlin DSL",
      "Spring Boot starter",
      "reactive streams"
    ]
  },
  {
    "title": "ollama-rag (langchain example)",
    "url": "https://github.com/langchain-ai/rag-ollama",
    "summary": "Template repo showing retrieval-augmented generation with Ollama, LangChain, Chroma and Streamlit.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "Chroma DB",
      "Streamlit UI",
      "PDF ingestion",
      "docker compose"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/ollama-helm/ollama-helm",
    "summary": "Helm chart to deploy Ollama on Kubernetes with GPU node-selector, PVC and horizontal scaling.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "GPU support",
      "PVC caching",
      "HPA",
      "configmaps"
    ]
  },
  {
    "title": "ollama-codex.nvim",
    "url": "https://github.com/ollama-codex/nvim",
    "summary": "Neovim plugin for inline code generation using Ollama models; supports FIM and custom prompts.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "Lua config",
      "FIM tokens",
      "async non-blocking",
      "Telescope picker"
    ]
  },
  {
    "title": "ollama-docker (official)",
    "url": "https://github.com/ollama/ollama/tree/main/docker",
    "summary": "Official Docker image with CUDA and ROCm variants; one-command containerised GPU inference.",
    "source": "github",
    "date": "2024-05-13",
    "highlights": [
      "CUDA 12",
      "ROCm",
      "multi-arch",
      "rootless"
    ]
  },
  {
    "title": "ollama-express",
    "url": "https://github.com/ollama-express/ollama-express",
    "summary": "Express.js middleware that exposes authenticated REST endpoints over Ollama for multi-tenant SaaS.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "JWT auth",
      "rate limits",
      "model quotas",
      "OpenAI-compatible"
    ]
  },
  {
    "title": "ollama-gradio",
    "url": "https://github.com/ollama-gradio/ollama-gradio",
    "summary": "Gradio UI component that wraps Ollama for quick Hugging Face Spaces demos and model comparison.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "Spaces ready",
      "side-by-side",
      "parameter sliders",
      "chat history"
    ]
  },
  {
    "title": "ollama-csharp (.NET)",
    "url": "https://github.com/ollama-csharp/ollama-csharp",
    "summary": ".NET 8 SDK for Ollama with async streams, dependency injection and minimal API integration.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "C# 12",
      "IAsyncEnumerable",
      "DI extensions",
      "Blazor sample"
    ]
  },
  {
    "title": "ollama-rust",
    "url": "https://github.com/ollama-rust/ollama-rust",
    "summary": "Rust crate providing strongly-typed async client for Ollama using reqwest and tokio.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "tokio",
      "Serde",
      "no-std opt",
      "examples"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/ollama-haystack/ollama-haystack",
    "summary": "Haystack integration to use Ollama models as generators or embedders in deepset pipelines.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "PromptNode",
      "embeddings",
      "pipelines",
      "YAML config"
    ]
  },
  {
    "title": "ollama-discord",
    "url": "https://github.com/ollama-discord/ollama-discord",
    "summary": "Self-hosted Discord bot that streams Ollama replies, supports slash commands and model switching per guild.",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "slash commands",
      "streaming",
      "guild configs",
      "role gating"
    ]
  },
  {
    "title": "ollama-slack",
    "url": "https://github.com/ollama-slack/ollama-slack",
    "summary": "Slack Bolt app that brings Ollama models into channels/DMs with thread support and rate limiting.",
    "source": "github",
    "date": "2024-05-04",
    "highlights": [
      "Bolt JS",
      "threads",
      "rate limit",
      "app home"
    ]
  },
  {
    "title": "ollama-obsidian",
    "url": "https://github.com/ollama-obsidian/ollama-obsidian",
    "summary": "Obsidian plugin for local AI note assistance\u2014summaries, Q&A and brainstorming powered by Ollama.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "local LLM",
      "command palette",
      "template prompts",
      "offline"
    ]
  }
]