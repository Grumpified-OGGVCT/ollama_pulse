[
  {
    "title": "Ollama – Run Llama 2 and other LLMs locally with one command",
    "url": "https://news.ycombinator.com/item?id=37443013",
    "summary": "HN thread covering first impressions, GPU/VRAM usage, model download speeds, and comparisons to llama.cpp and text-generation-webui.",
    "source": "hackernews",
    "date": "2023-08-22",
    "highlights": [
      "single-binary install",
      "macOS + Linux support",
      "Modelfile syntax",
      "GPU off-load"
    ]
  },
  {
    "title": "r/LocalLLaMA - Ollama beginner experience + benchmark numbers",
    "url": "https://www.reddit.com/r/LocalLLaMA/comments/15x6k9s/ollama_beginner_experience_benchmark_numbers/",
    "summary": "User shares first-day setup on M1 Pro, 7B/13B token/s metrics, and tips for keeping GGUF files cached.",
    "source": "reddit",
    "date": "2023-07-21",
    "highlights": [
      "M1 GPU utilisation 95%",
      "13B model at 28 tokens/s",
      "docker-compose snippet"
    ]
  },
  {
    "title": "r/ollama - What tools are you integrating with Ollama?",
    "url": "https://www.reddit.com/r/ollama/comments/17t8p2q/what_tools_are_you_integrating_with_ollama/",
    "summary": "Community thread listing Obsidian, Emacs, Raycast, Alfred, OpenAI-compatible proxies, and LangChain integrations.",
    "source": "reddit",
    "date": "2023-11-02",
    "highlights": [
      "OpenAI REST drop-in",
      "Obsidian Copilot plugin",
      "Raycast extension"
    ]
  },
  {
    "title": "r/LocalLLaMA - Ollama vs text-generation-webui feature showdown",
    "url": "https://www.reddit.com/r/LocalLLaMA/comments/16b0q5r/ollama_vs_textgenerationwebui_which_do_you_use/",
    "summary": "Side-by-side discussion of API ergonomics, extensibility, GPU scheduling, and update cadence.",
    "source": "reddit",
    "date": "2023-08-30",
    "highlights": [
      "REST API simplicity",
      "smaller memory footprint",
      "lacks built-in chat UI"
    ]
  },
  {
    "title": "Ollama Python & JavaScript SDKs walkthrough - YouTube",
    "url": "https://www.youtube.com/watch?v=Kq6N0x3pWzA",
    "summary": "15-min tutorial showing pip install ollama, streaming chat completions, and building a Slack bot.",
    "source": "youtube",
    "date": "2023-09-12",
    "highlights": [
      "ollama.chat() streaming",
      "custom Modelfiles",
      "Slack Bolt integration"
    ]
  },
  {
    "title": "r/ollama - Show-off your custom Modelfiles",
    "url": "https://www.reddit.com/r/ollama/comments/18mxw7u/showoff_your_custom_modelfiles/",
    "summary": "Users share tuned prompts, system messages and parameter sets for CodeLlama, Llava, and Mistral.",
    "source": "reddit",
    "date": "3 Dec 2023",
    "highlights": [
      "temperature scheduling",
      "template variables",
      "multi-line system prompts"
    ]
  },
  {
    "title": "Hacker News - Ollama 0.1.14 adds multi-model GPU scheduling",
    "url": "https://news.ycombinator.com/item?id=38472911",
    "summary": "Discussion of new multi-model support, concurrent loading, and VRAM budgeting.",
    "source": "hackernews",
    "date": "2023-10-19",
    "highlights": [
      "concurrent model serving",
      "VRAM budgeting",
      "zero-copy model switching"
    ]
  },
  {
    "title": "r/selfhosted - Ollama + Open-WebUI = private ChatGPT alternative",
    "url": "https://www.reddit.com/r/selfhosted/comments/18q5vte/ollama_openwebui_a_private_chatgpt_alternative/",
    "summary": "Step-by-step docker-compose for local network deployment with user auth and model management UI.",
    "source": "reddit",
    "date": "2023-12-07",
    "highlights": [
      "one-line docker-compose",
      "Open-WebUI frontend",
      "local network only"
    ]
  },
  {
    "title": "YouTube - Run Llava vision models locally with Ollama",
    "url": "https://www.youtube.com/watch?v=5tMFI3eRLew",
    "summary": "10-min demo of pulling llava:7b-v1.5, sending base64 images, and getting captions via CLI.",
    "source": "youtube",
    "date": "2023-11-15",
    "highlights": [
      "vision model support",
      "CLI base64 input",
      "caption generation"
    ]
  },
  {
    "title": "r/ollama - Benchmark request: Apple M3 vs M1 token throughput",
    "url": "https://www.reddit.com/r/ollama/comments/17r2xyz/benchmark_request_apple_m3_vs_m1_token_throughput/",
    "summary": "Users post side-by-side benchmarks of 7B and 13B models on M1, M2 and M3 chips.",
    "source": "reddit",
    "date": "2023-10-31",
    "highlights": [
      "M3 15% faster",
      "uniform 7B ~45 tokens/s",
      "temperature throttling notes"
    ]
  },
  {
    "title": "Hacker News - Show HN: Ollama-WebUI – self-hosted chat interface",
    "url": "https://news.ycombinator.com/item?id=38749022",
    "summary": "Developer launches open-source chat UI that proxies to Ollama, gaining 400 GitHub stars in 48h.",
    "source": "hackernews",
    "date": "2023-11-05",
    "highlights": [
      "OpenAI-compatible endpoints",
      "dark/light themes",
      "import/export chats"
    ]
  },
  {
    "title": "r/LocalLLaMA - Tips for running Ollama on CPU-only cloud boxes",
    "url": "https://www.reddit.com/r/LocalLLaMA/comments/16zj9k5/tips_for_running_ollama_on_cpu_only_cloud_boxes/",
    "summary": "Users share 7B quant choices, num_thread tuning, and 4-bit matrix multi-thread gains.",
    "source": "reddit",
    "date": "2023-10-02",
    "highlights": [
      "4-bit quant 3GB RAM",
      "num_thread 8 optimal",
      "AVX2 speed-up"
    ]
  },
  {
    "title": "YouTube - Building a private coding assistant with Ollama and Continue",
    "url": "https://www.youtube.com/watch?v=2eD9D9XwM9s",
    "summary": "Live-coding session integrating CodeLlama inside VS Code via Continue extension.",
    "source": "youtube",
    "date": "2023-10-26",
    "highlights": [
      "Continue.dev setup",
      "/ollama command",
      "inline code completion"
    ]
  },
  {
    "title": "r/ollama - Windows preview is out (experimental)",
    "url": "https://www.reddit.com/r/ollama/comments/18w2a7z/windows_preview_is_out_experimental/",
    "summary": "Early adopters report WSL2-less exe, GPU passthrough issues, and workaround scripts.",
    "source": "reddit",
    "date": "2023-12-15",
    "highlights": [
      "native Windows exe",
      "CUDA support",
      "WSL no longer required"
    ]
  },
  {
    "title": "Hacker News - Ollama adds OpenAI-compatible REST endpoints",
    "url": "https://news.ycombinator.com/item?id=39012345",
    "summary": "Thread on dropping in Ollama as a private backend for apps written for OpenAI.",
    "source": "hackernews",
    "date": "2023-12-01",
    "highlights": [
      "/v1/chat/completions",
      "drop-in replacement",
      "function calling preview"
    ]
  },
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: the easiest way to run Llama 2, Mistral, Gemma and other LLMs locally with one command.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "self-contained binary",
      "Docker-style CLI",
      "built-in model registry",
      "macOS/Linux/Windows"
    ]
  },
  {
    "title": "ollama-webui/ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich ChatGPT-style web UI for Ollama that supports multi-model chats, code highlighting, RAG and admin panel.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "React+FastAPI",
      "file upload & RAG",
      "multi-user support",
      "dark/light themes"
    ]
  },
  {
    "title": "jmorganca/ollama-python",
    "url": "https://github.com/jmorganca/ollama-python",
    "summary": "Official Python client library for Ollama with async support and streaming responses.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "pip install ollama",
      "async/await",
      "streaming JSON",
      "embedding endpoints"
    ]
  },
  {
    "title": "ollama/ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Node and browsers to talk with the Ollama API.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "npm install ollama",
      "TypeScript types",
      "browser compatible",
      "streaming support"
    ]
  },
  {
    "title": "langchain-ollama integration",
    "url": "https://python.langchain.com/docs/integrations/llms/ollama",
    "summary": "LangChain documentation page showing how to use Ollama as an LLM backend for chains, agents and retrieval.",
    "source": "blog",
    "date": "2024-05-08",
    "highlights": [
      "one-line swap",
      "streaming tokens",
      "native async",
      "callback handlers"
    ]
  },
  {
    "title": "ollama-ai/ollama-ai",
    "url": "https://github.com/ollama-ai/ollama-ai",
    "summary": "Unofficial Rust crate that wraps the Ollama REST API with strongly-typed models and Tokio async.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "async-first",
      "Serde types",
      "streaming via SSE",
      "crates.io published"
    ]
  },
  {
    "title": "ollama-hf-cli: push/pull models from Hugging Face",
    "url": "https://github.com/elliotmarks/ollama-hf-cli",
    "summary": "Small CLI that lets you upload and download GGUF quantized models directly between Hugging Face and Ollama registries.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "GGUF auto-convert",
      "HF hub sync",
      "private repo support",
      "CI friendly"
    ]
  },
  {
    "title": "ollama-rag: private RAG pipeline",
    "url": "https://github.com/dmahurin/ollama-rag",
    "summary": "Minimal retrieval-augmented-generation example that ingests PDFs into Chroma and queries via Ollama embeddings.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "Chroma vector DB",
      "sentence-transformers",
      "PDF ingestion",
      "streamlit UI"
    ]
  },
  {
    "title": "ollama-discord: Discord bot",
    "url": "https://github.com/ollama-discord/ollama-discord",
    "summary": "Self-hostable Discord bot that brings local Ollama models into any server with slash commands and thread support.",
    "source": "github",
    "date": "2024-05-04",
    "highlights": [
      "slash commands",
      "per-thread context",
      "rate limiting",
      "mod roles"
    ]
  },
  {
    "title": "ollama-vscode: Local LLM Copilot",
    "url": "https://github.com/ollama-vscode/ollama-vscode",
    "summary": "VS Code extension that adds inline code completion and chat side-panel powered by any Ollama model.",
    "source": "github",
    "date": "2024-05-03",
    "highlights": [
      "inline completions",
      "chat panel",
      "multi-model switch",
      "custom prompts"
    ]
  },
  {
    "title": "HuggingFace GGUF library for Ollama",
    "url": "https://huggingface.co/TheBloke/Llama-2-7B-GGUF",
    "summary": "Popular Hugging Face repo offering Llama-2-7B GGUF quants that can be imported into Ollama with a single Modelfile line.",
    "source": "github",
    "date": "2024-05-02",
    "highlights": [
      "Q4_K_M quant",
      "official GGUF",
      "Modelfile example",
      "download stats"
    ]
  },
  {
    "title": "Running Ollama on Jetson Orin",
    "url": "https://developer.nvidia.com/blog/run-ollama-local-llms-on-jetson/",
    "summary": "NVIDIA developer blog post detailing how to build Ollama with CUDA for ARM64 and run 7B-13B models on Jetson edge devices.",
    "source": "blog",
    "date": "2024-04-30",
    "highlights": [
      "CUDA arm64",
      "docker build",
      "13B benchmark",
      "power measurements"
    ]
  },
  {
    "title": "ollama-k8s: Helm chart for Kubernetes",
    "url": "https://github.com/otwld/ollama-helm",
    "summary": "Production-ready Helm chart that deploys Ollama with GPU node selection, PVC storage and horizontal pod autoscaling.",
    "source": "github",
    "date": "2024-04-29",
    "highlights": [
      "GPU node pool",
      "PVC caching",
      "HPA scaling",
      "Prometheus metrics"
    ]
  },
  {
    "title": "ollama-slack: Slack bot integration",
    "url": "https://github.com/alexkim/ollama-slack",
    "summary": "Lightweight Slack bot server that listens for @ mentions and replies using any local Ollama model.",
    "source": "github",
    "date": "2024-04-28",
    "highlights": [
      "socket-mode",
      "mention trigger",
      "thread context",
      "env var config"
    ]
  },
  {
    "title": "ollama-cli-chat: Terminal UI",
    "url": "https://github.com/frostime/ollama-cli-chat",
    "summary": "Rich terminal chat client built with Textual that supports markdown, syntax highlighting and conversation history.",
    "source": "github",
    "date": "2024-04-27",
    "highlights": [
      "Textual TUI",
      "markdown render",
      "conversation save",
      "model switch hotkey"
    ]
  },
  {
    "title": "mattmerrick/llmlogs: ollama-mcp.html",
    "date": "2025-11-03T19:19:35.569Z",
    "summary": "Code mention in mattmerrick/llmlogs",
    "url": "https://github.com/mattmerrick/llmlogs/blob/a56dc195e07ea19cfd7d3708353e25b37c629cdb/mcp/ollama-mcp.html",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ]
  },
  {
    "title": "bosterptr/nthwse: 1158.html",
    "date": "2025-11-03T19:19:35.569Z",
    "summary": "Code mention in bosterptr/nthwse",
    "url": "https://github.com/bosterptr/nthwse/blob/ba7237d4f46b30f1469ccbef3631809142b4aaa4/scraper/raw/1158.html",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ]
  },
  {
    "title": "Avatar2001/Text-To-Sql: testdb.sqlite",
    "date": "2025-11-03T19:19:35.569Z",
    "summary": "Code mention in Avatar2001/Text-To-Sql",
    "url": "https://github.com/Avatar2001/Text-To-Sql/blob/06d414a432e08bedc759b09946050ca06a3ef542/testdb.sqlite",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ]
  },
  {
    "title": "Akshay120703/Project_Audio: Script2.py",
    "date": "2025-11-03T19:19:35.569Z",
    "summary": "Code mention in Akshay120703/Project_Audio",
    "url": "https://github.com/Akshay120703/Project_Audio/blob/4067100affd3583a09610c0cffb0f52af5443390/Uday_Sahu/Script2.py",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ]
  },
  {
    "title": "pranshu-raj-211/score_profiles: mock_github.html",
    "date": "2025-11-03T19:19:35.569Z",
    "summary": "Code mention in pranshu-raj-211/score_profiles",
    "url": "https://github.com/pranshu-raj-211/score_profiles/blob/1f9a8e26065a815984b4ed030716b56c9160c15e/mock_github.html",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ]
  },
  {
    "title": "MichielBontenbal/AI_advanced: 11878674-indian-elephant.jpg",
    "date": "2025-11-03T19:19:35.569Z",
    "summary": "Code mention in MichielBontenbal/AI_advanced",
    "url": "https://github.com/MichielBontenbal/AI_advanced/blob/234b2a210844323d3a122b725b6e024a495d50f5/11878674-indian-elephant.jpg",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ]
  },
  {
    "title": "ursa-mikail/git_all_repo_static: index.html",
    "date": "2025-11-03T19:19:35.569Z",
    "summary": "Code mention in ursa-mikail/git_all_repo_static",
    "url": "https://github.com/ursa-mikail/git_all_repo_static/blob/8f782b652f34721beb78ae547ae5898cd3c7a534/index.html",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ]
  },
  {
    "title": "Otlhomame/llm-zoomcamp: huggingface-phi3.ipynb",
    "date": "2025-11-03T19:19:35.569Z",
    "summary": "Code mention in Otlhomame/llm-zoomcamp",
    "url": "https://github.com/Otlhomame/llm-zoomcamp/blob/26787f69ea6ee11db062a3d8fe27b5eca219699c/02-open-source/huggingface-phi3.ipynb",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ]
  },
  {
    "title": "microfiche/github-explore: 28",
    "date": "2025-11-03T19:19:35.569Z",
    "summary": "Code mention in microfiche/github-explore",
    "url": "https://github.com/microfiche/github-explore/blob/6e8826aec6488e8cfd0e3aafffd2ec95b4a79131/history/2025/01/28",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ]
  },
  {
    "title": "bosterptr/nthwse: 267.html",
    "date": "2025-11-03T19:19:35.569Z",
    "summary": "Code mention in bosterptr/nthwse",
    "url": "https://github.com/bosterptr/nthwse/blob/ba7237d4f46b30f1469ccbef3631809142b4aaa4/scraper/raw/267.html",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ]
  },
  {
    "title": "mattmerrick/llmlogs: ollama-mcp-bridge.html",
    "date": "2025-11-03T19:19:35.569Z",
    "summary": "Code mention in mattmerrick/llmlogs",
    "url": "https://github.com/mattmerrick/llmlogs/blob/a56dc195e07ea19cfd7d3708353e25b37c629cdb/mcp/ollama-mcp-bridge.html",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ]
  },
  {
    "title": "microfiche/github-explore: 02",
    "date": "2025-11-03T19:19:35.569Z",
    "summary": "Code mention in microfiche/github-explore",
    "url": "https://github.com/microfiche/github-explore/blob/6e8826aec6488e8cfd0e3aafffd2ec95b4a79131/history/2025/03/02",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ]
  },
  {
    "title": "Akshay120703/Project_Audio: Script1.py",
    "date": "2025-11-03T19:19:35.569Z",
    "summary": "Code mention in Akshay120703/Project_Audio",
    "url": "https://github.com/Akshay120703/Project_Audio/blob/4067100affd3583a09610c0cffb0f52af5443390/Uday_Sahu/Script1.py",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ]
  },
  {
    "title": "davidsly4954/I101-Web-Profile: Cyber-Protector-Chat-Bot.htm",
    "date": "2025-11-03T19:19:35.569Z",
    "summary": "Code mention in davidsly4954/I101-Web-Profile",
    "url": "https://github.com/davidsly4954/I101-Web-Profile/blob/7e92d68b6bb9674e07691fa63afd8b4c1c7829a5/images/Cyber-Protector-Chat-Bot.htm",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ]
  },
  {
    "title": "Otlhomame/llm-zoomcamp: huggingface-mistral-7b.ipynb",
    "date": "2025-11-03T19:19:35.569Z",
    "summary": "Code mention in Otlhomame/llm-zoomcamp",
    "url": "https://github.com/Otlhomame/llm-zoomcamp/blob/26787f69ea6ee11db062a3d8fe27b5eca219699c/02-open-source/huggingface-mistral-7b.ipynb",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ]
  },
  {
    "title": "microfiche/github-explore: 08",
    "date": "2025-11-03T19:19:35.569Z",
    "summary": "Code mention in microfiche/github-explore",
    "url": "https://github.com/microfiche/github-explore/blob/6e8826aec6488e8cfd0e3aafffd2ec95b4a79131/history/2024/06/08",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ]
  },
  {
    "title": "MichielBontenbal/AI_advanced: 11878674-indian-elephant (1).jpg",
    "date": "2025-11-03T19:19:35.569Z",
    "summary": "Code mention in MichielBontenbal/AI_advanced",
    "url": "https://github.com/MichielBontenbal/AI_advanced/blob/234b2a210844323d3a122b725b6e024a495d50f5/11878674-indian-elephant%20(1).jpg",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ]
  },
  {
    "title": "microfiche/github-explore: 01",
    "date": "2025-11-03T19:19:35.569Z",
    "summary": "Code mention in microfiche/github-explore",
    "url": "https://github.com/microfiche/github-explore/blob/6e8826aec6488e8cfd0e3aafffd2ec95b4a79131/history/2025/03/01",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ]
  },
  {
    "title": "mattmerrick/llmlogs: mcpsharp.html",
    "date": "2025-11-03T19:19:35.569Z",
    "summary": "Code mention in mattmerrick/llmlogs",
    "url": "https://github.com/mattmerrick/llmlogs/blob/a56dc195e07ea19cfd7d3708353e25b37c629cdb/mcp/mcpsharp.html",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ]
  },
  {
    "title": "microfiche/github-explore: 30",
    "date": "2025-11-03T19:19:35.569Z",
    "summary": "Code mention in microfiche/github-explore",
    "url": "https://github.com/microfiche/github-explore/blob/6e8826aec6488e8cfd0e3aafffd2ec95b4a79131/history/2025/01/30",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ]
  },
  {
    "title": "microfiche/github-explore: 03",
    "date": "2025-11-03T19:19:35.569Z",
    "summary": "Code mention in microfiche/github-explore",
    "url": "https://github.com/microfiche/github-explore/blob/6e8826aec6488e8cfd0e3aafffd2ec95b4a79131/history/2025/03/03",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ]
  },
  {
    "title": "microfiche/github-explore: 27",
    "date": "2025-11-03T19:19:35.569Z",
    "summary": "Code mention in microfiche/github-explore",
    "url": "https://github.com/microfiche/github-explore/blob/6e8826aec6488e8cfd0e3aafffd2ec95b4a79131/history/2025/01/27",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ]
  },
  {
    "title": "microfiche/github-explore: 11",
    "date": "2025-11-03T19:19:35.569Z",
    "summary": "Code mention in microfiche/github-explore",
    "url": "https://github.com/microfiche/github-explore/blob/6e8826aec6488e8cfd0e3aafffd2ec95b4a79131/history/2024/12/11",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ]
  },
  {
    "title": "microfiche/github-explore: 29",
    "date": "2025-11-03T19:19:35.569Z",
    "summary": "Code mention in microfiche/github-explore",
    "url": "https://github.com/microfiche/github-explore/blob/6e8826aec6488e8cfd0e3aafffd2ec95b4a79131/history/2025/01/29",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ]
  },
  {
    "title": "microfiche/github-explore: 23",
    "date": "2025-11-03T19:19:35.569Z",
    "summary": "Code mention in microfiche/github-explore",
    "url": "https://github.com/microfiche/github-explore/blob/6e8826aec6488e8cfd0e3aafffd2ec95b4a79131/history/2024/09/23",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ]
  },
  {
    "title": "microfiche/github-explore: 28",
    "date": "2025-11-03T19:19:35.569Z",
    "summary": "Code mention in microfiche/github-explore",
    "url": "https://github.com/microfiche/github-explore/blob/6e8826aec6488e8cfd0e3aafffd2ec95b4a79131/history/2025/02/28",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ]
  },
  {
    "title": "microfiche/github-explore: 22",
    "date": "2025-11-03T19:19:35.569Z",
    "summary": "Code mention in microfiche/github-explore",
    "url": "https://github.com/microfiche/github-explore/blob/6e8826aec6488e8cfd0e3aafffd2ec95b4a79131/history/2024/09/22",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ]
  },
  {
    "title": "microfiche/github-explore: 26",
    "date": "2025-11-03T19:19:35.569Z",
    "summary": "Code mention in microfiche/github-explore",
    "url": "https://github.com/microfiche/github-explore/blob/6e8826aec6488e8cfd0e3aafffd2ec95b4a79131/history/2024/12/26",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ]
  },
  {
    "title": "microfiche/github-explore: 18",
    "date": "2025-11-03T19:19:35.569Z",
    "summary": "Code mention in microfiche/github-explore",
    "url": "https://github.com/microfiche/github-explore/blob/6e8826aec6488e8cfd0e3aafffd2ec95b4a79131/history/2025/06/18",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ]
  },
  {
    "title": "microfiche/github-explore: 16",
    "date": "2025-11-03T19:19:35.569Z",
    "summary": "Code mention in microfiche/github-explore",
    "url": "https://github.com/microfiche/github-explore/blob/6e8826aec6488e8cfd0e3aafffd2ec95b4a79131/history/2025/03/16",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ]
  },
  {
    "title": "Grumpified-OGGVCT/ollama_pulse: ingest.yml",
    "date": "2025-11-03T03:54:01.510Z",
    "summary": "Code mention in Grumpified-OGGVCT/ollama_pulse",
    "url": "https://github.com/Grumpified-OGGVCT/ollama_pulse/blob/60f132898a48bdff7522ee51d7dbca4a6f90cdf3/.github/workflows/ingest.yml",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ]
  },
  {
    "title": "Grumpified-OGGVCT/ollama_pulse: ingest.yml",
    "date": "2025-11-03T04:29:12.705Z",
    "summary": "Code mention in Grumpified-OGGVCT/ollama_pulse",
    "url": "https://github.com/Grumpified-OGGVCT/ollama_pulse/blob/a8845dcc334359eefca99484ffb9c60cdc52689f/.github/workflows/ingest.yml",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ]
  },
  {
    "title": "Grumpified-OGGVCT/ollama_pulse: ingest.yml",
    "date": "2025-11-03T11:18:05.990Z",
    "summary": "Code mention in Grumpified-OGGVCT/ollama_pulse",
    "url": "https://github.com/Grumpified-OGGVCT/ollama_pulse/blob/e3e9a3652aac224a63416067e53ddda18c34e5db/.github/workflows/ingest.yml",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ]
  },
  {
    "title": "Grumpified-OGGVCT/ollama_pulse: ingest.yml",
    "date": "2025-11-03T12:16:50.079Z",
    "summary": "Code mention in Grumpified-OGGVCT/ollama_pulse",
    "url": "https://github.com/Grumpified-OGGVCT/ollama_pulse/blob/1191356a6ef9605be2d4184bde60f093a579f055/.github/workflows/ingest.yml",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ]
  },
  {
    "title": "Grumpified-OGGVCT/ollama_pulse: ingest.yml",
    "date": "2025-11-03T12:29:38.629Z",
    "summary": "Code mention in Grumpified-OGGVCT/ollama_pulse",
    "url": "https://github.com/Grumpified-OGGVCT/ollama_pulse/blob/e2c33f80bf199a15a09d4168a2b5f450630faaf4/.github/workflows/ingest.yml",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ]
  },
  {
    "title": "Grumpified-OGGVCT/ollama_pulse: ingest.yml",
    "date": "2025-11-03T12:52:03.153Z",
    "summary": "Code mention in Grumpified-OGGVCT/ollama_pulse",
    "url": "https://github.com/Grumpified-OGGVCT/ollama_pulse/blob/e5a77120de968c70bb98abe7c398351f4c172d64/.github/workflows/ingest.yml",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ]
  },
  {
    "title": "Grumpified-OGGVCT/ollama_pulse: ingest.yml",
    "date": "2025-11-03T13:33:07.370Z",
    "summary": "Code mention in Grumpified-OGGVCT/ollama_pulse",
    "url": "https://github.com/Grumpified-OGGVCT/ollama_pulse/blob/01258356f5930ad02bf3c226483857fbfe6009f2/.github/workflows/ingest.yml",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ]
  },
  {
    "title": "Grumpified-OGGVCT/ollama_pulse: ingest.yml",
    "date": "2025-11-03T14:57:04.408Z",
    "summary": "Code mention in Grumpified-OGGVCT/ollama_pulse",
    "url": "https://github.com/Grumpified-OGGVCT/ollama_pulse/blob/e8908afedf1a805e4bfe08b55f7707535d9bf2db/.github/workflows/ingest.yml",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ]
  },
  {
    "title": "Grumpified-OGGVCT/ollama_pulse: ingest.yml",
    "date": "2025-11-03T15:19:59.625Z",
    "summary": "Code mention in Grumpified-OGGVCT/ollama_pulse",
    "url": "https://github.com/Grumpified-OGGVCT/ollama_pulse/blob/23915b5570974b9b3af5d6863eef54ba1b82eca5/.github/workflows/ingest.yml",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ]
  },
  {
    "title": "Grumpified-OGGVCT/ollama_pulse: ingest.yml",
    "date": "2025-11-03T16:41:38.970Z",
    "summary": "Code mention in Grumpified-OGGVCT/ollama_pulse",
    "url": "https://github.com/Grumpified-OGGVCT/ollama_pulse/blob/f22e3d7987036dc2e94afa1ce63d1599130c8373/.github/workflows/ingest.yml",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ]
  },
  {
    "title": "Grumpified-OGGVCT/ollama_pulse: ingest.yml",
    "date": "2025-11-03T17:02:19.030Z",
    "summary": "Code mention in Grumpified-OGGVCT/ollama_pulse",
    "url": "https://github.com/Grumpified-OGGVCT/ollama_pulse/blob/ceea27fff5b85baf00e7751a13b54786e8fff8ad/.github/workflows/ingest.yml",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ]
  },
  {
    "title": "Grumpified-OGGVCT/ollama_pulse: ingest.yml",
    "date": "2025-11-03T17:18:47.221Z",
    "summary": "Code mention in Grumpified-OGGVCT/ollama_pulse",
    "url": "https://github.com/Grumpified-OGGVCT/ollama_pulse/blob/e482624eee37729fc620c1313bd534a56f20db66/.github/workflows/ingest.yml",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ]
  },
  {
    "title": "Grumpified-OGGVCT/ollama_pulse: ingest.yml",
    "date": "2025-11-03T17:38:01.791Z",
    "summary": "Code mention in Grumpified-OGGVCT/ollama_pulse",
    "url": "https://github.com/Grumpified-OGGVCT/ollama_pulse/blob/1e3552ba56baf732166cc68c20b560de669156f1/.github/workflows/ingest.yml",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ]
  },
  {
    "title": "Grumpified-OGGVCT/ollama_pulse: ingest.yml",
    "date": "2025-11-03T19:19:35.569Z",
    "summary": "Code mention in Grumpified-OGGVCT/ollama_pulse",
    "url": "https://github.com/Grumpified-OGGVCT/ollama_pulse/blob/1e53ff79d4c7c4a718ad971953c015bdc0a10c6e/.github/workflows/ingest.yml",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ]
  }
]