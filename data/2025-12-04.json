[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: get up and running with Llama 2, Mistral, Gemma, and other large language models locally.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "self-hosted LLM inference",
      "Docker images",
      "REST & CLI APIs"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Ollama, published on npm as \u2018ollama\u2019.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "Promise-based API",
      "Node & browser support",
      "full type definitions"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client for Ollama, available on PyPI as \u2018ollama\u2019.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "sync & async APIs",
      "streaming support",
      "PyPI package"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/partners/ollama",
    "summary": "LangChain integration package (langchain-ollama on PyPI) for using Ollama models in LangChain pipelines.",
    "source": "github",
    "date": "2024-05-13",
    "highlights": [
      "chat & embed models",
      "tool calling",
      "chain orchestration"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich web UI for Ollama (ChatGPT-style interface) with user auth, model management, and RAG.",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "dark/light themes",
      "document upload",
      "multi-user support"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/ollama/ollama-cli",
    "summary": "Community-built interactive CLI that wraps Ollama with chat history, syntax highlighting, and prompts.",
    "source": "github",
    "date": "2024-04-28",
    "highlights": [
      "readline history",
      "markdown rendering",
      "configurable prompts"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama/ollama-copilot",
    "summary": "VS Code extension that brings Ollama-powered code completion and inline chat into the editor.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "inline suggestions",
      "customizable models",
      "open-source Copilot alternative"
    ]
  },
  {
    "title": "ollama-rag",
    "url": "https://github.com/ggerganov/ollama-rag",
    "summary": "Lightweight RAG template using Ollama for embeddings and generation, with Chroma vector store.",
    "source": "github",
    "date": "2024-04-30",
    "highlights": [
      "PDF ingestion",
      "semantic search",
      "streamed answers"
    ]
  },
  {
    "title": "ollama-nvim",
    "url": "https://github.com/nanotee/ollama-nvim",
    "summary": "Neovim plugin to query Ollama models directly from the editor with customizable prompts.",
    "source": "github",
    "date": "2024-05-01",
    "highlights": [
      "Lua config",
      "keymap support",
      "selection-to-prompt"
    ]
  },
  {
    "title": "ollama-streamlit",
    "url": "https://github.com/streamlit/ollama-streamlit",
    "summary": "Streamlit chat app template that connects to local Ollama instance for quick prototyping.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "session memory",
      "model switcher",
      "one-click deploy"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/ollama-helm/ollama-helm",
    "summary": "Helm chart to deploy Ollama on Kubernetes with GPU node selection and horizontal scaling.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "GPU support",
      "PVC storage",
      "autoscaling"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/deepset-ai/haystack-ollama",
    "summary": "Haystack integration enabling Ollama models as Generators or Embedders in Haystack pipelines.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "pipeline nodes",
      "batch inference",
      "open-source"
    ]
  },
  {
    "title": "ollama-rust",
    "url": "https://github.com/ollama-rs/ollama-rs",
    "summary": "Rust crate providing typed async bindings to the Ollama REST API with serde models.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "tokio client",
      "strong typing",
      "crates.io release"
    ]
  },
  {
    "title": "ollama-go",
    "url": "https://github.com/ollama-go/ollama-go",
    "summary": "Go client library for Ollama with context cancellation and streaming support.",
    "source": "github",
    "date": "2024-05-04",
    "highlights": [
      "idiomatic Go",
      "streaming",
      "modular API"
    ]
  },
  {
    "title": "ollama-discord-bot",
    "url": "https://github.com/ollama-discord/ollama-discord-bot",
    "summary": "Self-hosted Discord bot that lets servers chat with any Ollama model via slash commands.",
    "source": "github",
    "date": "2024-05-03",
    "highlights": [
      "guild isolation",
      "rate limiting",
      "custom prefixes"
    ]
  },
  {
    "title": "ollama-django",
    "url": "https://github.com/ollama-django/ollama-django",
    "summary": "Reusable Django app adding Ollama chat endpoints and admin UI for model management.",
    "source": "github",
    "date": "2024-04-29",
    "highlights": [
      "DRF serializers",
      "caching",
      "admin integration"
    ]
  },
  {
    "title": "ollama-slackbot",
    "url": "https://github.com/ollama-slack/ollama-slackbot",
    "summary": "Slack Bolt app that threads Ollama responses and supports @ mentions and DM chats.",
    "source": "github",
    "date": "2024-05-02",
    "highlights": [
      "threading",
      "emoji reactions",
      "easy Heroku deploy"
    ]
  },
  {
    "title": "ollama-obsidian",
    "url": "https://github.com/ollama-obsidian/ollama-obsidian",
    "summary": "Obsidian plugin to run local LLM prompts on selected notes and insert generated text.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "template commands",
      "front-matter vars",
      "offline"
    ]
  }
]