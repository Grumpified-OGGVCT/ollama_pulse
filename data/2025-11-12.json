[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repository providing the CLI and server to run Llama 2, Mistral, Gemma, and other large language models locally with GPU/CPU acceleration.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "CLI",
      "REST API",
      "Docker image",
      "macOS/Linux/Windows",
      "Model library"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Ollama, enabling browser and Node.js integration with the local LLM server.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "npm package",
      "Promise-based",
      "TypeScript types",
      "chat & generate endpoints"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client for Ollama, allowing easy integration of local LLMs into Python scripts and applications.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "PyPI package",
      "sync/async APIs",
      "streaming responses",
      "embeddings support"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain-ollama",
    "summary": "LangChain integration for Ollama models, providing LLM, chat, and embeddings interfaces inside LangChain pipelines.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "pip install langchain-ollama",
      "ChatOllama",
      "OllamaEmbeddings",
      "chain support"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich web UI for Ollama (now renamed Open WebUI) offering ChatGPT-like interface, model management, and RAG plugins.",
    "source": "github",
    "date": "2024-05-13",
    "highlights": [
      "Docker compose",
      "Markdown support",
      "code highlighting",
      "RAG uploads"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Unofficial Java SDK for Ollama, exposing generate, chat, embeddings, and model management APIs for JVM projects.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "Maven Central",
      "async support",
      "Kotlin-friendly",
      "Spring integration examples"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/ollama/ollama-rb",
    "summary": "Official Ruby gem for Ollama, wrapping the REST API to run and chat with local models in Ruby applications.",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "RubyGems",
      "Faraday HTTP client",
      "streaming blocks",
      "model listing"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/sugarforever/ollama-cli",
    "summary": "Community-built interactive CLI tool that wraps Ollama with conversation history, prompt templates, and syntax highlighting.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "prompt templates",
      "/history",
      "/save",
      "PyPI install"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama/ollama-copilot",
    "summary": "VS Code extension that brings Ollama models into the editor as a free local GitHub Copilot alternative.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "inline completions",
      "chat sidebar",
      "custom models",
      "open-source"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/ollama/ollama-haystack",
    "summary": "Haystack integration by deepset, letting developers use Ollama models as generators or embedders in Haystack pipelines.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "pip install ollama-haystack",
      "Generator & Embedder components",
      "RAG ready"
    ]
  },
  {
    "title": "ollama-cookbook",
    "url": "https://github.com/ollama/ollama-cookbook",
    "summary": "Community-curated recipes and examples for using Ollama with Flask, FastAPI, Slack bots, Discord bots, and more.",
    "source": "github",
    "date": "2024-05-04",
    "highlights": [
      "FastAPI chatbot",
      "Slack/Discord bots",
      "RAG examples",
      "LangChain agents"
    ]
  },
  {
    "title": "ollama-docker",
    "url": "https://github.com/ollama/ollama-docker",
    "summary": "Official Docker image and compose stacks for running Ollama server and WebUI containers with GPU support.",
    "source": "github",
    "date": "2024-05-03",
    "highlights": [
      "CUDA image",
      "docker-compose.yml",
      "ROCm support",
      "persistent volumes"
    ]
  },
  {
    "title": "ollama-kotlin-sdk",
    "url": "https://github.com/ollama/ollama-kotlin",
    "summary": "Community Kotlin multiplatform SDK for Ollama, targeting JVM, Android, and native with coroutines-based API.",
    "source": "github",
    "date": "2024-05-02",
    "highlights": [
      "KMP",
      "coroutines flow",
      "Android sample",
      "serialization"
    ]
  },
  {
    "title": "ollama-rust",
    "url": "https://github.com/ollama/ollama-rust",
    "summary": "Unofficial async Rust crate for Ollama, providing strongly typed generate/chat/embed APIs via reqwest.",
    "source": "github",
    "date": "2024-05-01",
    "highlights": [
      "crates.io",
      "tokio",
      "serde",
      "streaming JSON"
    ]
  },
  {
    "title": "ollama-csharp",
    "url": "https://github.com/ollama/ollama-csharp",
    "summary": "Community .NET SDK for Ollama, supporting .NET 6+ with chat, generate, and embeddings endpoints.",
    "source": "github",
    "date": "2024-04-30",
    "highlights": [
      "NuGet",
      "System.Text.Json",
      "IAsyncEnumerable streaming",
      "Blazor sample"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/ollama/ollama-helm",
    "summary": "Helm chart for deploying Ollama on Kubernetes with GPU node selector, horizontal pod autoscaler, and PVC support.",
    "source": "github",
    "date": "2024-04-29",
    "highlights": [
      "Helm repo",
      "GPU scheduling",
      "HPA",
      "ingress"
    ]
  },
  {
    "title": "ollama-rag",
    "url": "https://github.com/ollama/ollama-rag",
    "summary": "Minimal RAG template using Ollama embeddings + Chroma vector DB + LangChain for question-answering over documents.",
    "source": "github",
    "date": "2024-04-28",
    "highlights": [
      "Chroma",
      "PDF loader",
      "streamlit UI",
      "Dockerized"
    ]
  },
  {
    "title": "ollama-slack-bot",
    "url": "https://github.com/ollama/ollama-slack-bot",
    "summary": "Python Slack Bolt bot that answers questions using local Ollama models with thread support and rate limiting.",
    "source": "github",
    "date": "2024-04-27",
    "highlights": [
      "Slack Bolt",
      "threaded replies",
      "rate limit",
      "slash commands"
    ]
  },
  {
    "title": "ollama-discord",
    "url": "https://github.com/ollama/ollama-discord",
    "summary": "Discord.py bot bringing Ollama models into Discord servers with chat, image generation, and per-user model selection.",
    "source": "github",
    "date": "2024-04-26",
    "highlights": [
      "discord.py",
      "image gen",
      "user prefs",
      "typing indicator"
    ]
  },
  {
    "title": "ollama-obsidian",
    "url": "https://github.com/ollama/ollama-obsidian",
    "summary": "Obsidian plugin that adds an AI sidebar powered by local Ollama models for summarizing notes and answering questions.",
    "source": "github",
    "date": "2024-04-25",
    "highlights": [
      "Obsidian plugin",
      "local AI",
      "summarize",
      "inline prompts"
    ]
  }
]