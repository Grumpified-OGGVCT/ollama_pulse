[
  {
    "title": "Which LLMs can I run locally on RTX 1080 8GB with 48GB RAM?",
    "date": "2025-11-10T15:46:14",
    "summary": "Stack Overflow question with 0 answers, 64 views",
    "url": "https://stackoverflow.com/questions/79815816/which-llms-can-i-run-locally-on-rtx-1080-8gb-with-48gb-ram",
    "source": "stackoverflow",
    "turbo_score": 0.3,
    "highlights": [
      "views: 64",
      "answers: 0",
      "score: 0",
      "tags: gpu, large-language-model, ollama"
    ]
  },
  {
    "title": "Fast, Domain-Aware BPMN Analyzer for Fintech Workflows",
    "date": "2025-11-10T14:37:15",
    "summary": "Stack Overflow question with 0 answers, 30 views",
    "url": "https://stackoverflow.com/questions/79815735/fast-domain-aware-bpmn-analyzer-for-fintech-workflows",
    "source": "stackoverflow",
    "turbo_score": 0.3,
    "highlights": [
      "views: 30",
      "answers: 0",
      "score: 0",
      "tags: java, nlp, large-language-model"
    ]
  },
  {
    "title": "Qwen 2.5 3B VLM Index error at the line trainer.train()",
    "date": "2025-11-06T14:30:18",
    "summary": "Stack Overflow question with 0 answers, 75 views",
    "url": "https://stackoverflow.com/questions/79811390/qwen-2-5-3b-vlm-index-error-at-the-line-trainer-train",
    "source": "stackoverflow",
    "turbo_score": 0.3,
    "highlights": [
      "views: 75",
      "answers: 0",
      "score: 0",
      "tags: python, large-language-model, index-error"
    ]
  },
  {
    "title": "I want to know where to locate the file I upload though the ragflow system, how to find it in the windows system",
    "date": "2025-03-19T01:22:03",
    "summary": "Stack Overflow question with 1 answers, 136 views",
    "url": "https://stackoverflow.com/questions/79518917/i-want-to-know-where-to-locate-the-file-i-upload-though-the-ragflow-system-how",
    "source": "stackoverflow",
    "turbo_score": -0.5,
    "highlights": [
      "views: 136",
      "answers: 1",
      "score: -4",
      "tags: rag"
    ]
  },
  {
    "title": "AgentWorkflow doesn't call functions when using Ollama",
    "date": "2025-10-21T08:46:28",
    "summary": "Stack Overflow question with 0 answers, 42 views",
    "url": "https://stackoverflow.com/questions/79795621/agentworkflow-doesnt-call-functions-when-using-ollama",
    "source": "stackoverflow",
    "turbo_score": 0.3,
    "highlights": [
      "views: 42",
      "answers: 0",
      "score: 0",
      "tags: python, typescript, artificial-intelligence"
    ]
  },
  {
    "title": "How do I pass an image to DSPy for analysis?",
    "date": "2025-05-28T11:28:21",
    "summary": "Stack Overflow question with 1 answers, 640 views",
    "url": "https://stackoverflow.com/questions/79642103/how-do-i-pass-an-image-to-dspy-for-analysis",
    "source": "stackoverflow",
    "turbo_score": 1.0,
    "highlights": [
      "views: 640",
      "answers: 1",
      "score: 1",
      "tags: ollama, dspy"
    ]
  },
  {
    "title": "Model not found Scrapegraph-ai",
    "date": "2024-08-12T09:32:01",
    "summary": "Stack Overflow question with 2 answers, 586 views",
    "url": "https://stackoverflow.com/questions/78860941/model-not-found-scrapegraph-ai",
    "source": "stackoverflow",
    "turbo_score": 1.0,
    "highlights": [
      "views: 586",
      "answers: 2",
      "score: 0",
      "tags: python, web-scraping, artificial-intelligence"
    ]
  },
  {
    "title": "How to stop Ollama model streaming",
    "date": "2024-07-12T23:11:33",
    "summary": "Stack Overflow question with 1 answers, 2201 views",
    "url": "https://stackoverflow.com/questions/78742490/how-to-stop-ollama-model-streaming",
    "source": "stackoverflow",
    "turbo_score": 1.0,
    "highlights": [
      "views: 2201",
      "answers: 1",
      "score: 1",
      "tags: python, websocket, fastapi"
    ]
  },
  {
    "title": "How to stream LLM responses in a Shiny app instead of waiting for full output?",
    "date": "2025-09-17T15:41:54",
    "summary": "Stack Overflow question with 1 answers, 252 views",
    "url": "https://stackoverflow.com/questions/79767548/how-to-stream-llm-responses-in-a-shiny-app-instead-of-waiting-for-full-output",
    "source": "stackoverflow",
    "turbo_score": 1.0,
    "highlights": [
      "views: 252",
      "answers: 1",
      "score: 5",
      "tags: r, shiny, large-language-model"
    ]
  },
  {
    "title": "Llama Stack Agent not invoking MCP server in Docker setup despite tool group being registered",
    "date": "2025-09-24T09:10:13",
    "summary": "Stack Overflow question with 0 answers, 73 views",
    "url": "https://stackoverflow.com/questions/79773500/llama-stack-agent-not-invoking-mcp-server-in-docker-setup-despite-tool-group-bei",
    "source": "stackoverflow",
    "turbo_score": 0.6,
    "highlights": [
      "views: 73",
      "answers: 0",
      "score: 1",
      "tags: amazon-web-services, docker, docker-compose"
    ]
  },
  {
    "title": "Running Ollama on local computer and prompting from jupyter notebook - does the model recall prior prompts like if it was the same chat?",
    "date": "2025-09-23T23:35:57",
    "summary": "Stack Overflow question with 0 answers, 33 views",
    "url": "https://stackoverflow.com/questions/79773153/running-ollama-on-local-computer-and-prompting-from-jupyter-notebook-does-the",
    "source": "stackoverflow",
    "turbo_score": 0.3,
    "highlights": [
      "views: 33",
      "answers: 0",
      "score: 0",
      "tags: large-language-model, llama, ollama"
    ]
  },
  {
    "title": "langgraph with ollama not responding with a response",
    "date": "2025-09-23T14:01:30",
    "summary": "Stack Overflow question with 0 answers, 86 views",
    "url": "https://stackoverflow.com/questions/79772697/langgraph-with-ollama-not-responding-with-a-response",
    "source": "stackoverflow",
    "turbo_score": 0.3,
    "highlights": [
      "views: 86",
      "answers: 0",
      "score: 0",
      "tags: python, langchain, ollama"
    ]
  },
  {
    "title": "Pycharm: \"Python Interpreter exited with non-zero exit code -1\" when connecting to an existing Docker Compose Service",
    "date": "2025-09-16T11:25:45",
    "summary": "Stack Overflow question with 1 answers, 177 views",
    "url": "https://stackoverflow.com/questions/79766168/pycharm-python-interpreter-exited-with-non-zero-exit-code-1-when-connecting",
    "source": "stackoverflow",
    "turbo_score": 1.0,
    "highlights": [
      "views: 177",
      "answers: 1",
      "score: 3",
      "tags: python, docker, pycharm"
    ]
  },
  {
    "title": "FastAPI streaming response getting buffered instead of word by word using fetchEventSource in NextJS 14",
    "date": "2025-09-16T08:07:23",
    "summary": "Stack Overflow question with 0 answers, 23 views",
    "url": "https://stackoverflow.com/questions/79765935/fastapi-streaming-response-getting-buffered-instead-of-word-by-word-using-fetche",
    "source": "stackoverflow",
    "turbo_score": 0.23,
    "highlights": [
      "views: 23",
      "answers: 0",
      "score: 0",
      "tags: next.js, fastapi, ollama"
    ]
  },
  {
    "title": "Why is my dependent container not starting?",
    "date": "2025-09-11T17:21:51",
    "summary": "Stack Overflow question with 1 answers, 97 views",
    "url": "https://stackoverflow.com/questions/79762226/why-is-my-dependent-container-not-starting",
    "source": "stackoverflow",
    "turbo_score": -0.8,
    "highlights": [
      "views: 97",
      "answers: 1",
      "score: -5",
      "tags: docker, docker-compose"
    ]
  },
  {
    "title": "Getting inconsistent structured output from Ollama models with Genkit",
    "date": "2025-09-03T04:36:57",
    "summary": "Stack Overflow question with 0 answers, 92 views",
    "url": "https://stackoverflow.com/questions/79754131/getting-inconsistent-structured-output-from-ollama-models-with-genkit",
    "source": "stackoverflow",
    "turbo_score": 0.9,
    "highlights": [
      "views: 92",
      "answers: 0",
      "score: 2",
      "tags: node.js, typescript, ollama"
    ]
  },
  {
    "title": "Smolagents CodeAgent gets error from correct code",
    "date": "2025-08-24T18:32:36",
    "summary": "Stack Overflow question with 0 answers, 53 views",
    "url": "https://stackoverflow.com/questions/79745092/smolagents-codeagent-gets-error-from-correct-code",
    "source": "stackoverflow",
    "turbo_score": 0.3,
    "highlights": [
      "views: 53",
      "answers: 0",
      "score: 0",
      "tags: python-3.x, large-language-model, agent"
    ]
  },
  {
    "title": "ragas with Ollama does not terminate",
    "date": "2025-08-29T14:41:03",
    "summary": "Stack Overflow question with 0 answers, 64 views",
    "url": "https://stackoverflow.com/questions/79750438/ragas-with-ollama-does-not-terminate",
    "source": "stackoverflow",
    "turbo_score": 0.6,
    "highlights": [
      "views: 64",
      "answers: 0",
      "score: 1",
      "tags: python, rag, ragas"
    ]
  },
  {
    "title": "Can't connect to Ollama hosted locally from python script",
    "date": "2025-08-28T15:24:16",
    "summary": "Stack Overflow question with 1 answers, 93 views",
    "url": "https://stackoverflow.com/questions/79749305/cant-connect-to-ollama-hosted-locally-from-python-script",
    "source": "stackoverflow",
    "turbo_score": 0.7,
    "highlights": [
      "views: 93",
      "answers: 1",
      "score: 0",
      "tags: docker, docker-compose, etl"
    ]
  },
  {
    "title": "How to print input requests and output responses in Ollama server?",
    "date": "2024-06-11T18:19:55",
    "summary": "Stack Overflow question with 1 answers, 15249 views",
    "url": "https://stackoverflow.com/questions/78609187/how-to-print-input-requests-and-output-responses-in-ollama-server",
    "source": "stackoverflow",
    "turbo_score": 0.7,
    "highlights": [
      "views: 15249",
      "answers: 1",
      "score: 0",
      "tags: prompt, langchain, ollama"
    ]
  },
  {
    "title": "Import \"llama_index.llms.ollama\" could not be resolved",
    "date": "2025-08-13T15:07:32",
    "summary": "Stack Overflow question with 1 answers, 111 views",
    "url": "https://stackoverflow.com/questions/79734455/import-llama-index-llms-ollama-could-not-be-resolved",
    "source": "stackoverflow",
    "turbo_score": 1.0,
    "highlights": [
      "views: 111",
      "answers: 1",
      "score: 1",
      "tags: python, python-venv, llama"
    ]
  },
  {
    "title": "Function call with OpenAI Agent SDK with Ollama fails",
    "date": "2025-08-10T12:41:28",
    "summary": "Stack Overflow question with 1 answers, 228 views",
    "url": "https://stackoverflow.com/questions/79731216/function-call-with-openai-agent-sdk-with-ollama-fails",
    "source": "stackoverflow",
    "turbo_score": 1.0,
    "highlights": [
      "views: 228",
      "answers: 1",
      "score: 3",
      "tags: python, openai-api, agent"
    ]
  },
  {
    "title": "Is there a way to manually set the first part of a model's response in Ollama?",
    "date": "2025-07-05T23:57:01",
    "summary": "Stack Overflow question with 1 answers, 191 views",
    "url": "https://stackoverflow.com/questions/79691404/is-there-a-way-to-manually-set-the-first-part-of-a-models-response-in-ollama",
    "source": "stackoverflow",
    "turbo_score": 1.0,
    "highlights": [
      "views: 191",
      "answers: 1",
      "score: 1",
      "tags: python, artificial-intelligence, large-language-model"
    ]
  },
  {
    "title": "Langchain unpredicted behavior create_sql_query_chain",
    "date": "2024-08-12T23:26:12",
    "summary": "Stack Overflow question with 4 answers, 2306 views",
    "url": "https://stackoverflow.com/questions/78863892/langchain-unpredicted-behavior-create-sql-query-chain",
    "source": "stackoverflow",
    "turbo_score": 1.0,
    "highlights": [
      "views: 2306",
      "answers: 4",
      "score: 0",
      "tags: langchain, large-language-model"
    ]
  },
  {
    "title": "Qwen 2.5 7B randomly hangs for 67 minutes when called using Ollama while running on EC2 Instance",
    "date": "2024-09-30T19:10:03",
    "summary": "Stack Overflow question with 0 answers, 860 views",
    "url": "https://stackoverflow.com/questions/79040747/qwen-2-5-7b-randomly-hangs-for-67-minutes-when-called-using-ollama-while-running",
    "source": "stackoverflow",
    "turbo_score": 0.3,
    "highlights": [
      "views: 860",
      "answers: 0",
      "score: 0",
      "tags: large-language-model, ollama"
    ]
  },
  {
    "title": "Fine-tuned Qwen2.5-7B model loops infinitely in Ollama but works fine with transformers",
    "date": "2025-07-23T18:26:08",
    "summary": "Stack Overflow question with 1 answers, 289 views",
    "url": "https://stackoverflow.com/questions/79712412/fine-tuned-qwen2-5-7b-model-loops-infinitely-in-ollama-but-works-fine-with-trans",
    "source": "stackoverflow",
    "turbo_score": 1.0,
    "highlights": [
      "views: 289",
      "answers: 1",
      "score: 1",
      "tags: large-language-model, ollama"
    ]
  },
  {
    "title": "How to use OllamaSharp Embeddings to get Cosine Similarity",
    "date": "2025-07-25T07:21:03",
    "summary": "Stack Overflow question with 0 answers, 198 views",
    "url": "https://stackoverflow.com/questions/79714339/how-to-use-ollamasharp-embeddings-to-get-cosine-similarity",
    "source": "stackoverflow",
    "turbo_score": 0.3,
    "highlights": [
      "views: 198",
      "answers: 0",
      "score: 0",
      "tags: c#, cosine-similarity, ollama"
    ]
  },
  {
    "title": "MCPToolConversionError: Failed to get tools from MCP server: 404",
    "date": "2025-07-18T04:09:55",
    "summary": "Stack Overflow question with 1 answers, 423 views",
    "url": "https://stackoverflow.com/questions/79705666/mcptoolconversionerror-failed-to-get-tools-from-mcp-server-404",
    "source": "stackoverflow",
    "turbo_score": 1.0,
    "highlights": [
      "views: 423",
      "answers: 1",
      "score: 3",
      "tags: python, langchain, model-context-protocol"
    ]
  },
  {
    "title": "Postgresql MCP server not running. Tool showing error",
    "date": "2025-07-21T21:31:42",
    "summary": "Stack Overflow question with 0 answers, 267 views",
    "url": "https://stackoverflow.com/questions/79709658/postgresql-mcp-server-not-running-tool-showing-error",
    "source": "stackoverflow",
    "turbo_score": 0.9,
    "highlights": [
      "views: 267",
      "answers: 0",
      "score: 2",
      "tags: python, postgresql, large-language-model"
    ]
  },
  {
    "title": "cannot import name 'LangChainBridge' from 'python_a2a.langchain'",
    "date": "2025-07-18T03:07:15",
    "summary": "Stack Overflow question with 2 answers, 242 views",
    "url": "https://stackoverflow.com/questions/79705629/cannot-import-name-langchainbridge-from-python-a2a-langchain",
    "source": "stackoverflow",
    "turbo_score": 1.0,
    "highlights": [
      "views: 242",
      "answers: 2",
      "score: 2",
      "tags: python, langchain, model-context-protocol"
    ]
  }
]