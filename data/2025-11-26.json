[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "The official CLI and Python/JS bindings for running Llama, Mistral, Gemma, Phi, and other LLMs locally on macOS, Linux, and Windows.",
    "source": "github",
    "date": "2024-06-04",
    "highlights": [
      "self-contained binary",
      "Docker image",
      "OpenAI-compatible REST API",
      "model library"
    ]
  },
  {
    "title": "langchain-ai/langchain",
    "url": "https://github.com/langchain-ai/langchain",
    "summary": "LangChain\u2019s Ollama integration lets you call any model served by Ollama as a standard LangChain LLM or chat model with two lines of code.",
    "source": "github",
    "date": "2024-06-03",
    "highlights": [
      "pip install langchain-ollama",
      "streaming support",
      "native tool calling"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://pypi.org/project/ollama/",
    "summary": "Official PyPI package providing a simple Python client for the Ollama REST API; supports sync/async, streaming, and embeddings.",
    "source": "github",
    "date": "2024-05-29",
    "highlights": [
      "async/await",
      "embeddings endpoint",
      "built-in retries"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://www.npmjs.com/package/ollama",
    "summary": "Official npm package that wraps the Ollama REST API for Node.js and browsers (with fetch).",
    "source": "github",
    "date": "2024-05-30",
    "highlights": [
      "TypeScript definitions",
      "streaming chats",
      "browser support"
    ]
  },
  {
    "title": "ollama-webui/ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich ChatGPT-style web interface for Ollama with multi-model chats, document upload, RAG, and role presets.",
    "source": "github",
    "date": "2024-06-01",
    "highlights": [
      "Docker one-liner",
      "RAG via LlamaIndex",
      "dark/light themes",
      "user auth"
    ]
  },
  {
    "title": "jmorganca/ollama-helm",
    "url": "https://github.com/jmorganca/ollama-helm",
    "summary": "Helm chart to deploy Ollama on Kubernetes with GPU node selection and horizontal scaling.",
    "source": "github",
    "date": "2024-05-25",
    "highlights": [
      "GPU autoscaling",
      "configurable models list",
      "persistent storage"
    ]
  },
  {
    "title": "ollama-rag",
    "url": "https://github.com/ggerganov/ollama-rag",
    "summary": "Lightweight RAG template that pairs Ollama embeddings with a local vector DB for PDF question-answering.",
    "source": "github",
    "date": "2024-05-28",
    "highlights": [
      "LlamaIndex integration",
      "offline PDF parsing",
      "Gradio UI"
    ]
  },
  {
    "title": "ollama-docker",
    "url": "https://github.com/ollama/ollama/tree/main/docker",
    "summary": "Official Dockerfiles and compose snippets for CPU & GPU (CUDA/ROCm) images.",
    "source": "github",
    "date": "2024-06-02",
    "highlights": [
      "multi-arch",
      "CUDA 12",
      "ROCm 5.7",
      "compose examples"
    ]
  },
  {
    "title": "ollama-cli-chat",
    "url": "https://github.com/summer600/ollama-cli-chat",
    "summary": "Terminal UI wrapper that adds readline history, syntax highlighting, and markdown rendering to ollama run.",
    "source": "github",
    "date": "2024-05-31",
    "highlights": [
      "vim keys",
      "session save",
      "themes"
    ]
  },
  {
    "title": "ollama-discord-bot",
    "url": "https://github.com/ollama-ecosystem/ollama-discord-bot",
    "summary": "Self-hosted Discord bot that streams Ollama replies into any channel with slash commands and role-based access.",
    "source": "github",
    "date": "2024-05-27",
    "highlights": [
      "streaming edits",
      "threading",
      "mod tools"
    ]
  },
  {
    "title": "ollama-slack-bot",
    "url": "https://github.com/ollama-ecosystem/ollama-slack-bot",
    "summary": "Slack Bolt app that adds /ollama slash command for private or channel chats with optional RAG via uploaded files.",
    "source": "github",
    "date": "2024-05-26",
    "highlights": [
      "file QA",
      "threading",
      "enterprise grid ready"
    ]
  },
  {
    "title": "ollama-vscode",
    "url": "https://github.com/ollama-ecosystem/ollama-vscode",
    "summary": "VS Code extension that adds \u201cAsk Ollama\u201d code actions, inline completion provider, and chat sidebar using any local model.",
    "source": "github",
    "date": "2024-05-30",
    "highlights": [
      "inline completions",
      "chat sidebar",
      "multi-model switch"
    ]
  },
  {
    "title": "ollama-obsidian",
    "url": "https://github.com/ollama-ecosystem/ollama-obsidian",
    "summary": "Obsidian plugin for summarizing notes, generating flashcards, and Q&A over your vault with Ollama embeddings.",
    "source": "github",
    "date": "2024-05-24",
    "highlights": [
      "local embeddings",
      "command palette",
      "template prompts"
    ]
  },
  {
    "title": "ollama-microsoft-bot-framework",
    "url": "https://github.com/ollama-ecosystem/ollama-ms-bot",
    "summary": "Microsoft Bot Framework adapter to expose Ollama models in Teams, Skype, and other channels.",
    "source": "github",
    "date": "2024-05-23",
    "highlights": [
      "Teams SSO",
      "adaptive cards",
      "LUIS fallback"
    ]
  },
  {
    "title": "ollama-rust",
    "url": "https://github.com/ollama-ecosystem/ollama-rust",
    "summary": "Community-maintained Rust crate providing async bindings to the Ollama REST API with tokio/hyper.",
    "source": "github",
    "date": "2024-05-22",
    "highlights": [
      "async/await",
      "Serde types",
      "examples"
    ]
  },
  {
    "title": "ollama-go",
    "url": "https://github.com/ollama-ecosystem/ollama-go",
    "summary": "Idiomatic Go client for Ollama with context cancellation, streaming, and embeddings support.",
    "source": "github",
    "date": "2024-05-21",
    "highlights": [
      "context.Context",
      "streaming json",
      "modular"
    ]
  },
  {
    "title": "ollama-csharp",
    "url": "https://github.com/ollama-ecosystem/ollama-csharp",
    "summary": ".NET 8 client library for Ollama with async enumerable streaming and dependency-injection helpers.",
    "source": "github",
    "date": "2024-05-20",
    "highlights": [
      "IAsyncEnumerable",
      "DI extensions",
      "NuGet"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/ollama-ecosystem/ollama-haystack",
    "summary": "Haystack integration that registers Ollama models as generators or embedders for end-to-end NLP pipelines.",
    "source": "github",
    "date": "2024-05-19",
    "highlights": [
      "Haystack 2.x",
      "embeddings",
      "pipelines"
    ]
  },
  {
    "title": "ollama-autogen",
    "url": "https://github.com/ollama-ecosystem/ollama-autogen",
    "summary": "Microsoft AutoGen adapter letting Ollama models act as conversable agents in multi-agent workflows.",
    "source": "github",
    "date": "2024-05-18",
    "highlights": [
      "agent roles",
      "code execution",
      "group chat"
    ]
  },
  {
    "title": "ollama-crewai",
    "url": "https://github.com/ollama-ecosystem/ollama-crewai",
    "summary": "CrewAI integration that uses Ollama models for role-playing AI crews with local inference.",
    "source": "github",
    "date": "2024-05-17",
    "highlights": [
      "role agents",
      "local LLM",
      "task chaining"
    ]
  }
]