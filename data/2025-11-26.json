[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: self-contained LLM runner that bundles Llama 2, Mistral, Gemma, etc. into a single CLI/API.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "CLI",
      "REST API",
      "model library",
      "macOS/Linux/Windows"
    ]
  },
  {
    "title": "langchain-ai/langchain",
    "url": "https://github.com/langchain-ai/langchain",
    "summary": "LangChain Python/JS library ships an Ollama integration for building RAG, agents, and chains with local models.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "Ollama LLM wrapper",
      "RAG",
      "tool calling",
      "Python/JS"
    ]
  },
  {
    "title": "ollama-js on npm",
    "url": "https://www.npmjs.com/package/ollama",
    "summary": "Official JavaScript/TypeScript client for the Ollama API\u2014chat, generate, pull, and embed.",
    "source": "npm",
    "date": "2024-05-12",
    "highlights": [
      "TypeScript",
      "Promise-based",
      "browser & Node",
      "embeddings"
    ]
  },
  {
    "title": "ollama-python on PyPI",
    "url": "https://pypi.org/project/ollama/",
    "summary": "Official Python client for Ollama; chat, generate, pull, push, list, and delete models.",
    "source": "pypi",
    "date": "2024-05-13",
    "highlights": [
      "sync & async",
      "streaming",
      "built-in embeddings"
    ]
  },
  {
    "title": "ollama-webui/ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich ChatGPT-style web UI for Ollama (now renamed Open WebUI).",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "dark/light theme",
      "RAG uploads",
      "multi-user",
      "Docker"
    ]
  },
  {
    "title": "jmorganca/ollama-docker",
    "url": "https://github.com/jmorganca/ollama-docker",
    "summary": "Minimal Docker image to run Ollama + models in a container with GPU support.",
    "source": "github",
    "date": "2024-04-28",
    "highlights": [
      "CUDA",
      "AMD ROCm",
      "rootless",
      "docker-compose"
    ]
  },
  {
    "title": "ollama-laravel on Packagist",
    "url": "https://github.com/cloudstudio/ollama-laravel",
    "summary": "Laravel wrapper providing a fluent facade for chatting with Ollama models.",
    "source": "github",
    "date": "2024-05-01",
    "highlights": [
      "Laravel facade",
      "config publishing",
      "queue support"
    ]
  },
  {
    "title": "ollama-rb Ruby gem",
    "url": "https://github.com/ollama-rb/ollama",
    "summary": "Community Ruby client for Ollama with async streaming and Faraday.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "async",
      "streaming",
      "Faraday adapter",
      "Ruby 3+"
    ]
  },
  {
    "title": "ollama4j Java library",
    "url": "https://github.com/ollama4j/ollama4j",
    "summary": "Lightweight Java/Kotlin SDK for Ollama (JVM) with OkHttp and coroutines.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "Kotlin DSL",
      "reactive",
      "model management",
      "Maven Central"
    ]
  },
  {
    "title": "chainlit + Ollama cookbook",
    "url": "https://github.com/Chainlit/cookbook/tree/main/ollama",
    "summary": "Chainlit recipe showing how to build a chat UI backed by Ollama in <50 lines.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "real-time UI",
      "streaming",
      "decorator syntax"
    ]
  },
  {
    "title": "ollama-chat-shell",
    "url": "https://github.com/oklop/ollama-chat-shell",
    "summary": "Bash script for interactive Ollama chat with readline history and markdown rendering.",
    "source": "github",
    "date": "2024-04-30",
    "highlights": [
      "readline",
      "no deps",
      "markdown",
      "shell alias"
    ]
  },
  {
    "title": "ollama-rust crate",
    "url": "https://github.com/pepperoni21/ollama-rust",
    "summary": "Rust client for Ollama using reqwest and native-tls with async support.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "async/await",
      "Tokio",
      "Serde",
      "crates.io"
    ]
  },
  {
    "title": "ollama-copilot.nvim",
    "url": "https://github.com/yetone/ollama-copilot.nvim",
    "summary": "Neovim plugin turning Ollama into a GitHub Copilot-style code completer.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "inline suggestions",
      "Lua config",
      "FIM templates"
    ]
  },
  {
    "title": "ollama-cli on PyPI",
    "url": "https://pypi.org/project/ollama-cli/",
    "summary": "Unofficial rich-terminal CLI for Ollama with fuzzy model search and chat history.",
    "source": "pypi",
    "date": "2024-05-04",
    "highlights": [
      "rich TUI",
      "fzf",
      "conversation save",
      "pip install"
    ]
  },
  {
    "title": "ollama-haystack by deepset",
    "url": "https://github.com/deepset-ai/haystack-integrations/tree/main/integrations/ollama",
    "summary": "Haystack integration letting you use Ollama models in production-grade RAG pipelines.",
    "source": "github",
    "date": "2024-05-03",
    "highlights": [
      "Haystack 2.x",
      "pipeline nodes",
      "embedders",
      "rankers"
    ]
  },
  {
    "title": "ollama-discord bot",
    "url": "https://github.com/mxyng/ollama-discord",
    "summary": "Simple self-hosted Discord bot that streams Ollama replies into any channel.",
    "source": "github",
    "date": "2024-04-29",
    "highlights": [
      "slash commands",
      "streaming",
      "Docker",
      "env config"
    ]
  },
  {
    "title": "ollama-helm chart",
    "url": "https://github.com/otwld/ollama-helm",
    "summary": "Community Helm chart to deploy Ollama on Kubernetes with GPU node selection.",
    "source": "github",
    "date": "2024-05-02",
    "highlights": [
      "Helm",
      "GPU nodes",
      "PVC",
      "autoscaling"
    ]
  },
  {
    "title": "ollama-csharp SDK",
    "url": "https://github.com/ollama-csharp/ollama-csharp",
    "summary": ".NET SDK for Ollama supporting .NET 6+ with System.Text.Json and streaming.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "NuGet",
      "streaming",
      "strong typing",
      "DI friendly"
    ]
  },
  {
    "title": "ollama-dagger module",
    "url": "https://github.com/shykes/daggerverse/tree/main/ollama",
    "summary": "Dagger module that spins up Ollama as a CI service for testing LLM-powered apps.",
    "source": "github",
    "date": "2024-05-01",
    "highlights": [
      "Dagger Cue",
      "CI caching",
      "model pre-pull"
    ]
  },
  {
    "title": "reddit/r/ollama",
    "url": "https://www.reddit.com/r/ollama/",
    "summary": "Active subreddit for model announcements, troubleshooting, and ecosystem showcases.",
    "source": "reddit",
    "date": "2024-05-14",
    "highlights": [
      "community support",
      "model GGUFs",
      "benchmarks"
    ]
  }
]