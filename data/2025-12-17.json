[
  {
    "title": "Ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Get up and running with Llama 3.3, Mistral, Gemma 2, and other large language models locally.",
    "source": "github",
    "date": "2024-06-01",
    "highlights": [
      "Run Llama 3.3, Mistral, Gemma 2 locally",
      "Simple CLI and REST API",
      "macOS, Linux, Windows support"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "The official Ollama JavaScript/TypeScript library for Node.js and browsers.",
    "source": "github",
    "date": "2024-05-15",
    "highlights": [
      "Official JS/TS client",
      "Promise-based API",
      "Works in Node & browser"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Ollama Python library for chatting with local models.",
    "source": "github",
    "date": "2024-05-20",
    "highlights": [
      "Official Python client",
      "Streaming & async support",
      "PyPI package"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain-ollama",
    "summary": "LangChain integration for Ollama models.",
    "source": "github",
    "date": "2024-04-10",
    "highlights": [
      "LangChain LLM & embeddings",
      "Chat & tool-calling",
      "Community provider"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "ChatGPT-style web UI client for Ollama, no API keys needed.",
    "source": "github",
    "date": "2024-05-30",
    "highlights": [
      "ChatGPT-like interface",
      "Docker one-liner",
      "Multi-model chats"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Unofficial Java SDK for Ollama\u2019s REST API.",
    "source": "github",
    "date": "2024-03-12",
    "highlights": [
      "Java/Kotlin support",
      "Fluent builder API",
      "Maven Central"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/nileshtrivedi/ollama-rb",
    "summary": "Community Ruby gem for interacting with Ollama.",
    "source": "github",
    "date": "2024-02-28",
    "highlights": [
      "Ruby client",
      "Streaming responses",
      "Gem install"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/sugarforever/ollama-cli",
    "summary": "Enhanced command-line wrapper with history and prompt templates.",
    "source": "github",
    "date": "2024-04-05",
    "highlights": [
      "Readline history",
      "Prompt templates",
      "Shell completions"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama-copilot/ollama-copilot",
    "summary": "VS Code extension bringing local LLM copilots via Ollama.",
    "source": "github",
    "date": "2024-05-18",
    "highlights": [
      "Inline completions",
      "Local privacy",
      "VS Code marketplace"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/deepset-ai/haystack-integrations/tree/main/integrations/ollama",
    "summary": "Haystack integration to use Ollama models in RAG pipelines.",
    "source": "github",
    "date": "2024-04-22",
    "highlights": [
      "Haystack generator & embedder",
      "RAG ready",
      "Pipeline YAML support"
    ]
  },
  {
    "title": "ollama-csharp",
    "url": "https://github.com/awaescher/ollama-csharp",
    "summary": ".NET client for Ollama with async streaming and dependency injection.",
    "source": "github",
    "date": "2024-03-30",
    "highlights": [
      ".NET 8 support",
      "Dependency injection friendly",
      "NuGet package"
    ]
  },
  {
    "title": "ollama-discord",
    "url": "https://github.com/mxyng/ollama-discord",
    "summary": "Self-host Discord bot that chats using local Ollama models.",
    "source": "github",
    "date": "2024-05-02",
    "highlights": [
      "Slash commands",
      "Thread support",
      "Docker image"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/otwld/ollama-helm",
    "summary": "Helm chart to deploy Ollama on Kubernetes with GPU autoscaling.",
    "source": "github",
    "date": "2024-05-25",
    "highlights": [
      "GPU node pools",
      "Autoscaling",
      "Ingress & PVC ready"
    ]
  },
  {
    "title": "ollama-nix",
    "url": "https://github.com/NixOS/nixpkgs/tree/master/pkgs/tools/misc/ollama",
    "summary": "Nix flake for reproducible Ollama installations.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "Nix flake",
      "CUDA & ROCm variants",
      "Reproducible builds"
    ]
  },
  {
    "title": "ollama-rust",
    "url": "https://github.com/pepperoni21/ollama-rs",
    "summary": "Rust crate for Ollama with async/tokio and serde types.",
    "source": "github",
    "date": "2024-04-15",
    "highlights": [
      "Async/tokio",
      "Strongly typed",
      "Crates.io published"
    ]
  },
  {
    "title": "ollama-go",
    "url": "https://github.com/ollama/ollama-go",
    "summary": "Official Go client library for Ollama.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "Official Go SDK",
      "Streaming support",
      "Go modules"
    ]
  },
  {
    "title": "ollama-slack",
    "url": "https://github.com/alexanderldavis/ollama-slack",
    "summary": "Slack bot that answers questions using local Ollama models.",
    "source": "github",
    "date": "2024-04-18",
    "highlights": [
      "Socket-mode bot",
      "Thread replies",
      "Env var config"
    ]
  },
  {
    "title": "ollama-docker-compose",
    "url": "https://github.com/valiantlynx/ollama-docker-compose",
    "summary": "Production-ready docker-compose with GPU, WebUI, and monitoring.",
    "source": "github",
    "date": "2024-05-27",
    "highlights": [
      "GPU runtime",
      "Prometheus metrics",
      "Open WebUI bundled"
    ]
  },
  {
    "title": "ollama-ex",
    "url": "https://github.com/michaelguarino/ollama-ex",
    "summary": "Elixir wrapper for Ollama with GenServer and LiveView examples.",
    "source": "github",
    "date": "2024-03-20",
    "highlights": [
      "Elixir GenServer",
      "LiveView demo",
      "Hex package"
    ]
  },
  {
    "title": "ollama-obsidian",
    "url": "https://github.com/hinterdupfinger/ollama-obsidian",
    "summary": "Obsidian plugin to run local LLM prompts inside your vault.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "Command palette",
      "Template variables",
      "Community plugin"
    ]
  }
]