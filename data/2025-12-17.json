[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: get up and running with Llama 3, Mistral, Gemma, and other large language models locally.",
    "source": "github",
    "date": "2024-05-20",
    "highlights": [
      "self-contained binary",
      "macOS/Linux/Windows",
      "Docker image",
      "REST & CLI APIs"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python SDK for Ollama: chat, generate, embed, pull, list, delete models with a few lines of code.",
    "source": "github",
    "date": "2024-05-18",
    "highlights": [
      "pip install ollama",
      "sync & async clients",
      "streaming support",
      "type hints"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript SDK for Node & browsers; same generate/chat/embed API surface as Python.",
    "source": "github",
    "date": "2024-05-17",
    "highlights": [
      "npm i ollama",
      "ESM & CommonJS",
      "streaming JSON",
      "zero native deps"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/community/langchain_community/llms/ollama",
    "summary": "LangChain integration: use any Ollama model as an LLM or chat endpoint with LangChain primitives.",
    "source": "github",
    "date": "2024-05-19",
    "highlights": [
      "pip install langchain-community",
      "callback streaming",
      "tool calling",
      "embeddings wrapper"
    ]
  },
  {
    "title": "llama-index-llms-ollama",
    "url": "https://github.com/run-llama/llama_index/tree/main/llama-index-integrations/llms/llama-index-llms-ollama",
    "summary": "LlamaIndex LLM and embedding drivers for Ollama; plug local models into RAG pipelines.",
    "source": "github",
    "date": "2024-05-16",
    "highlights": [
      "pip install llama-index-llms-ollama",
      "embedding support",
      "JSON mode",
      "tool use"
    ]
  },
  {
    "title": "ollama-webui (formerly ollama-webui)",
    "url": "https://github.com/open-webui/open-webui",
    "summary": "Feature-rich chat WebUI for Ollama: markdown, code highlighting, multimodal, RAG, user management.",
    "source": "github",
    "date": "2024-05-20",
    "highlights": [
      "Docker run",
      "offline RAG",
      "custom modelfiles",
      "role-based auth",
      "voice input"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/technomancy/ollama-cli",
    "summary": "Rust-based TUI for interactive chatting, model management, and conversation history.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "cross-platform binary",
      "vim keys",
      "themes",
      "chat history search"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama/ollama-copilot",
    "summary": "VS Code extension that turns Ollama models into inline code copilots with autocomplete and chat.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "inline suggestions",
      "chat panel",
      "custom prompts",
      "multi-model switch"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java/Kotlin client for Ollama; offers synchronous, asynchronous, and reactive APIs.",
    "source": "github",
    "date": "2024-05-15",
    "highlights": [
      "Maven Central",
      "Spring Boot starter",
      "Kotlin coroutines",
      "embedding support"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/ollama/ollama-rb",
    "summary": "Official Ruby gem for Ollama; generate, chat, pull, list, delete models from Ruby.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "gem install ollama",
      "streaming blocks",
      "Faraday backend",
      "RSpec tested"
    ]
  },
  {
    "title": "ollama-workflows",
    "url": "https://github.com/ollama/ollama-workflows",
    "summary": "Community GitHub Actions to pull, cache, and serve Ollama models in CI pipelines.",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "GitHub cache",
      "matrix models",
      "service containers",
      "free runners"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/ollama/helm-charts",
    "summary": "Official Helm chart for deploying Ollama on Kubernetes with GPU autoscaling.",
    "source": "github",
    "date": "2024-05-13",
    "highlights": [
      "GPU nodeSelector",
      "pvc cache",
      "ingress",
      "HPA support"
    ]
  },
  {
    "title": "ollama-docker-compose",
    "url": "https://github.com/ollama/ollama-docker-compose",
    "summary": "Ready-to-run Docker Compose stacks bundling Ollama with WebUI, Open-WebUI, or LibreChat.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "GPU passthrough",
      "env file",
      "volume mounts",
      "one-liner up"
    ]
  },
  {
    "title": "ollama-model-registry",
    "url": "https://github.com/ollama/ollama-model-registry",
    "summary": "Self-hosted model registry that lets teams publish, version, and cache Ollama Modelfiles internally.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "OCI artifacts",
      "signed manifests",
      "RBAC",
      "harbor integration"
    ]
  },
  {
    "title": "ollama-cookbook",
    "url": "https://github.com/ollama/ollama-cookbook",
    "summary": "Community recipes for fine-tuning, RAG, function calling, multimodal bots, and edge deployments.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "Jupyter notebooks",
      "Modelfile snippets",
      "LangChain/LlamaIndex",
      "Pi 5 guide"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/deepset-ai/haystack-integrations/tree/main/integrations/ollama",
    "summary": "Haystack integration to use Ollama generators and embedders in production pipelines.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "pip install farm-haystack[ollama]",
      "YAML pipelines",
      "Ray scaling",
      "eval harness"
    ]
  },
  {
    "title": "ollama-fastapi",
    "url": "https://github.com/ollama/ollama-fastapi",
    "summary": "Lightweight FastAPI proxy that adds JWT auth, rate limits, and usage metrics to Ollama endpoints.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "OpenAPI schema",
      "Prometheus metrics",
      "Redis rate limit",
      "Docker image"
    ]
  },
  {
    "title": "ollama-rag-obsidian",
    "url": "https://github.com/ollama/ollama-rag-obsidian",
    "summary": "Obsidian plugin that builds a local vector index of your vault and lets you chat with notes via Ollama.",
    "source": "github",
    "date": "2024-05-04",
    "highlights": [
      "offline embeddings",
      "smart notes",
      "copilot sidebar",
      "graph RAG"
    ]
  },
  {
    "title": "ollama-nestjs",
    "url": "https://github.com/ollama/ollama-nestjs",
    "summary": "NestJS module providing injectable services for chatting and embedding with Ollama models.",
    "source": "github",
    "date": "2024-05-03",
    "highlights": [
      "npm install @ollama/nestjs",
      "RxJS streams",
      "Swagger docs",
      "config module"
    ]
  },
  {
    "title": "ollama-dagger",
    "url": "https://github.com/ollama/ollama-dagger",
    "summary": "Dagger module for reproducible CI pipelines that test and benchmark Ollama models across GPUs.",
    "source": "github",
    "date": "2024-05-02",
    "highlights": [
      "cue plans",
      "cross-GPU matrix",
      "cache mounts",
      "GitHub Actions"
    ]
  }
]