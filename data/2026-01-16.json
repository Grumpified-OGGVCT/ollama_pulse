[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: get up and running with Llama 2, Mistral, Gemma, and other large language models locally.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "self-contained LLM runner",
      "macOS/Linux/Windows",
      "Docker images",
      "REST API"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python library for Ollama, offering a simple client to chat with local models.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "pip install ollama",
      "async support",
      "streaming responses"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Ollama, usable in Node or browsers.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "npm i ollama",
      "TypeScript types",
      "browser compatibility"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/ollama",
    "summary": "LangChain integration package letting you use Ollama models as LLM components.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "pip install langchain-ollama",
      "chain composition",
      "tool calling"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich chat WebUI for Ollama (renamed to Open WebUI); supports RAG, multimodal, admin panel.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "Docker one-liner",
      "RAG via embeddings",
      "user roles",
      "dark/light themes"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/sugarforever/ollama-cli",
    "summary": "Conversational CLI wrapper around Ollama with chat history and markdown rendering.",
    "source": "github",
    "date": "2024-04-30",
    "highlights": [
      "chat session persistence",
      "syntax highlighting",
      "pip install"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama-copilot/ollama-copilot",
    "summary": "Copilot-style VS Code extension that uses local Ollama models for inline suggestions.",
    "source": "github",
    "date": "2024-05-02",
    "highlights": [
      "inline completions",
      "configurable model",
      "no cloud required"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/deepset-ai/haystack-core-integrations/tree/main/integrations/ollama",
    "summary": "Haystack 2.0 integration to plug Ollama models into production-ready NLP pipelines.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "generator & embedder nodes",
      "pip install ollama-haystack"
    ]
  },
  {
    "title": "ollama-rag",
    "url": "https://github.com/ggerganov/ollama-rag",
    "summary": "Minimal retrieval-augmented-generation example combining Ollama + Sentence-Transformers + FAISS.",
    "source": "github",
    "date": "2024-04-28",
    "highlights": [
      "chunking utils",
      "vector store",
      "Gradio UI"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java/Kotlin SDK for Ollama, wrapping the REST API with fluent builders.",
    "source": "github",
    "date": "2024-05-01",
    "highlights": [
      "Maven Central",
      "reactive streams",
      "Spring Boot starter"
    ]
  },
  {
    "title": "ollama-csharp",
    "url": "https://github.com/awaescher/ollama-csharp",
    "summary": ".NET client for Ollama with async streaming and dependency-injection helpers.",
    "source": "github",
    "date": "2024-04-29",
    "highlights": [
      "NuGet package",
      "ASP.NET Core sample",
      "streaming chat"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/otwld/ollama-helm",
    "summary": "Helm chart to deploy Ollama on Kubernetes with GPU node selection and autoscaling.",
    "source": "github",
    "date": "2024-05-04",
    "highlights": [
      "GPU resource limits",
      "PVC model cache",
      "Ingress ready"
    ]
  },
  {
    "title": "ollama-gpt4all",
    "url": "https://github.com/ollama/ollama/tree/main/gpt4all",
    "summary": "Docs and scripts showing how to import GPT4All models into Ollama\u2019s Modelfile format.",
    "source": "github",
    "date": "2024-05-03",
    "highlights": [
      "conversion script",
      "quantization tips",
      "community models"
    ]
  },
  {
    "title": "ollama-rust",
    "url": "https://github.com/pepperoni21/ollama-rust",
    "summary": "Community-built Rust crate for chatting with Ollama via async HTTP calls.",
    "source": "github",
    "date": "2024-04-27",
    "highlights": [
      "tokio/async",
      "Serde models",
      "crates.io"
    ]
  },
  {
    "title": "ollama-discord-bot",
    "url": "https://github.com/rizerphe/ollama-discord-bot",
    "summary": "Self-hostable Discord bot that streams Ollama replies into threads with slash commands.",
    "source": "github",
    "date": "2024-05-01",
    "highlights": [
      "slash commands",
      "conversation threads",
      "Docker image"
    ]
  },
  {
    "title": "ollama-nest",
    "url": "https://github.com/jmcdo29/ollama-nest",
    "summary": "NestJS module wrapping the Ollama JS client for dependency injection in Node APIs.",
    "source": "github",
    "date": "2024-04-26",
    "highlights": [
      "Injectable service",
      "configurable providers",
      "example controller"
    ]
  },
  {
    "title": "ollama-dagger",
    "url": "https://github.com/dagger/dagger/tree/main/sdk/python/examples/ollama",
    "summary": "Dagger pipeline example that spins up Ollama in a container and runs model tests.",
    "source": "github",
    "date": "2024-05-03",
    "highlights": [
      "CI-friendly",
      "caching models",
      "Python SDK"
    ]
  },
  {
    "title": "ollama-go",
    "url": "https://github.com/ollama/ollama-go",
    "summary": "Official Go client library for Ollama with generated structs and streaming support.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "go get github.com/ollama/ollama-go",
      "context cancellation",
      "embedding endpoint"
    ]
  },
  {
    "title": "ollama-models",
    "url": "https://github.com/ollama/ollama/tree/main/models",
    "summary": "Registry of community-contributed Modelfiles (Llava, CodeLlama, Mistral, etc.).",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "pull via tag",
      "quantization options",
      "custom prompts"
    ]
  },
  {
    "title": "ollama-rfcs",
    "url": "https://github.com/ollama/ollama-rfcs",
    "summary": "Public RFC repository where new Ollama features (tool use, multi-modal, auth) are discussed.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "open proposals",
      "community feedback",
      "design docs"
    ]
  }
]