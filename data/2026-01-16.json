[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: self-host LLMs (Llama 2, Mistral, Gemma, \u2026) behind a simple REST/CLI API with GPU/Metal acceleration.",
    "source": "github",
    "date": "2024-05-17",
    "highlights": [
      "CLI + REST API",
      "built-in model library",
      "GPU & Apple Metal support",
      "Docker image"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "First-party Python client for Ollama; chat, embed, pull, list models in ~5 lines.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "sync & async",
      "streaming responses",
      "PyPI: ollama"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client; works in Node, Bun, Deno & browsers (via proxy).",
    "source": "github",
    "date": "2024-05-15",
    "highlights": [
      "npm: ollama",
      "Promise + stream APIs",
      "zero deps"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/partners/ollama",
    "summary": "LangChain integration package\u2014LLM, chat, embeddings, tool-calling via Ollama.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "pip: langchain-ollama",
      "tool calling",
      "structured output"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich ChatGPT-style web UI for Ollama (models, chats, RAG, admin).",
    "source": "github",
    "date": "2024-05-16",
    "highlights": [
      "Docker one-liner",
      "multi-user",
      "RAG uploads",
      "dark mode"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java/Kotlin client for Ollama with POJO mapping & Spring Boot starters.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "Maven Central",
      "Spring starter",
      "async streaming"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/ollama/ollama-rb",
    "summary": "Community Ruby gem wrapping Ollama\u2019s REST API.",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "RubyGems: ollama",
      "streaming chat",
      "model management"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/sugarforever/ollama-cli",
    "summary": "Rust-based interactive CLI with syntax highlighting & conversation memory.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "Cargo install",
      "REPL",
      "conversation save/load"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama/ollama-copilot",
    "summary": "VS Code extension that turns any Ollama model into a GitHub Copilot replacement.",
    "source": "github",
    "date": "2024-05-13",
    "highlights": [
      "inline completions",
      "FIM templates",
      "configurable model"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/otwld/ollama-helm",
    "summary": "Production-ready Helm chart for deploying Ollama on Kubernetes with GPU node selectors.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "autoscaling",
      "PVC model cache",
      "GPU support"
    ]
  },
  {
    "title": "ollama-docker-compose",
    "url": "https://github.com/ollama/ollama/tree/main/docker",
    "summary": "Official Docker & docker-compose examples (CPU/GPU, Open WebUI stack).",
    "source": "github",
    "date": "2024-05-17",
    "highlights": [
      "one-line GPU",
      "Open WebUI bundle",
      "AMD ROCm image"
    ]
  },
  {
    "title": "ollama-models",
    "url": "https://github.com/ollama/ollama/tree/main/models",
    "summary": "Registry of 150+ community Modelfiles (Llama 3, Phi-3, CodeLlama, Zephyr).",
    "source": "github",
    "date": "2024-05-17",
    "highlights": [
      "official Modelfiles",
      "quantization recipes",
      "pull by name"
    ]
  },
  {
    "title": "ollama-embeddings",
    "url": "https://github.com/ollama/ollama/tree/main/docs/embedding.md",
    "summary": "Built-in embedding endpoint (mxbai-embed-large, nomic-embed-text) for RAG apps.",
    "source": "github",
    "date": "2024-05-15",
    "highlights": [
      "single endpoint",
      "cosine distance",
      "512-8k dims"
    ]
  },
  {
    "title": "ollama-slack-bot",
    "url": "https://github.com/ollama/ollama-slack-bot",
    "summary": "Slack Bolt app that @-mentions any Ollama model in channels/DMs.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "Bolt JS",
      "threading",
      "/ollama slash command"
    ]
  },
  {
    "title": "ollama-dagger-module",
    "url": "https://github.com/shykes/daggerverse/tree/main/ollama",
    "summary": "Dagger module to cache & serve Ollama models inside CI pipelines.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "CI caching",
      "Dagger functions",
      "multi-arch"
    ]
  },
  {
    "title": "ollama-n8n-node",
    "url": "https://github.com/n8n-io/n8n/tree/master/packages/nodes-base/nodes/Ollama",
    "summary": "n8n community node to call Ollama workflows (chat, generate, embed).",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "npm: n8n-nodes-ollama",
      "credentials manager",
      "streaming"
    ]
  },
  {
    "title": "ollama-rag",
    "url": "https://github.com/ollama/ollama-rag",
    "summary": "Minimal Streamlit RAG example using Ollama embeddings + Chroma vector DB.",
    "source": "github",
    "date": "2024-05-04",
    "highlights": [
      "Streamlit",
      "PDF ingestion",
      "local only"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/deepset-ai/haystack-core-integrations/tree/main/integrations/ollama",
    "summary": "Haystack 2.x integration for Ollama generators & embedders.",
    "source": "github",
    "date": "2024-05-03",
    "highlights": [
      "pip: haystack-ai[ollama]",
      "pipeline nodes",
      "async"
    ]
  },
  {
    "title": "ollama-discord-bot",
    "url": "https://github.com/ollama/ollama-discord-bot",
    "summary": "Discord.py bot bringing any Ollama model to servers with slash commands & conversation memory.",
    "source": "github",
    "date": "2024-05-02",
    "highlights": [
      "slash commands",
      "per-user history",
      "role-based access"
    ]
  },
  {
    "title": "ollama-mistral-ft",
    "url": "https://github.com/ollama/ollama-mistral-ft",
    "summary": "Fine-tune Mistral 7B on your data and serve with Ollama in <30 min notebook.",
    "source": "github",
    "date": "2024-05-01",
    "highlights": [
      "Axolotl trainer",
      "QLoRA",
      "one-click Modelfile"
    ]
  }
]