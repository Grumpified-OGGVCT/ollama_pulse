[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: get up and running with Llama 2, Mistral, Gemma, and other large language models locally.",
    "source": "github",
    "date": "2024-05-20",
    "highlights": [
      "self-contained binary",
      "Docker image",
      "macOS/Linux/Windows",
      "REST & CLI APIs"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python SDK for Ollama: chat, embed, pull, and manage models with a few lines of code.",
    "source": "github",
    "date": "2024-05-15",
    "highlights": [
      "pip install ollama",
      "async support",
      "streaming responses",
      "built-in embed"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Node & browsers; same API surface as the Python SDK.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "npm i ollama",
      "TypeScript defs",
      "streaming fetch",
      "browser compatible"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://python.langchain.com/docs/integrations/llms/ollama",
    "summary": "LangChain integration: use any Ollama model as an LLM, chat, or embedding provider in LangChain pipelines.",
    "source": "github",
    "date": "2024-05-18",
    "highlights": [
      "pip install langchain-ollama",
      "chat model",
      "embeddings",
      "tool calling"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich web UI for Ollama (ChatGPT-style interface) with multi-user support, model management, and RAG.",
    "source": "github",
    "date": "2024-05-19",
    "highlights": [
      "Docker-ready",
      "dark/light themes",
      "upload docs/PDF",
      "open-source"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java/Kotlin client for Ollama; offers synchronous & async APIs, streaming, and embedding support.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "Maven Central",
      "Kotlin coroutines",
      "Spring Boot starter",
      "zero dependencies"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/gbaptista/ollama-rb",
    "summary": "Ruby gem wrapping Ollama\u2019s REST API; chat, generate, pull, and delete models from Ruby.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "gem install ollama",
      "streaming blocks",
      "ActiveRecord-like DSL",
      "RSpec tested"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/salty-flower/ollama-cli",
    "summary": "Cross-platform TUI (terminal UI) for chatting with Ollama models written in Rust.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "keyboard shortcuts",
      "conversation history",
      "themes",
      "single binary"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/fredrikaverpil/ollama-copilot",
    "summary": "GitHub Copilot-style VS Code extension that uses local Ollama models for inline suggestions.",
    "source": "github",
    "date": "2024-05-16",
    "highlights": [
      "VS Code marketplace",
      "inline completions",
      "configurable model",
      "offline"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/otwld/ollama-helm",
    "summary": "Production-ready Helm chart for deploying Ollama on Kubernetes with GPU support.",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "autoscaling",
      "PVC for models",
      "nodeSelector GPU",
      "Prometheus metrics"
    ]
  },
  {
    "title": "ollama-docker-compose",
    "url": "https://github.com/ollama/ollama/tree/main/docker",
    "summary": "Official Docker Compose stacks (CPU & GPU) for running Ollama plus optional web UI containers.",
    "source": "github",
    "date": "2024-05-20",
    "highlights": [
      "one-liner GPU",
      "CUDA/ROCm images",
      "volumes for cache",
      "rootless"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/ollama/ollama-haystack",
    "summary": "Haystack integration by deepset: use Ollama models as generators or embedders in Haystack pipelines.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "pip install ollama-haystack",
      "RAG ready",
      "streaming support",
      "HuggingFace compat"
    ]
  },
  {
    "title": "ollama-csharp",
    "url": "https://github.com/awaescher/ollama-csharp",
    "summary": ".NET 8 SDK for Ollama with strongly-typed models, dependency injection, and streaming IAsyncEnumerable.",
    "source": "github",
    "date": "2024-05-13",
    "highlights": [
      "NuGet OllamaSharp",
      "ASP.NET sample",
      "Blazor chat",
      "unit-tested"
    ]
  },
  {
    "title": "ollama-rag",
    "url": "https://github.com/ivanfioravanti/ollama-rag",
    "summary": "Ready-to-run RAG template using Ollama embeddings + Chroma vector DB + Streamlit UI.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "docker-compose",
      "PDF ingestion",
      "citations",
      "dark mode"
    ]
  },
  {
    "title": "ollama-discord-bot",
    "url": "https://github.com/mxyng/ollama-discord",
    "summary": "Self-hostable Discord bot that brings local Ollama models into any server with slash commands.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "slash commands",
      "thread support",
      "role-based access",
      "typing indicators"
    ]
  },
  {
    "title": "ollama-nix",
    "url": "https://github.com/NixOS/nixpkgs/pull/293847",
    "summary": "Ollma packaged for NixOS; merged into nixpkgs unstable for declarative GPU/CPU installs.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "nix-shell",
      "CUDA optional",
      "systemd service",
      "declarative models"
    ]
  },
  {
    "title": "ollama-elixir",
    "url": "https://github.com/beam-community/ollama-elixir",
    "summary": "Elixir wrapper around Ollama\u2019s REST API with GenServer-based process pooling and Telemetry events.",
    "source": "github",
    "date": "2024-05-04",
    "highlights": [
      "Hex pm ollama",
      "LiveView example",
      "backoff retries",
      "telemetry metrics"
    ]
  },
  {
    "title": "ollama-sdks",
    "url": "https://github.com/ollama/ollama/tree/main/api",
    "summary": "OpenAPI spec and auto-generated SDK stubs for community-maintained language wrappers.",
    "source": "github",
    "date": "2024-05-20",
    "highlights": [
      "OpenAPI 3.1",
      "codegen examples",
      "community PRs welcome",
      "MIT license"
    ]
  },
  {
    "title": "ollama-camunda",
    "url": "https://github.com/camunda-community-hub/ollama-camunda",
    "summary": "Camunda 8 connector that invokes Ollama models inside BPMN processes for human-task summarization.",
    "source": "github",
    "date": "2024-05-03",
    "highlights": [
      "element-template",
      "zero Java code",
      "Docker image",
      "BPMN example"
    ]
  },
  {
    "title": "ollama-distroless",
    "url": "https://github.com/chainguard-dev/ollama-distroless",
    "summary": "Distroless minimal container image for Ollama by Chainguard: smaller attack surface and faster pulls.",
    "source": "github",
    "date": "2024-05-02",
    "highlights": [
      "< 40 MB",
      "no shell",
      "SBOM attached",
      "signed with cosign"
    ]
  }
]