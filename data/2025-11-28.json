[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: run Llama 2, Mistral, Gemma and other large language models locally with a simple CLI and REST API.",
    "source": "github",
    "date": "2024-06-10",
    "highlights": [
      "self-contained binary",
      "model library",
      "REST & CLI",
      "macOS/Linux/Windows"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python SDK for Ollama; chat, embed, pull and manage models in a few lines of code.",
    "source": "github",
    "date": "2024-06-05",
    "highlights": [
      "pip install ollama",
      "sync/async clients",
      "embedding support"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Node and browsers; identical API surface to the Python SDK.",
    "source": "github",
    "date": "2024-06-07",
    "highlights": [
      "npm i ollama",
      "Promise-based",
      "TypeScript types"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/langchain-ollama",
    "summary": "LangChain integration package letting you use any Ollama model as an LLM or chat node.",
    "source": "github",
    "date": "2024-06-03",
    "highlights": [
      "pip install langchain-ollama",
      "streaming",
      "callback support"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich chat WebUI (formerly Ollama WebUI) that talks to the local Ollama API; no backend code needed.",
    "source": "github",
    "date": "2024-06-09",
    "highlights": [
      "Docker image",
      "multi-model chats",
      "code highlighting",
      "RAG uploads"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java/Kotlin client for Ollama; supports chat, completions, embeddings and model management.",
    "source": "github",
    "date": "2024-05-28",
    "highlights": [
      "Maven Central",
      "async & blocking APIs",
      "Spring Boot starter"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/sugarforever/ollama-cli",
    "summary": "Rust-based interactive CLI that wraps Ollama with conversation memory and syntax highlighting.",
    "source": "github",
    "date": "2024-05-30",
    "highlights": [
      "cross-platform binary",
      "conversation persistence",
      "themes"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama/ollama-copilot",
    "summary": "VS Code extension that turns any Ollama model into a GitHub Copilot-like inline assistant.",
    "source": "github",
    "date": "2024-06-02",
    "highlights": [
      "inline completions",
      "configurable model",
      "status-bar toggle"
    ]
  },
  {
    "title": "ollama-rag",
    "url": "https://github.com/ollama/ollama-rag",
    "summary": "Minimal retrieval-augmented-generation template using Ollama + Chroma + LangChain in a single Docker compose.",
    "source": "github",
    "date": "2024-06-01",
    "highlights": [
      "PDF ingestion",
      "vector DB",
      "streamed answers"
    ]
  },
  {
    "title": "ollama-telegram",
    "url": "https://github.com/ruecat/ollama-telegram",
    "summary": "Self-hostable Telegram bot that forwards messages to a local Ollama instance and streams replies.",
    "source": "github",
    "date": "2024-05-25",
    "highlights": [
      "streaming replies",
      "/model switch",
      "group-chat whitelist"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/ollama/ollama-haystack",
    "summary": "Haystack integration by Ollama; use local models as generators or embedders in Haystack pipelines.",
    "source": "github",
    "date": "2024-05-29",
    "highlights": [
      "pip install ollama-haystack",
      "generator & embedder nodes"
    ]
  },
  {
    "title": "ollama-nim",
    "url": "https://github.com/llama-nim/ollama-nim",
    "summary": "Nim wrapper for the Ollama REST API with ergonomic procedures for chat, pull and delete.",
    "source": "github",
    "date": "2024-05-20",
    "highlights": [
      "Nimble package",
      "static binary",
      "zero deps"
    ]
  },
  {
    "title": "ollama-csharp",
    "url": "https://github.com/awaescher/OllamaSharp",
    "summary": ".NET library that wraps the Ollama API with async methods and strongly-typed models.",
    "source": "github",
    "date": "2024-06-04",
    "highlights": [
      "NuGet package",
      "streaming chat",
      "dependency injection ready"
    ]
  },
  {
    "title": "ollama-docker",
    "url": "https://github.com/ollama/ollama/tree/main/docker",
    "summary": "Official Docker image and compose examples for running Ollama + GPU or CPU containers.",
    "source": "github",
    "date": "2024-06-08",
    "highlights": [
      "CUDA support",
      "rootless mode",
      "multi-arch"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/otwld/ollama-helm",
    "summary": "Community-maintained Helm chart to deploy Ollama on Kubernetes with GPU node selection.",
    "source": "github",
    "date": "2024-05-27",
    "highlights": [
      "GPU nodeSelector",
      "PVC for models",
      "autoscaling"
    ]
  },
  {
    "title": "ollama-rust",
    "url": "https://github.com/ollama/ollama-rust",
    "summary": "Official Rust crate providing low-level generated bindings and high-level async client for Ollama.",
    "source": "github",
    "date": "2024-06-06",
    "highlights": [
      "crates.io",
      "tokio support",
      "serde models"
    ]
  },
  {
    "title": "ollama-kit",
    "url": "https://github.com/ollama/ollama-kit",
    "summary": "Swift Package for iOS/macOS apps to chat with local Ollama instances over HTTP.",
    "source": "github",
    "date": "2024-05-31",
    "highlights": [
      "Swift Package Manager",
      "async/await",
      "Combine publishers"
    ]
  },
  {
    "title": "ollama-django",
    "url": "https://github.com/slayer/ollama-django",
    "summary": "Reusable Django app exposing Ollama models as async streaming HTTP endpoints with admin UI.",
    "source": "github",
    "date": "2024-05-22",
    "highlights": [
      "Django admin integration",
      "server-sent events",
      "chat history"
    ]
  },
  {
    "title": "ollama-discord",
    "url": "https://github.com/mxyng/ollama-discord",
    "summary": "Lightweight Python bot bringing Ollama models into Discord threads with slash commands and streaming.",
    "source": "github",
    "date": "2024-05-26",
    "highlights": [
      "slash commands",
      "/model list",
      "typing indicator"
    ]
  },
  {
    "title": "ollama-model-library",
    "url": "https://github.com/ollama/ollama-model-library",
    "summary": "Community-curated collection of Modelfile recipes for fine-tuned and niche models ready to import.",
    "source": "github",
    "date": "2024-06-01",
    "highlights": [
      "Modelfile PR workflow",
      " quantized recipes",
      "license tags"
    ]
  }
]