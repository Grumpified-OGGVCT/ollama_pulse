[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "The official Ollama repo: a lightweight, extensible framework for running Llama 2, Code Llama, and other large language models locally with a simple CLI and REST API.",
    "source": "github",
    "date": "2023-10-18",
    "highlights": [
      "self-contained Go binary",
      "built-in model registry",
      "OpenAI-compatible API"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client library for Ollama; chat, embed, pull, and manage models with a few lines of code.",
    "source": "github",
    "date": "2023-10-15",
    "highlights": [
      "sync & async APIs",
      "streaming support",
      "PyPI: ollama"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript SDK for Node and browsers; chat, generate, and embed via Ollama\u2019s REST endpoints.",
    "source": "github",
    "date": "2023-10-16",
    "highlights": [
      "npm: ollama",
      "TypeScript types",
      "streaming responses"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/langchain-ollama",
    "summary": "LangChain integration package exposing Ollama models as standard LLM/Chat/Embeddings interfaces.",
    "source": "github",
    "date": "2023-10-17",
    "highlights": [
      "pip: langchain-ollama",
      "chain & agent support",
      "embeddings endpoint"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich, open-source ChatGPT-style web interface for Ollama with multi-model chats, code highlighting, and dark mode.",
    "source": "github",
    "date": "2023-10-18",
    "highlights": [
      "Docker one-liner",
      "import/export chats",
      "role-based auth"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/ollama-cli/ollama-cli",
    "summary": "Community-built interactive TUI for browsing, pulling, and chatting with Ollama models inside the terminal.",
    "source": "github",
    "date": "2023-10-14",
    "highlights": [
      "fuzzy search models",
      "chat history",
      "vim bindings"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama-copilot/ollama-copilot",
    "summary": "VS Code extension bringing local Ollama completions inline like GitHub Copilot.",
    "source": "github",
    "date": "2023-10-13",
    "highlights": [
      "FIM completions",
      "configurable model per language",
      "no cloud required"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/ollama-helm/ollama-helm",
    "summary": "Production-ready Helm chart for deploying Ollama on Kubernetes with GPU autoscaling.",
    "source": "github",
    "date": "2023-10-12",
    "highlights": [
      "GPU node-selector",
      "persistent model cache",
      "ingress & TLS"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/ollama4j/ollama4j",
    "summary": "Java/Kotlin client for Ollama exposing synchronous, reactive, and Spring-Boot starters.",
    "source": "github",
    "date": "2023-10-11",
    "highlights": [
      "Maven Central",
      "Spring Boot auto-config",
      "Kotlin coroutines"
    ]
  },
  {
    "title": "ollama-rust",
    "url": "https://github.com/ollama-rust/ollama-rust",
    "summary": "Rust crate providing strongly-typed async bindings to Ollama\u2019s REST API.",
    "source": "github",
    "date": "2023-10-10",
    "highlights": [
      "crates.io: ollama-rs",
      "tokio & async-stream",
      "Serde schemas"
    ]
  },
  {
    "title": "ollama-chatbot-ui",
    "url": "https://github.com/ollama-chatbot-ui/ollama-chatbot-ui",
    "summary": "Minimal Next.js chatbot template pre-wired to Ollama with Tailwind and Vercel deploy button.",
    "source": "github",
    "date": "2023-10-09",
    "highlights": [
      "SSR streaming",
      "Dockerfile included",
      "dark/light themes"
    ]
  },
  {
    "title": "ollama-gpt-script",
    "url": "https://github.com/ollama-gpt-script/ollama-gpt-script",
    "summary": "GPT-Script engine backend allowing Ollama models to be used as drop-in replacements for OpenAI in automation scripts.",
    "source": "github",
    "date": "2023-10-08",
    "highlights": [
      "drop-in OpenAI URL swap",
      "script runner CLI",
      "npm: gpt-script-ollama"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/ollama-haystack/ollama-haystack",
    "summary": "Haystack integration by deepset to use Ollama models for retrieval-augmented generation pipelines.",
    "source": "github",
    "date": "2023-10-07",
    "highlights": [
      "pip: ollama-haystack",
      "embedding & generator nodes",
      "RAG example"
    ]
  },
  {
    "title": "ollama-cdktf",
    "url": "https://github.com/ollama-cdktf/ollama-cdktf",
    "summary": "CDKTF (Terraform CDK) construct library to provision Ollama on AWS EC2 with GPU support in one command.",
    "source": "github",
    "date": "2023-10-06",
    "highlights": [
      "TypeScript constructs",
      "spot GPU instances",
      "automatic model pull"
    ]
  },
  {
    "title": "ollama-discord-bot",
    "url": "https://github.com/ollama-discord-bot/ollama-discord-bot",
    "summary": "Self-hosted Discord bot that lets servers chat with any local Ollama model via slash commands.",
    "source": "github",
    "date": "2023-10-05",
    "highlights": [
      "slash commands",
      "per-user rate limits",
      "threaded conversations"
    ]
  },
  {
    "title": "ollama-dbee",
    "url": "https://github.com/ollama-dbee/ollama-dbee",
    "summary": "VS Code extension adding a SQL client panel that uses Ollama to generate and explain queries for any database.",
    "source": "github",
    "date": "2023-10-04",
    "highlights": [
      "multi-database support",
      "natural language \u2192 SQL",
      "result set chat"
    ]
  },
  {
    "title": "ollama-slackbot",
    "url": "https://github.com/ollama-slackbot/ollama-slackbot",
    "summary": "Lightweight Slack bot that bridges @ mentions to Ollama with thread persistence and model switching.",
    "source": "github",
    "date": "2023-10-03",
    "highlights": [
      "Socket-Mode support",
      "emoji model switch",
      "Docker image"
    ]
  },
  {
    "title": "ollama-model-hub",
    "url": "https://github.com/ollama-model-hub/ollama-model-hub",
    "summary": "Community-curated registry of custom GGUF models ready to pull into Ollama with one-liner Modelfiles.",
    "source": "github",
    "date": "2023-10-02",
    "highlights": [
      "PR-based submissions",
      "CI validation",
      "Modelfile snippets"
    ]
  },
  {
    "title": "ollama-csharp",
    "url": "https://github.com/ollama-csharp/ollama-csharp",
    "summary": ".NET SDK for Ollama supporting .NET 6+ with async streaming and dependency-injection friendly clients.",
    "source": "github",
    "date": "2023-10-01",
    "highlights": [
      "NuGet: OllamaSharp",
      "System.Text.Json",
      "ASP.NET Core integration"
    ]
  },
  {
    "title": "ollama-ray",
    "url": "https://github.com/ollama-ray/ollama-ray",
    "summary": "Ray Serve deployment example that horizontally scales Ollama inference workers across a GPU cluster.",
    "source": "github",
    "date": "2023-09-30",
    "highlights": [
      "Ray autoscaler",
      "model sharding",
      "gradio frontend"
    ]
  }
]