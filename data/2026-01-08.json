[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: get up and running with Llama 3, Mistral, Gemma and other large language models locally.",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "self-contained binary",
      "macOS/Linux/Windows",
      "Docker image",
      "built-in model registry"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python SDK for Ollama; chat, embed, pull and manage local models with a few lines of code.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "pip install ollama",
      "sync/async clients",
      "streaming responses",
      "embedding support"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Ollama; works in Node, Bun, Deno and modern browsers.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "npm install ollama",
      "Promise & stream APIs",
      "TypeScript types included",
      "browser compatible"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/ollama",
    "summary": "LangChain integration layer exposing Ollama models as LLM, chat and embedding components.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "pip install langchain-ollama",
      "unified LLM/Chat/Embeddings interfaces",
      "callback support"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich web UI for Ollama (chat UI, model management, multi-user, OpenAI-compatible endpoints).",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "docker-compose one-liner",
      "dark/light themes",
      "code-highlighting",
      "role-based auth"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/effortlessdev/ollama-cli",
    "summary": "Interactive CLI wrapper around Ollama with chat history, syntax highlighting and prompt templates.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "readline history",
      "prompt snippets",
      "markdown rendering",
      "configurable shortcuts"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/fredyk/westack-ollama-copilot",
    "summary": "VS Code extension that turns any Ollama model into a GitHub Copilot-like pair-programmer.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "inline completions",
      "custom model pick",
      "FIM template support",
      "status-bar indicator"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/otwld/ollama-helm",
    "summary": "Production-ready Helm chart for deploying Ollama on Kubernetes with GPU and persistence options.",
    "source": "github",
    "date": "2024-05-04",
    "highlights": [
      "GPU node-selector",
      "PVC for model cache",
      "ingress & HPA",
      "configurable probes"
    ]
  },
  {
    "title": "ollama-docker",
    "url": "https://github.com/ggerganov/ollama-docker",
    "summary": "Lightweight multi-arch Docker image for Ollama with CUDA and CPU-only variants.",
    "source": "github",
    "date": "2024-05-03",
    "highlights": [
      "cuda11/12 layers",
      "multi-arch build",
      "runtime model pull",
      "docker-compose examples"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java/JVM SDK for Ollama supporting synchronous, reactive and streaming APIs.",
    "source": "github",
    "date": "2024-05-02",
    "highlights": [
      "Maven Central",
      "Spring Boot starter",
      "Kotlin extensions",
      "async streaming"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/fuyutar/ollama-rb",
    "summary": "Ruby gem providing idiomatic access to the Ollama API with concurrent streaming support.",
    "source": "github",
    "date": "2024-05-01",
    "highlights": [
      "gem install ollama-rb",
      "Fiber-based streaming",
      "ActiveModel-like DSL",
      "Rails integration"
    ]
  },
  {
    "title": "ollama-cpp",
    "url": "https://github.com/jmorganca/ollama-cpp",
    "summary": "Minimal C/C++ header-only client for embedded or high-performance integrations with Ollama.",
    "source": "github",
    "date": "2024-04-30",
    "highlights": [
      "header-only",
      "zero deps",
      "C++17",
      "CMake fetchcontent ready"
    ]
  },
  {
    "title": "ollama-csharp",
    "url": "https://github.com/awaescher/ollama-csharp",
    "summary": ".NET SDK for Ollama with strong typing, dependency-injection helpers and Blazor sample.",
    "source": "github",
    "date": "2024-04-29",
    "highlights": [
      "nuget OllamaSharp",
      "DI extensions",
      "Blazor chat demo",
      "streaming IAsyncEnumerable"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/deepset-ai/haystack-ollama",
    "summary": "Haystack integration letting you use Ollama models as generators or embedders in RAG pipelines.",
    "source": "github",
    "date": "2024-04-28",
    "highlights": [
      "pip install haystack-ollama",
      "RAG ready",
      "prompt node",
      "embedding node"
    ]
  },
  {
    "title": "ollama-camunda",
    "url": "https://github.com/camunda-community-hub/ollama-camunda",
    "summary": "Camunda Connectors that invoke Ollama models from BPMN processes for AI-powered workflows.",
    "source": "github",
    "date": "2024-04-27",
    "highlights": [
      "outbound connector",
      "FEEL expression support",
      "model versioning",
      "task worker example"
    ]
  },
  {
    "title": "ollama-discord",
    "url": "https://github.com/mxyng/ollama-discord",
    "summary": "Self-hostable Discord bot that streams Ollama chat completions with slash-command support.",
    "source": "github",
    "date": "2024-04-26",
    "highlights": [
      "slash commands",
      "streaming replies",
      "per-guild model config",
      "typing indicators"
    ]
  },
  {
    "title": "ollama-slack",
    "url": "https://github.com/seriousme/ollama-slack",
    "summary": "Slack Bolt app bringing Ollama models into channels via mentions or app-commands.",
    "source": "github",
    "date": "2024-04-25",
    "highlights": [
      "socket mode",
      "mention trigger",
      "threaded replies",
      "rate-limit per user"
    ]
  },
  {
    "title": "ollama-obsidian",
    "url": "https://github.com/hintergrund/ollama-obsidian",
    "summary": "Obsidian plugin that adds AI autocomplete, summarization and semantic search backed by Ollama.",
    "source": "github",
    "date": "2024-04-24",
    "highlights": [
      "editor autocomplete",
      "note summarization",
      "local embeddings",
      "command palette"
    ]
  },
  {
    "title": "ollama-npm",
    "url": "https://www.npmjs.com/package/ollama",
    "summary": "Official npm package download page for the Ollama JavaScript/TypeScript client.",
    "source": "npm",
    "date": "2024-05-09",
    "highlights": [
      "zero runtime deps",
      "ESM & CJS",
      "typedoc docs",
      "weekly >20k downloads"
    ]
  },
  {
    "title": "ollama-pypi",
    "url": "https://pypi.org/project/ollama/",
    "summary": "Official PyPI page for the Ollama Python SDK with quickstart and model examples.",
    "source": "pypi",
    "date": "2024-05-10",
    "highlights": [
      "python \u22653.8",
      "wheel distro",
      "pepy 40k+ weekly",
      "rich CLI examples"
    ]
  }
]