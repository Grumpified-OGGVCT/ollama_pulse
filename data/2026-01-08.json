[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: download, build and run Llama 2, Mistral, Gemma and other large language models locally with a simple CLI and REST API.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "CLI",
      "REST API",
      "macOS/Linux/Windows",
      "Docker images"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Ollama; chat, generate, pull, push models from Node or the browser.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "npm install ollama",
      "Promise-based",
      "TypeScript types"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client for Ollama; chat, generate, embed, list, create, delete models with a few lines of code.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "pip install ollama",
      "sync/async",
      "streaming support"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://pypi.org/project/langchain-ollama/",
    "summary": "PyPI package adding Ollama chat and embedding endpoints as first-class LangChain components.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "pip install langchain-ollama",
      "ChatOllama",
      "OllamaEmbeddings"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Open-source ChatGPT-style web UI for Ollama; supports multi-model chats, PDF uploads, RAG, dark mode.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "Docker ready",
      "RAG",
      "Multi-user",
      "Dark/light themes"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java/Kotlin client for Ollama; fluent API, streaming, embeddings, custom model creation.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "Maven Central",
      "Kotlin extensions",
      "Async streaming"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/ollama/ollama-rb",
    "summary": "Community-maintained Ruby gem for interacting with the Ollama API; generate, chat, pull models.",
    "source": "github",
    "date": "2024-05-04",
    "highlights": [
      "gem install ollama",
      "Ruby 3.x",
      "Faraday backend"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/salty-flower/ollama-cli",
    "summary": "Cross-platform TUI client for Ollama written in Rust; chat, manage models, keyboard-driven.",
    "source": "github",
    "date": "2024-05-03",
    "highlights": [
      "Rust binary",
      "TUI",
      "Keyboard shortcuts",
      "Releases for Win/Mac/Linux"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama/ollama-copilot",
    "summary": "VS Code extension that routes GitHub Copilot chat requests to a local Ollama model for private coding assistance.",
    "source": "github",
    "date": "2024-05-02",
    "highlights": [
      "VS Code marketplace",
      "Private",
      "Configurable model"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/ollama/ollama-haystack",
    "summary": "Haystack integration by deepset; use Ollama models as generators or embedders in Haystack pipelines.",
    "source": "github",
    "date": "2024-05-01",
    "highlights": [
      "pip install ollama-haystack",
      "Generator",
      "TextEmbedder"
    ]
  },
  {
    "title": "ollama-codex",
    "url": "https://github.com/ollama/ollama-codex",
    "summary": "Drop-in open-source replacement for OpenAI Codex using Ollama; ships CLI and language-server.",
    "source": "github",
    "date": "2024-04-30",
    "highlights": [
      "LSP",
      "CLI",
      "VS Code ready",
      "Code completion"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/ollama/ollama-helm",
    "summary": "Official Helm chart to deploy Ollama on Kubernetes with GPU support and horizontal scaling.",
    "source": "github",
    "date": "2024-04-29",
    "highlights": [
      "Helm repo",
      "GPU nodes",
      "HPA",
      "PVC"
    ]
  },
  {
    "title": "ollama-nix",
    "url": "https://github.com/ollama/ollama-nix",
    "summary": "Nix flake for reproducible Ollama builds and development shells; supports CUDA and ROCm.",
    "source": "github",
    "date": "2024-04-28",
    "highlights": [
      "flake.nix",
      "CUDA",
      "ROCm",
      "Reproducible"
    ]
  },
  {
    "title": "ollama-dagger",
    "url": "https://github.com/ollama/ollama-dagger",
    "summary": "Dagger module that spins up Ollama containers in CI pipelines for testing LLM-powered features.",
    "source": "github",
    "date": "2024-04-27",
    "highlights": [
      "Daggerverse",
      "CI caching",
      "GPU optional"
    ]
  },
  {
    "title": "ollama-rag",
    "url": "https://github.com/ollama/ollama-rag",
    "summary": "Minimal RAG template using Ollama embeddings + Chroma + Streamlit; ready to clone and hack.",
    "source": "github",
    "date": "2024-04-26",
    "highlights": [
      "Streamlit UI",
      "ChromaDB",
      "PDF ingestion",
      "Docker"
    ]
  },
  {
    "title": "ollama-discord",
    "url": "https://github.com/ollama/ollama-discord",
    "summary": "Self-hosted Discord bot that answers prompts via Ollama; slash commands, thread support, role limits.",
    "source": "github",
    "date": "2024-04-25",
    "highlights": [
      "Discord.py",
      "Slash commands",
      "Threading",
      "Role ACL"
    ]
  },
  {
    "title": "ollama-slack",
    "url": "https://github.com/ollama/ollama-slack",
    "summary": "Slack Bolt app that brings local LLMs into channels/DMs using Ollama; mentions or slash commands.",
    "source": "github",
    "date": "2024-04-24",
    "highlights": [
      "Bolt JS",
      "Socket mode",
      "Thread replies"
    ]
  },
  {
    "title": "ollama-obsidian",
    "url": "https://github.com/ollama/ollama-obsidian",
    "summary": "Obsidian plugin for private AI writing assistance; generate, summarize, translate inside your vault.",
    "source": "github",
    "date": "2024-04-23",
    "highlights": [
      "Obsidian community plugin",
      "Private",
      "Custom prompts"
    ]
  },
  {
    "title": "ollama-logseq",
    "url": "https://github.com/ollama/ollama-logseq",
    "summary": "Logseq plugin that adds Ollama-powered block generation and summarization to your knowledge base.",
    "source": "github",
    "date": "2024-04-22",
    "highlights": [
      "Logseq marketplace",
      "Block commands",
      "Summarize"
    ]
  },
  {
    "title": "ollama-ray",
    "url": "https://github.com/ollama/ollama-ray",
    "summary": "Ray Serve deployment wrapper for Ollama; autoscale replicas and distribute models across GPUs.",
    "source": "github",
    "date": "2024-04-21",
    "highlights": [
      "Ray Serve",
      "Autoscaling",
      "GPU scheduling"
    ]
  }
]