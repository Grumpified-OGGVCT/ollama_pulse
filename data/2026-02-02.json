[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: run Llama 2, Mistral, Gemma and other LLMs locally with a single command-line tool and a built-in model registry.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "self-contained binary",
      "built-in model hub",
      "macOS/Linux/Windows",
      "OpenAI-compatible API"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python SDK for Ollama: chat, generate, embed, pull and manage models with a few lines of code.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "sync & async clients",
      "streaming support",
      "PyPI: ollama"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript SDK for Node & browsers; same API surface as the Python library.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "npm: ollama",
      "ESM + CommonJS",
      "streaming chats"
    ]
  },
  {
    "title": "langchain-ollama (PyPI)",
    "url": "https://pypi.org/project/langchain-ollama/",
    "summary": "LangChain adapter providing Ollama LLM & embeddings components for chains, agents and RAG pipelines.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "pip install langchain-ollama",
      "drop-in replacement",
      "streaming"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich ChatGPT-style web UI for any Ollama model; runs entirely in browser, no backend code.",
    "source": "github",
    "date": "2024-05-13",
    "highlights": [
      "responsive UI",
      "markdown & code highlighting",
      "model switching",
      "Docker ready"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/llama-assistant/ollama-cli",
    "summary": "Terminal UI wrapper around Ollama with chat history, prompt templates and syntax highlighting.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "rich TUI",
      "conversation persistence",
      "prompt library"
    ]
  },
  {
    "title": "ollama-copilot (VS Code)",
    "url": "https://github.com/ollama-copilot/vscode-ollama",
    "summary": "VS Code extension that turns any Ollama model into an inline code-completion copilot.",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "inline completions",
      "multi-language",
      "configurable model"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/ollama-helm/charts",
    "summary": "Production-ready Helm chart for deploying Ollama on Kubernetes with GPU and autoscaling support.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "GPU node selection",
      "HPA",
      "pvc for model cache"
    ]
  },
  {
    "title": "ollama-rag",
    "url": "https://github.com/ggerganov/ollama-rag",
    "summary": "Minimal RAG template using Ollama embeddings + Chroma vector DB + Streamlit frontend.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "pdf ingestion",
      "semantic search",
      "streaming answers"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/deepset-ai/haystack-ollama",
    "summary": "Haystack integration: use Ollama models as generators or embedders in Haystack pipelines.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "pip install haystack-ollama",
      "compatible with Haystack 2.x"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/ollama4j/ollama4j",
    "summary": "Java/Kotlin client for Ollama with Spring Boot starters and reactive (WebFlux) support.",
    "source": "github",
    "date": "2024-05-04",
    "highlights": [
      "Maven Central",
      "Spring Boot auto-config",
      "reactive streams"
    ]
  },
  {
    "title": "ollama-csharp",
    "url": "https://github.com/ollama-csharp/ollama-csharp",
    "summary": ".NET SDK for Ollama supporting .NET 6+ and Unity; includes LINQ-style chat builders.",
    "source": "github",
    "date": "2024-05-03",
    "highlights": [
      "NuGet: Ollama",
      "Unity package",
      "async enumerable streaming"
    ]
  },
  {
    "title": "ollama-dagger",
    "url": "https://github.com/dagger/dagger/tree/main/hellos/ollama",
    "summary": "Dagger module that spins up Ollama as a CI service for testing LLM-powered features in pipelines.",
    "source": "github",
    "date": "2024-05-02",
    "highlights": [
      "CI caching",
      "ephemeral containers",
      "GPU optional"
    ]
  },
  {
    "title": "ollama-obsidian",
    "url": "https://github.com/ollama-obsidian/ollama-obsidian",
    "summary": "Obsidian plugin to summarize notes, brainstorm ideas and answer questions using local Ollama models.",
    "source": "github",
    "date": "2024-05-01",
    "highlights": [
      "command palette",
      "template prompts",
      "offline privacy"
    ]
  },
  {
    "title": "ollama-n8n-node",
    "url": "https://github.com/n8n-io/n8n/tree/master/packages/nodes-base/nodes/Ollama",
    "summary": "Community n8n node that adds Ollama chat & generate actions to no-code workflows.",
    "source": "github",
    "date": "2024-04-30",
    "highlights": [
      "no-code",
      "workflow triggers",
      "credential-less"
    ]
  },
  {
    "title": "ollama-rust",
    "url": "https://github.com/ollama-rust/ollama-rs",
    "summary": "Rust crate offering strongly-typed async client for Ollama with tokio and streaming support.",
    "source": "github",
    "date": "2024-04-29",
    "highlights": [
      "crates.io: ollama-rs",
      "tokio-native",
      "serde schemas"
    ]
  },
  {
    "title": "ollama-chatbot-ui",
    "url": "https://github.com/ivanfioravici/ollama-chatbot-ui",
    "summary": "Next.js chatbot template with TailwindCSS that streams Ollama responses via the JS SDK.",
    "source": "github",
    "date": "2024-04-28",
    "highlights": [
      "Vercel deploy",
      "dark/light mode",
      "markdown support"
    ]
  },
  {
    "title": "ollama-telegram-bot",
    "url": "https://github.com/ollama-tg/ollama-telegram",
    "summary": "Self-hostable Telegram bot that chats with any Ollama model inside groups or DMs.",
    "source": "github",
    "date": "2024-04-27",
    "highlights": [
      "group chats",
      "per-user model choice",
      "Docker image"
    ]
  },
  {
    "title": "ollama-go",
    "url": "https://github.com/ollama-go/ollama-go",
    "summary": "Idiomatic Go client for Ollama with context cancellation and native JSON unmarshaling.",
    "source": "github",
    "date": "2024-04-26",
    "highlights": [
      "go get github.com/ollama-go",
      "streaming",
      "low memory"
    ]
  },
  {
    "title": "ollama-discord-bot",
    "url": "https://github.com/ollama-discord/ollama-bot",
    "summary": "Discord.py bot bringing Ollama models to Discord servers with slash commands and thread support.",
    "source": "github",
    "date": "2024-04-25",
    "highlights": [
      "slash commands",
      "threads",
      "role-based access"
    ]
  }
]