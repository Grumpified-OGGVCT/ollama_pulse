[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama project: Get up and running with Llama 3, Mistral, Gemma, and other large language models locally.",
    "source": "github",
    "date": "2024-05-15",
    "highlights": [
      "CLI & REST API",
      "Model library",
      "macOS/Linux/Windows support"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript SDK for Ollama. Chat with local LLMs from Node.js or browsers.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "npm package",
      "Promise-based API",
      "TypeScript definitions"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python library for Ollama. Simple interface to pull, run, and chat with models.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "PyPI package",
      "Streaming responses",
      "Async support"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/partners/ollama",
    "summary": "LangChain integration for Ollama. Use Ollama models as LangChain LLMs, embeddings, and chat endpoints.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "LangChain partner package",
      "Embeddings support",
      "Chat model wrapper"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich web UI for Ollama. Chat interface, model management, multimodal support, and admin panel.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "Docker image",
      "OpenAI-compatible API",
      "RAG & file upload"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java SDK for Ollama. Integrate local LLMs into Java/Kotlin/Spring Boot applications.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "Maven Central",
      "Async & sync APIs",
      "Spring Boot starter"
    ]
  },
  {
    "title": "ollama-rs",
    "url": "https://github.com/pepperoni21/ollama-rs",
    "summary": "Rust crate for Ollama. Type-safe client with async support and streaming chat.",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "crates.io",
      "Tokio async",
      "Serde models"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama/ollama-copilot",
    "summary": "VS Code extension that brings Ollama models into GitHub Copilot chat.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "VS Code marketplace",
      "Inline chat",
      "Custom model selection"
    ]
  },
  {
    "title": "ollama-chat",
    "url": "https://github.com/jmorganca/ollama-chat",
    "summary": "Minimal React chat app for Ollama. Demonstrates streaming chat with Next.js and Tailwind.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "Next.js",
      "Server-sent events",
      "Responsive UI"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/deepset-ai/haystack-integrations/tree/main/integrations/ollama",
    "summary": "Haystack integration for Ollama. Use local models in Haystack pipelines for RAG and question answering.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "Haystack 2.0 support",
      "Generator & embedder nodes",
      "Pipeline YAML"
    ]
  },
  {
    "title": "ollama-discord",
    "url": "https://github.com/ollama/ollama-discord",
    "summary": "Discord bot that streams Ollama model responses into any Discord channel.",
    "source": "github",
    "date": "2024-05-04",
    "highlights": [
      "Slash commands",
      "Thread support",
      "Model switching"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/ollama/ollama-cli",
    "summary": "Enhanced CLI for Ollama with interactive REPL, conversation history, and syntax highlighting.",
    "source": "github",
    "date": "2024-05-03",
    "highlights": [
      "REPL mode",
      "History file",
      "Markdown rendering"
    ]
  },
  {
    "title": "ollama-streamlit",
    "url": "https://github.com/suyash/ollama-streamlit",
    "summary": "Streamlit chat interface for Ollama. Upload PDFs and chat with RAG using local embeddings.",
    "source": "github",
    "date": "2024-05-02",
    "highlights": [
      "PDF ingestion",
      "Chroma vector DB",
      "Session memory"
    ]
  },
  {
    "title": "ollama-n8n",
    "url": "https://github.com/n8n-io/n8n/tree/master/packages/nodes-base/nodes/Ollama",
    "summary": "n8n node for Ollama. Add local LLM steps to no-code workflows with credentials management.",
    "source": "github",
    "date": "2024-05-01",
    "highlights": [
      "n8n community node",
      "Credential encryption",
      "Workflow triggers"
    ]
  },
  {
    "title": "ollama-rust",
    "url": "https://github.com/ollama-rs/ollama-rs",
    "summary": "Community Rust client for Ollama. Focuses on ergonomic APIs and comprehensive model operations.",
    "source": "github",
    "date": "2024-04-30",
    "highlights": [
      "Reqwest client",
      "Full model ops",
      "Examples folder"
    ]
  },
  {
    "title": "ollama-elixir",
    "url": "https://github.com/ai-hackathon-team/ollama-elixir",
    "summary": "Elixir client for Ollama. GenServer-based wrapper with Phoenix LiveView chat example.",
    "source": "github",
    "date": "2024-04-29",
    "highlights": [
      "Hex.pm package",
      "LiveView demo",
      "GenServer pooling"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/otwld/ollama-helm",
    "summary": "Helm chart for deploying Ollama on Kubernetes with GPU support and horizontal scaling.",
    "source": "github",
    "date": "2024-04-28",
    "highlights": [
      "GPU node selector",
      "PVC for models",
      "Prometheus metrics"
    ]
  },
  {
    "title": "ollama-dart",
    "url": "https://github.com/mikeknapp/ollama-dart",
    "summary": "Dart/Flutter package for Ollama. Chat with local LLMs from mobile and desktop Flutter apps.",
    "source": "github",
    "date": "2024-04-27",
    "highlights": [
      "pub.dev",
      "Flutter example",
      "Streaming support"
    ]
  },
  {
    "title": "ollama-rag",
    "url": "https://github.com/ggerganov/ollama-rag",
    "summary": "Lightweight RAG implementation using Ollama for embeddings and generation with SQLite vector search.",
    "source": "github",
    "date": "2024-04-26",
    "highlights": [
      "SQLite vec0 extension",
      "Incremental indexing",
      "CLI ingestion"
    ]
  },
  {
    "title": "ollama-csharp",
    "url": "https://github.com/ollama-csharp/ollama-csharp",
    "summary": ".NET SDK for Ollama. Targets .NET 6+ with async enumerables for streaming chat completions.",
    "source": "github",
    "date": "2024-04-25",
    "highlights": [
      "NuGet package",
      "System.Text.Json",
      "ASP.NET Core sample"
    ]
  }
]