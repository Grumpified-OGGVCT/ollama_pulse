[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official CLI and Python/JS bindings to pull, run, and manage large language models locally.",
    "source": "github",
    "date": "2024-05-20",
    "highlights": [
      "CLI",
      "REST API",
      "macOS/Linux/Windows",
      "GGUF support"
    ]
  },
  {
    "title": "ollama/ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Ollama; chat, generate, embed, list, pull, delete.",
    "source": "github",
    "date": "2024-05-18",
    "highlights": [
      "npm install ollama",
      "Promise-based",
      "browser/node"
    ]
  },
  {
    "title": "ollama/ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client; sync & async APIs for chat, generate, embeddings, model management.",
    "source": "github",
    "date": "2024-05-19",
    "highlights": [
      "pip install ollama",
      "asyncio",
      "streaming"
    ]
  },
  {
    "title": "jmorganca/ollama",
    "url": "https://pypi.org/project/ollama/",
    "summary": "PyPI landing page for the official ollama Python package.",
    "source": "pypi",
    "date": "2024-05-19",
    "highlights": [
      "pip install",
      "official",
      "Python 3.8+"
    ]
  },
  {
    "title": "ollama/ollama-nvidia",
    "url": "https://github.com/ollama/ollama-nvidia",
    "summary": "Experimental NVIDIA GPU integration for Ollama using TensorRT-LLM.",
    "source": "github",
    "date": "2024-05-15",
    "highlights": [
      "GPU acceleration",
      "TensorRT",
      "beta"
    ]
  },
  {
    "title": "ollama-webui/ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Open-source ChatGPT-style web UI that connects to any local Ollama instance.",
    "source": "github",
    "date": "2024-05-20",
    "highlights": [
      "React",
      "dark/light mode",
      "multi-model chat"
    ]
  },
  {
    "title": "otisg/ollama-chat",
    "url": "https://github.com/otisg/ollama-chat",
    "summary": "Minimal Express/Mithril chat app that proxies to Ollama REST API.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "Express",
      "Mithril",
      "Dockerfile"
    ]
  },
  {
    "title": "langchain-ai/langchain",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/community/langchain_community/llms/ollama",
    "summary": "LangChain community integration for Ollama LLMs and embeddings.",
    "source": "github",
    "date": "2024-05-20",
    "highlights": [
      "LangChain",
      "embeddings",
      "streaming"
    ]
  },
  {
    "title": "embedchain/embedchain",
    "url": "https://github.com/embedchain/embedchain",
    "summary": "RAG framework with built-in Ollama support for local LLM and embeddings.",
    "source": "github",
    "date": "2024-05-19",
    "highlights": [
      "RAG",
      "Chroma",
      "PDF/YouTube loaders"
    ]
  },
  {
    "title": "ollama4j/ollama4j",
    "url": "https://github.com/ollama4j/ollama4j",
    "summary": "Java/Kotlin client library for Ollama with fluent API and Spring Boot starter.",
    "source": "github",
    "date": "2024-05-17",
    "highlights": [
      "Java",
      "Kotlin",
      "Spring Boot"
    ]
  },
  {
    "title": "sammcj/ollama-chatbot",
    "url": "https://github.com/sammcj/ollama-chatbot",
    "summary": "FastAPI + Vue chatbot template that streams Ollama responses.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "FastAPI",
      "Vue",
      "streaming"
    ]
  },
  {
    "title": "r/ollama",
    "url": "https://www.reddit.com/r/ollama/",
    "summary": "Subreddit for Ollama users sharing models, tips, and integrations.",
    "source": "reddit",
    "date": "2024-05-20",
    "highlights": [
      "community",
      "models",
      "troubleshooting"
    ]
  },
  {
    "title": "ollama-models/ollama-models",
    "url": "https://github.com/ollama-models/ollama-models",
    "summary": "Community-curated list of GGUF models tested with Ollama.",
    "source": "github",
    "date": "2024-05-18",
    "highlights": [
      "GGUF",
      "Modelfile recipes",
      "quantization"
    ]
  },
  {
    "title": "mchiang/ollama-slack-bot",
    "url": "https://github.com/mchiang/ollama-slack-bot",
    "summary": "Slack bot that answers questions using a local Ollama model.",
    "source": "github",
    "date": "2024-05-13",
    "highlights": [
      "Slack",
      "Bolt",
      "slash command"
    ]
  },
  {
    "title": "ollama-hass/ollama-hass",
    "url": "https://github.com/ollama-hass/ollama-hass",
    "summary": "Home Assistant custom component to expose Ollama as a conversation agent.",
    "source": "github",
    "date": "2024-05-16",
    "highlights": [
      "Home Assistant",
      "conversation",
      "YAML config"
    ]
  },
  {
    "title": "ollama-rust/ollama-rs",
    "url": "https://github.com/ollama-rust/ollama-rs",
    "summary": "Rust crate providing async bindings to the Ollama REST API.",
    "source": "github",
    "date": "2024-05-15",
    "highlights": [
      "Rust",
      "tokio",
      "async"
    ]
  },
  {
    "title": "ollama-csharp/ollama-csharp",
    "url": "https://github.com/ollama-csharp/ollama-csharp",
    "summary": ".NET client for Ollama with chat, generate, and embeddings endpoints.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "C#",
      "NuGet",
      ".NET 6+"
    ]
  },
  {
    "title": "ollama-cli/ollama-cli",
    "url": "https://github.com/ollama-cli/ollama-cli",
    "summary": "Enhanced interactive CLI wrapper around ollama with history and syntax highlighting.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "interactive",
      "prompt-toolkit",
      "history"
    ]
  },
  {
    "title": "ollama-docker/ollama-docker",
    "url": "https://github.com/ollama-docker/ollama-docker",
    "summary": "Ready-to-run Docker Compose stacks for Ollama with GPU and CPU variants.",
    "source": "github",
    "date": "2024-05-19",
    "highlights": [
      "Docker",
      "Compose",
      "CUDA"
    ]
  },
  {
    "title": "Hacker News discussion",
    "url": "https://news.ycombinator.com/item?id=40471234",
    "summary": "Thread discussing Ollama\u2019s new Windows preview and multi-GPU support.",
    "source": "hackernews",
    "date": "2024-05-20",
    "highlights": [
      "Windows",
      "multi-GPU",
      "community"
    ]
  }
]