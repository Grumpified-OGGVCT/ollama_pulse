[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: self-contained LLM runner that bundles model weights, config and data into a single Modelfile; offers a CLI and REST API to pull, create and run Llama-2, Mistral, Gemma, etc. locally.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "CLI + REST API",
      "Modelfile packaging",
      "macOS/Linux/Windows",
      "Built-in registry"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client for Ollama; chat, generate, embed, pull, push, list models with a few lines of code.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "pip install ollama",
      "sync & async APIs",
      "embeddings support"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Node & browsers; same generate/chat/embed API surface as the Python SDK.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "npm install ollama",
      "Promise/async-await",
      "TypeScript types"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/partners/ollama",
    "summary": "LangChain integration package; drop-in LLM and embeddings interface to chain Ollama models with prompts, memory, tools, agents, etc.",
    "source": "github",
    "date": "2024-05-13",
    "highlights": [
      "pip install langchain-ollama",
      "ChatOllama & OllamaEmbeddings",
      "LCEL compatible"
    ]
  },
  {
    "title": "ollama-webui (ollama-webui/ollama-webui)",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich web UI for Ollama (formerly Ollama-WebUI); chat folders, multi-model convos, code highlighting, RAG, admin panel.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "Docker one-liner",
      "OpenAI-compatible endpoint",
      "RAG via uploads"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java/Kotlin client for Ollama; fluent builder API, async & reactive wrappers, Spring Boot starter.",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "Maven Central",
      "Kotlin coroutines",
      "Spring Boot auto-config"
    ]
  },
  {
    "title": "ollama-cli (emanuele-f/ollama-cli)",
    "url": "https://github.com/emanuele-f/ollama-cli",
    "summary": "Terminal UI wrapper (fzf, syntax highlighting, chat history) around the ollama binary for power users.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "fuzzy model picker",
      "conversation history",
      "vim bindings"
    ]
  },
  {
    "title": "ollama-copilot (cmiller01/ollama-copilot)",
    "url": "https://github.com/cmiller01/ollama-copilot",
    "summary": "GitHub Copilot-like VS-Code extension that routes completions to a local Ollama model instead of OpenAI.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "VS-Code ext",
      "inline completions",
      "configurable model"
    ]
  },
  {
    "title": "ollama-rag (zachary62/ollama-rag)",
    "url": "https://github.com/zachary62/ollama-rag",
    "summary": "Minimal RAG template; uses Ollama for both embeddings and generation, Chroma vector store, Streamlit UI.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "Streamlit chat",
      "ChromaDB",
      "pdf loader included"
    ]
  },
  {
    "title": "ollama-haystack (deepset-ai/haystack-ollama)",
    "url": "https://github.com/deepset-ai/haystack-ollama",
    "summary": "Haystack integration; OllamaGenerator and OllamaTextEmbedder nodes for building local NLP pipelines.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "pip install haystack-ollama",
      "YAML pipeline support",
      "batch embed"
    ]
  },
  {
    "title": "ollama-rs",
    "url": "https://github.com/pepperoni21/ollama-rs",
    "summary": "Community Rust crate; strongly-typed async client covering chat, generate, pull, list, embeddings.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "crates.io",
      "tokio/async",
      "serde types"
    ]
  },
  {
    "title": "ollama-csharp (awaescher/ollama-csharp)",
    "url": "https://github.com/awaescher/ollama-csharp",
    "summary": ".NET client library; chat & generate with async enumerable streaming, dependency-injection friendly.",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "NuGet package",
      "IAsyncEnumerable",
      "DI extensions"
    ]
  },
  {
    "title": "ollama-gui (stellar-amen/ollama-gui)",
    "url": "https://github.com/stellar-amen/ollama-gui",
    "summary": "Lightweight Flutter desktop app; chat interface, model manager, markdown rendering, Windows/macOS/Linux.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "Flutter cross-platform",
      "local install wizard",
      "theme switch"
    ]
  },
  {
    "title": "ollama-helm (ollama-helm/ollama-helm)",
    "url": "https://github.com/ollama-helm/ollama-helm",
    "summary": "Official Helm chart for deploying Ollama on Kubernetes with GPU support, PVC, autoscaling options.",
    "source": "github",
    "date": "2024-05-13",
    "highlights": [
      "Helm repo",
      "GPU node-selector",
      "HPA ready"
    ]
  },
  {
    "title": "ollama-docker (ai-dock/ollama-docker)",
    "url": "https://github.com/ai-dock/ollama-docker",
    "summary": "Production-ready container stack: Ollama + CUDA + WebUI + automatic model downloader, compose templates.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "CUDA base",
      "docker-compose",
      "model auto-pull"
    ]
  },
  {
    "title": "ollama-discord-bot (kristophM/ollama-discord-bot)",
    "url": "https://github.com/kristophM/ollama-discord-bot",
    "summary": "Discord.py bot that routes user prompts to a local Ollama instance; slash commands, conversation memory.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "slash commands",
      "per-user threads",
      "moderation filter"
    ]
  },
  {
    "title": "ollama-slack-bot (grantdfoster/ollama-slack-bot)",
    "url": "https://github.com/grantdfoster/ollama-slack-bot",
    "summary": "Bolt-js Slack bot; listens in channels/DM, streams Ollama responses back to thread with typing indicator.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "Socket-Mode",
      "streaming replies",
      "typing indicator"
    ]
  },
  {
    "title": "ollama-npm (npm package)",
    "url": "https://www.npmjs.com/package/ollama",
    "summary": "Official Ollama JS SDK published on npm; zero dependencies, ESM/CJS bundles, typedocs.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "npm install ollama",
      "dual ESM/CJS",
      "typedocs"
    ]
  },
  {
    "title": "ollama PyPI package",
    "url": "https://pypi.org/project/ollama/",
    "summary": "Official Python SDK on PyPI; same API as repo, wheels for macOS/Linux/Windows.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "pip install ollama",
      "universal wheels",
      "PEP-561 types"
    ]
  },
  {
    "title": "r/ollama - Reddit community",
    "url": "https://www.reddit.com/r/ollama/",
    "summary": "Active subreddit for sharing models, troubleshooting, integrations and showcase projects.",
    "source": "reddit",
    "date": "2024-05-14",
    "highlights": [
      "model sharing",
      "troubleshooting",
      "showcase"
    ]
  }
]