[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: get up and running with Llama 3.2, Mistral, Gemma 2 and other large language models locally.",
    "source": "github",
    "date": "2024-06-10",
    "highlights": [
      "self-contained binary",
      "macOS/Linux/Windows",
      "Docker image",
      "REST & Go API"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Ollama; chat, generate, embed, pull, push, list, delete models.",
    "source": "github",
    "date": "2024-06-05",
    "highlights": [
      "npm install ollama",
      "Promise-based",
      "browser & Node",
      "full API coverage"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client for Ollama; synchronous & async support, streaming, embeddings, model management.",
    "source": "github",
    "date": "2024-06-07",
    "highlights": [
      "pip install ollama",
      "async/await",
      "streaming responses",
      "built-in embeddings"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain-ollama",
    "summary": "LangChain integration package offering Ollama chat, generate and embedding components.",
    "source": "github",
    "date": "2024-06-08",
    "highlights": [
      "pip install langchain-ollama",
      "ChatOllama",
      "OllamaEmbeddings",
      "tool-calling support"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich web UI for Ollama (ChatGPT-style interface) with model management, multi-user, RAG, plugins.",
    "source": "github",
    "date": "2024-06-09",
    "highlights": [
      "Docker one-liner",
      "OpenAI-compatible API",
      "document QA",
      "voice input"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/ollama4j/ollama4j",
    "summary": "Java/Kotlin client library for Ollama; offers synchronous & async APIs, model pulling, chat, embeddings.",
    "source": "github",
    "date": "2024-06-04",
    "highlights": [
      "Maven Central",
      "Spring Boot starter",
      "Kotlin coroutines",
      "POJO mapping"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/ollama/ollama-rb",
    "summary": "Official Ruby gem for Ollama; simple interface to chat, generate, stream and manage local models.",
    "source": "github",
    "date": "2024-06-03",
    "highlights": [
      "gem install ollama",
      "streaming blocks",
      "model listing",
      "embeddings"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/technomancy/ollama-cli",
    "summary": "Rust-based interactive CLI for Ollama with syntax highlighting, history, and prompt templates.",
    "source": "github",
    "date": "2024-05-28",
    "highlights": [
      "cargo install ollama-cli",
      "readline",
      "themes",
      "configurable prompt files"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/fostermaier/ollama-copilot",
    "summary": "Visual Studio Code extension that turns Ollama models into inline code copilots with autocomplete.",
    "source": "github",
    "date": "2024-06-02",
    "highlights": [
      "inline suggestions",
      "configurable model",
      "status-bar toggle",
      "telemetry-free"
    ]
  },
  {
    "title": "ollama-chem",
    "url": "https://github.com/ncfrey/ollama-chem",
    "summary": "Python package that wraps Ollama for chemistry Q&A and molecule generation using Llama-based models.",
    "source": "github",
    "date": "2024-05-25",
    "highlights": [
      "pip install ollama-chem",
      "SMILES support",
      "PubChem lookup",
      "RDKit integration"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/ollama-haystack/ollama-haystack",
    "summary": "Haystack integration by deepset for using Ollama models as generators or embedders in RAG pipelines.",
    "source": "github",
    "date": "2024-06-01",
    "highlights": [
      "Generator & Embedder components",
      "streaming support",
      "Docker examples"
    ]
  },
  {
    "title": "ollama-cookbook",
    "url": "https://github.com/ollama/ollama-cookbook",
    "summary": "Community cookbook with recipes for function-calling, vision, LangGraph, Docker Compose stacks, etc.",
    "source": "github",
    "date": "2024-06-06",
    "highlights": [
      "function-calling demo",
      "vision examples",
      "LangGraph agent",
      "Modelfile snippets"
    ]
  },
  {
    "title": "ollama-nix",
    "url": "https://github.com/ollama/ollama-nix",
    "summary": "Nix flake that packages Ollama and several model derivations for reproducible deployments.",
    "source": "github",
    "date": "2024-05-30",
    "highlights": [
      "flakes",
      "GPU acceleration",
      "declarative models",
      "NixOS module"
    ]
  },
  {
    "title": "ollama-docker",
    "url": "https://github.com/ollama/ollama-docker",
    "summary": "Official Docker image source and compose examples for CPU & GPU (CUDA/ROCm) setups.",
    "source": "github",
    "date": "2024-06-10",
    "highlights": [
      "official image",
      "CUDA & ROCm tags",
      "docker-compose.yml",
      "Kubernetes manifests"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/ollama-helm/ollama-helm",
    "summary": "Community Helm chart to deploy Ollama on Kubernetes with autoscaling and PVC model cache.",
    "source": "github",
    "date": "2024-05-29",
    "highlights": [
      "Helm repo",
      "GPU nodeSelector",
      "model init containers",
      "HPA support"
    ]
  },
  {
    "title": "ollama-rag",
    "url": "https://github.com/ggerganov/ollama-rag",
    "summary": "Minimal RAG example using Ollama embeddings + llama.cpp for retrieval and generation.",
    "source": "github",
    "date": "2024-05-27",
    "highlights": [
      "pure C++",
      "FAISS index",
      "CLI search",
      "Dockerfile"
    ]
  },
  {
    "title": "ollama-sdks",
    "url": "https://github.com/ollama/ollama-sdks",
    "summary": "Meta-repo tracking community SDKs for C#, Go, Rust, PHP, Swift and more.",
    "source": "github",
    "date": "2024-06-03",
    "highlights": [
      "community driven",
      "auto-generated docs",
      "compatibility matrix"
    ]
  },
  {
    "title": "ollama-distroless",
    "url": "https://github.com/ollama-distroless/ollama-distroless",
    "summary": "Distroless container images for Ollama reducing attack surface and image size.",
    "source": "github",
    "date": "2024-05-26",
    "highlights": [
      "scratch base",
      "SBOM",
      "cosign signatures",
      "multi-arch"
    ]
  },
  {
    "title": "ollama-model-hub",
    "url": "https://github.com/ollama-model-hub/ollama-model-hub",
    "summary": "Community-curated collection of Modelfiles for fine-tuned and domain-specific models.",
    "source": "github",
    "date": "2024-06-05",
    "highlights": [
      "pull requests welcome",
      "categories",
      " quantized scripts",
      "license tags"
    ]
  },
  {
    "title": "ollama-discord-bot",
    "url": "https://github.com/ollama-discord/ollama-discord-bot",
    "summary": "Self-hostable Discord bot that brings Ollama models into chat with slash commands and threads.",
    "source": "github",
    "date": "2024-06-02",
    "highlights": [
      "slash commands",
      "per-guild config",
      "thread isolation",
      "streaming replies"
    ]
  }
]