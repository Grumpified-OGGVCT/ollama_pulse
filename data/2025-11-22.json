[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: get up and running with Llama 3, Mistral, Gemma, and other large language models locally.",
    "source": "github",
    "date": "2024-04-19",
    "highlights": [
      "self-contained binary",
      "macOS/Linux/Windows",
      "Docker images",
      "REST API",
      "model library"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript SDK for Ollama, published to npm as \u2018ollama\u2019.",
    "source": "github",
    "date": "2024-04-18",
    "highlights": [
      "npm install ollama",
      "Promise-based",
      "chat & generate",
      "streaming support"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client for Ollama, available on PyPI as \u2018ollama\u2019.",
    "source": "github",
    "date": "2024-04-18",
    "highlights": [
      "pip install ollama",
      "sync/async APIs",
      "chat & embed",
      "model management"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/partners/ollama",
    "summary": "LangChain integration package (langchain-ollama) exposing Ollama models as LLMs & chat models.",
    "source": "github",
    "date": "2024-04-17",
    "highlights": [
      "pip install langchain-ollama",
      "LLM & Chat bindings",
      "embeddings",
      "tool-calling beta"
    ]
  },
  {
    "title": "ollama-webui (ollama-webui/ollama-webui)",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich web UI for Ollama (now renamed \u2018Open WebUI\u2019) with chat folders, model switching, RAG uploads.",
    "source": "github",
    "date": "2024-04-19",
    "highlights": [
      "Docker ready",
      "markdown & code highlight",
      "import docs/PDF",
      "multi-user"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/sugarforever/ollama-cli",
    "summary": "NPM-published CLI tool for chatting, listing, pulling, and deleting Ollama models.",
    "source": "github",
    "date": "2024-03-30",
    "highlights": [
      "npm i -g ollama-cli",
      "interactive REPL",
      "model management"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama/ollama-copilot",
    "summary": "Experimental VS Code extension that routes GitHub Copilot calls to a local Ollama model.",
    "source": "github",
    "date": "2024-04-05",
    "highlights": [
      "VS Code ext",
      "copilot proxy",
      "local only"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/ollama4j/ollama4j",
    "summary": "Java/JVM client library for Ollama published to Maven Central.",
    "source": "github",
    "date": "2024-04-15",
    "highlights": [
      "Java/Kotlin friendly",
      "sync/async",
      "chat & embed",
      "Spring starter"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/ollama/ollama-rb",
    "summary": "Community-maintained Ruby gem for interacting with the Ollama API.",
    "source": "github",
    "date": "2024-04-10",
    "highlights": [
      "gem install ollama",
      "Faraday based",
      "chat & generate"
    ]
  },
  {
    "title": "ollama-rs",
    "url": "https://github.com/ollama/ollama-rs",
    "summary": "Rust crate providing strongly-typed async bindings to the Ollama REST API.",
    "source": "github",
    "date": "2024-04-18",
    "highlights": [
      "cargo add ollama-rs",
      "tokio/async",
      "chat & embed",
      "streaming"
    ]
  },
  {
    "title": "ollama-docker",
    "url": "https://github.com/ollama/ollama/tree/main/docker",
    "summary": "Official Docker images (ollama/ollama) with CUDA & ROCm variants for headless deployment.",
    "source": "github",
    "date": "2024-04-19",
    "highlights": [
      "docker run ollama/ollama",
      "CUDA ROCm tags",
      "GPU accel",
      "rootless"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/ollama/ollama-helm",
    "summary": "Community Helm chart for deploying Ollama on Kubernetes with GPU node selectors.",
    "source": "github",
    "date": "2024-04-16",
    "highlights": [
      "helm repo add ollama",
      "GPU scheduling",
      "PVC model cache"
    ]
  },
  {
    "title": "ollama-chat (npm package)",
    "url": "https://www.npmjs.com/package/ollama-chat",
    "summary": "Lightweight Node wrapper exposing Ollama chat with async iterators for streaming.",
    "source": "github",
    "date": "2024-04-01",
    "highlights": [
      "npm i ollama-chat",
      "streaming parser",
      "TypeScript"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/ollama/ollama-haystack",
    "summary": "Haystack integration by deepset, exposing Ollama models as generative & embedding components.",
    "source": "github",
    "date": "2024-04-12",
    "highlights": [
      "pip install ollama-haystack",
      "RAG ready",
      "embeddings"
    ]
  },
  {
    "title": "ollama-codex",
    "url": "https://github.com/ollama/ollama-codex",
    "summary": "Experimental port of OpenAI Codex CLI that swaps backend to local Ollama models.",
    "source": "github",
    "date": "2024-04-08",
    "highlights": [
      "terminal IDE helper",
      "local code completion",
      "FIM support"
    ]
  },
  {
    "title": "ollama-curl",
    "url": "https://github.com/technomancy/ollama-curl",
    "summary": "Minimal POSIX shell library wrapping Ollama REST endpoints with curl+jq.",
    "source": "github",
    "date": "2024-03-25",
    "highlights": [
      "pure shell",
      "no deps",
      "dotfiles friendly"
    ]
  },
  {
    "title": "ollama-streamlit",
    "url": "https://github.com/randomthought/ollama-streamlit",
    "summary": "Streamlit chat app template that talks to Ollama, including file upload and prompt history.",
    "source": "github",
    "date": "2024-04-14",
    "highlights": [
      "pip install streamlit",
      "drag-drop files",
      "session memory"
    ]
  },
  {
    "title": "ollama-rag",
    "url": "https://github.com/ollama-rag/ollama-rag",
    "summary": "Starter repo showing how to build RAG with Ollama embeddings + Chroma + LangChain.",
    "source": "github",
    "date": "2024-04-13",
    "highlights": [
      "Chroma vectorstore",
      "PDF loader",
      "Gradio UI"
    ]
  },
  {
    "title": "ollama-nestjs",
    "url": "https://github.com/ollama/ollama-nestjs",
    "summary": "NestJS module wrapping the ollama-js client for dependency-injected LLM services.",
    "source": "github",
    "date": "2024-04-11",
    "highlights": [
      "@nestjs/ollama",
      "async providers",
      "configurable"
    ]
  },
  {
    "title": "ollama-express",
    "url": "https://github.com/ollama/ollama-express",
    "summary": "Express.js starter that mounts Ollama chat endpoints with OpenAI-compatible routes.",
    "source": "github",
    "date": "2024-04-09",
    "highlights": [
      "OpenAI drop-in",
      "chat completions",
      "streaming"
    ]
  }
]