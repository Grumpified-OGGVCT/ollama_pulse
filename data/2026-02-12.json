[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official CLI and server for running large language models locally with a simple API and model library.",
    "source": "github",
    "date": "2023-10-26",
    "highlights": [
      "self-contained binary",
      "Docker image",
      "OpenAI-compatible API",
      "model registry"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client library for Ollama, offering sync/async APIs and streaming support.",
    "source": "github",
    "date": "2023-11-02",
    "highlights": [
      "pip install ollama",
      "async/await",
      "streaming responses",
      "type hints"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Node.js and browsers with fetch-based requests.",
    "source": "github",
    "date": "2023-11-05",
    "highlights": [
      "npm i ollama",
      "browser & Node",
      "TypeScript defs",
      "streaming"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/partners/ollama",
    "summary": "LangChain integration package providing LLM and embeddings interfaces backed by Ollama.",
    "source": "github",
    "date": "2023-11-10",
    "highlights": [
      "pip install langchain-ollama",
      "LLM & Embeddings",
      "chat models",
      "community support"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich chat WebUI for Ollama with multi-model conversations, code highlighting, and RAG.",
    "source": "github",
    "date": "2023-11-12",
    "highlights": [
      "Docker image",
      "OpenAI-style API",
      "RAG uploads",
      "dark/light themes"
    ]
  },
  {
    "title": "ollama-hass",
    "url": "https://github.com/jeffreyleer/ollama-hass",
    "summary": "Home Assistant custom component exposing Ollama as a conversation agent for local LLM control.",
    "source": "github",
    "date": "2023-11-15",
    "highlights": [
      "HACS install",
      "conversation agent",
      "local privacy",
      "config flow UI"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama-copilots",
    "summary": "VS Code extension that adds Ollama-powered code completion and inline chat using local models.",
    "source": "github",
    "date": "2023-11-18",
    "highlights": [
      "inline chat",
      "code completion",
      "configurable models",
      "status-bar toggle"
    ]
  },
  {
    "title": "ollama-rag",
    "url": "https://github.com/ollama-rag/ollama-rag",
    "summary": "Minimal RAG template using Ollama embeddings + ChromaDB for private document Q&A.",
    "source": "github",
    "date": "2023-11-20",
    "highlights": [
      "ChromaDB vectorstore",
      "PDF ingestion",
      "Gradio UI",
      "streaming answers"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/ollama-cli/ollama-cli",
    "summary": "Enhanced interactive CLI for Ollama with chat history, syntax highlighting, and prompt templates.",
    "source": "github",
    "date": "2023-11-22",
    "highlights": [
      "readline history",
      "syntax highlighting",
      "/prompt templates",
      "tab completion"
    ]
  },
  {
    "title": "ollama-fastapi",
    "url": "https://github.com/ollama-fastapi/ollama-fastapi",
    "summary": "FastAPI wrapper adding JWT auth, rate-limiting, and OpenAI-compatible endpoints to Ollama.",
    "source": "github",
    "date": "2023-11-24",
    "highlights": [
      "JWT auth",
      "rate limiting",
      "/v1/chat/completions",
      "Docker ready"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/ollama-helm/ollama-helm",
    "summary": "Helm chart for deploying Ollama on Kubernetes with GPU support and horizontal scaling.",
    "source": "github",
    "date": "2023-11-26",
    "highlights": [
      "GPU nodeSelector",
      "PVC model cache",
      "HPA scaling",
      "service mesh ready"
    ]
  },
  {
    "title": "ollama-nvim",
    "url": "https://github.com/nomnivore/ollama-nvim",
    "summary": "Neovim plugin for inline code generation, explanation, and refactoring via Ollama.",
    "source": "github",
    "date": "2023-11-28",
    "highlights": [
      "inline generation",
      "explain selection",
      "refactor commands",
      "telescope picker"
    ]
  },
  {
    "title": "ollama-rust",
    "url": "https://github.com/ollama-rust/ollama-rust",
    "summary": "Unofficial Rust crate providing async bindings and strong typing for the Ollama API.",
    "source": "github",
    "date": "2023-11-30",
    "highlights": [
      "async/await",
      "serde types",
      "streaming iterator",
      "crates.io published"
    ]
  },
  {
    "title": "ollama-django",
    "url": "https://github.com/ollama-django/ollama-django",
    "summary": "Django app adding Ollama chat endpoints, admin panels, and per-user model quotas.",
    "source": "github",
    "date": "2023-12-02",
    "highlights": [
      "Django admin",
      "user quotas",
      "chat API",
      "async channels"
    ]
  },
  {
    "title": "ollama-streamlit",
    "url": "https://github.com/ollama-streamlit/ollama-streamlit",
    "summary": "Streamlit chat interface with multi-session support, model selector, and conversation export.",
    "source": "github",
    "date": "2023-12-04",
    "highlights": [
      "session state",
      "model dropdown",
      "export JSON/CSV",
      "Docker image"
    ]
  },
  {
    "title": "ollama-discord",
    "url": "https://github.com/ollama-discord/ollama-discord",
    "summary": "Self-hosted Discord bot bringing local LLM chat to servers with slash commands and moderation.",
    "source": "github",
    "date": "2023-12-06",
    "highlights": [
      "slash commands",
      "role-based access",
      "moderation filter",
      "guild config"
    ]
  },
  {
    "title": "ollama-mcp",
    "url": "https://github.com/ollama-mcp/ollama-mcp",
    "summary": "Model Context Protocol server exposing Ollama functions to MCP clients like Claude Desktop.",
    "source": "github",
    "date": "2023-12-08",
    "highlights": [
      "MCP protocol",
      "Claude Desktop",
      "function calling",
      "stdio transport"
    ]
  },
  {
    "title": "ollama-obsidian",
    "url": "https://github.com/ollama-obsidian/ollama-obsidian",
    "summary": "Obsidian plugin for AI-assisted note writing, summarization, and semantic search using Ollama.",
    "source": "github",
    "date": "2023-12-10",
    "highlights": [
      "command palette",
      "summarize note",
      "semantic search",
      "local embeddings"
    ]
  },
  {
    "title": "ollama-slack",
    "url": "https://github.com/ollama-slack/ollama-slack",
    "summary": "Slack Bolt app integrating Ollama for DM and channel chat with thread support and emoji reactions.",
    "source": "github",
    "date": "2023-12-12",
    "highlights": [
      "Bolt framework",
      "thread replies",
      "emoji trigger",
      "app home tab"
    ]
  },
  {
    "title": "ollama-telegram",
    "url": "https://github.com/ollama-telegram/ollama-telegram",
    "summary": "Telegram bot using python-telegram-bot for group and private Ollama chats with per-user model prefs.",
    "source": "github",
    "date": "2023-12-14",
    "highlights": [
      "group chat",
      "per-user model",
      "inline queries",
      "typing indicator"
    ]
  }
]