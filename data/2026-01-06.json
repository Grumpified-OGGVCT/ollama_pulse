[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official CLI and Python/JS bindings to pull, run and manage GGUF models locally; supports Llama 2, Mistral, Gemma, etc.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "self-contained binary",
      "REST & streaming API",
      "model library hub",
      "macOS/Linux/Windows"
    ]
  },
  {
    "title": "ollama/ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official TypeScript/JavaScript SDK that wraps the local Ollama REST API for Node & browsers.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "Promise/async API",
      "chat & embed endpoints",
      "npm install ollama"
    ]
  },
  {
    "title": "ollama/ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client with sync & async support, streaming, embeddings and tool-calling helpers.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "pip install ollama",
      "FastAPI-style client",
      "Pydantic models"
    ]
  },
  {
    "title": "jmorganca/ollama",
    "url": "https://pypi.org/project/ollama/",
    "summary": "PyPI landing page for the official ollama-python package; mirrors GitHub releases.",
    "source": "pypi",
    "date": "2024-05-12",
    "highlights": [
      "> 200 k downloads/mo",
      "Python \u2265 3.8",
      "zero native deps"
    ]
  },
  {
    "title": "ollama on npm",
    "url": "https://www.npmjs.com/package/ollama",
    "summary": "npm registry page for the official ollama-js SDK; ships ESM & CJS bundles.",
    "source": "npm",
    "date": "2024-05-10",
    "highlights": [
      "~ 30 k weekly downloads",
      "TypeScript definitions",
      "browser compatible"
    ]
  },
  {
    "title": "ollama-webui/ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Open-source ChatGPT-style web interface that talks to the local Ollama API; no external sign-ups.",
    "source": "github",
    "date": "2024-05-13",
    "highlights": [
      "Docker one-liner",
      "multi-model chats",
      "markdown & code highlighting"
    ]
  },
  {
    "title": "langchain-ai/langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/ollama",
    "summary": "LangChain integration package exposing Ollama models as LLM, chat and embeddings components.",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "pip install langchain-ollama",
      "tool calling support",
      "streaming tokens"
    ]
  },
  {
    "title": "lmstudio-ai/ollama-lmstudio-bridge",
    "url": "https://github.com/lmstudio-ai/ollama-lmstudio-bridge",
    "summary": "Community bridge that lets LMStudio discover and serve Ollama-pulled GGUF models.",
    "source": "github",
    "date": "2024-04-28",
    "highlights": [
      "automatic model detection",
      "unified UI",
      "Windows builds"
    ]
  },
  {
    "title": "ollama-rag/ollama-rag-stack",
    "url": "https://github.com/ollama-rag/ollama-rag-stack",
    "summary": "Starter repo showing RAG with Ollama embeddings, Chroma vector store and LangChain.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "docker-compose stack",
      "PDF ingestion",
      "Gradio UI"
    ]
  },
  {
    "title": "Embedchain with Ollama",
    "url": "https://github.com/embedchain/embedchain/tree/main/embedchain/llm/ollama",
    "summary": "Embedchain adapter allowing Ollama models to be used as the LLM backend for RAG bots.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "pip install embedchain[ollama]",
      "YAML config",
      "offline mode"
    ]
  },
  {
    "title": "ollama-haystack by deepset",
    "url": "https://github.com/deepset-ai/haystack-integrations/tree/main/integrations/ollama",
    "summary": "Haystack integration providing OllamaGenerator and OllamaEmbedder nodes.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "Haystack 2.0 ready",
      "batch inference",
      "model warm-up"
    ]
  },
  {
    "title": "ollama-discord-bot",
    "url": "https://github.com/rizerphe/ollama-discord-bot",
    "summary": "Self-hostable Discord bot that streams Ollama answers into any channel using slash commands.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "typing indicators",
      "multi-user sessions",
      "Docker image"
    ]
  },
  {
    "title": "ollama-slack-bot",
    "url": "https://github.com/technosophos/ollama-slack-bot",
    "summary": "Lightweight Slack bot using Socket-mode to query local Ollama models privately.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "Bolt framework",
      "threaded replies",
      "env-var config"
    ]
  },
  {
    "title": "ollama-cli-chat (rich TUI)",
    "url": "https://github.com/turing-machines/ollama-cli-chat",
    "summary": "Terminal UI built with Rich and Textual for interactive multi-model chatting via Ollama.",
    "source": "github",
    "date": "2024-05-04",
    "highlights": [
      "keyboard shortcuts",
      "conversation history",
      "syntax themes"
    ]
  },
  {
    "title": "ollama-copilot.vim",
    "url": "https://github.com/mikezzb/ollama-copilot.vim",
    "summary": "Vim plugin that adds code-completion and inline suggestions powered by Ollama models.",
    "source": "github",
    "date": "2024-05-03",
    "highlights": [
      "deoplete source",
      "FIM templates",
      "lazy loading"
    ]
  },
  {
    "title": "ollama-vscode extension",
    "url": "https://github.com/mjbvz/ollama-vscode",
    "summary": "Unofficial VS Code extension to run Ollama models inside the editor for Q&A and code generation.",
    "source": "github",
    "date": "2024-05-02",
    "highlights": [
      "sidebar panel",
      "streaming output",
      "custom prompts"
    ]
  },
  {
    "title": "ollama-rs (Rust client)",
    "url": "https://github.com/pepperoni21/ollama-rs",
    "summary": "Community-built async Rust crate for integrating Ollama into Rust apps via the REST API.",
    "source": "github",
    "date": "2024-05-01",
    "highlights": [
      "tokio based",
      "Serde models",
      "crates.io published"
    ]
  },
  {
    "title": "ollama-go (Go client SDK)",
    "url": "https://github.com/ollama-go/ollama-go",
    "summary": "Idiomatic Go package that wraps the Ollama REST endpoints with context and streaming support.",
    "source": "github",
    "date": "2024-04-30",
    "highlights": [
      "go get github.com/ollama-go/ollama-go",
      "retryable http client",
      "model listing"
    ]
  },
  {
    "title": "ollama-csharp (.NET SDK)",
    "url": "https://github.com/ollama-csharp/ollama-csharp",
    "summary": "Community C# library for .6+ exposing Ollama APIs with IAsyncEnumerable streaming.",
    "source": "github",
    "date": "2024-04-29",
    "highlights": [
      "NuGet package",
      "dependency injection friendly",
      "Unity samples"
    ]
  },
  {
    "title": "r/ollama - Reddit community",
    "url": "https://www.reddit.com/r/ollama/",
    "summary": "Active subreddit for sharing models, troubleshooting, and showcasing Ollama-based projects.",
    "source": "reddit",
    "date": "2024-05-14",
    "highlights": [
      "> 7 k members",
      "model requests",
      "performance tips"
    ]
  }
]