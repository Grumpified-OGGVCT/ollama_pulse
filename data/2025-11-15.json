[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: lightweight, extensible framework for running Llama 2, Mistral, Gemma and other LLMs locally with a single CLI.",
    "source": "github",
    "date": "2023-10-15",
    "highlights": [
      "self-contained binary",
      "Docker image",
      "model library",
      "REST API",
      "macOS/Linux/Windows"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for the Ollama server; install via npm.",
    "source": "github",
    "date": "2023-11-02",
    "highlights": [
      "npm install ollama",
      "Promise-based API",
      "chat & generate endpoints",
      "streaming support"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client for Ollama; pip-installable wrapper around the REST API.",
    "source": "github",
    "date": "2023-10-28",
    "highlights": [
      "pip install ollama",
      "sync & async clients",
      "chat/generate/embed",
      "type hints"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/partners/ollama",
    "summary": "LangChain integration package letting you use any Ollama-hosted model as an LLM or chat component.",
    "source": "github",
    "date": "2023-11-10",
    "highlights": [
      "pip install langchain-ollama",
      "ChatOllama",
      "OllamaLLM",
      "embeddings support"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich, self-hosted web UI for Ollama (ChatGPT-style interface) built with SvelteKit.",
    "source": "github",
    "date": "2023-11-12",
    "highlights": [
      "markdown & code highlighting",
      "multi-model chats",
      "document upload",
      "Docker image"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java/Kotlin client for Ollama; Maven Central artifact offering sync/async APIs.",
    "source": "github",
    "date": "2023-11-05",
    "highlights": [
      "Maven dependency",
      "Kotlin coroutines",
      "streaming responses",
      "chat & generate"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/ollama/ollama-rb",
    "summary": "Community-maintained Ruby gem for interacting with the Ollama API.",
    "source": "github",
    "date": "2023-11-01",
    "highlights": [
      "gem install ollama",
      "Faraday-based",
      "chat & generate",
      "streaming"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/saltyorg/ollama-cli",
    "summary": "Convenience wrapper adding shell aliases, fzf model picker and prompt templates for Ollama.",
    "source": "github",
    "date": "2023-11-07",
    "highlights": [
      "bash/zsh completion",
      "fuzzy model search",
      "prompt snippets",
      "config file"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama/ollama-copilot",
    "summary": "Experimental VS Code extension that routes GitHub Copilot calls to a local Ollama model.",
    "source": "github",
    "date": "2023-11-09",
    "highlights": [
      "local Copilot replacement",
      "configurable model",
      "inline suggestions"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/ollama/ollama-haystack",
    "summary": "Haystack integration by deepset allowing Ollama models to be used as generators or rankers.",
    "source": "github",
    "date": "2023-11-11",
    "highlights": [
      "pip install ollama-haystack",
      "Generator & Ranker nodes",
      "Haystack 2.0 ready"
    ]
  },
  {
    "title": "ollama-docker",
    "url": "https://github.com/ollama/ollama/tree/main/docker",
    "summary": "Official Docker image and compose examples for running Ollama containerised with GPU support.",
    "source": "github",
    "date": "2023-10-20",
    "highlights": [
      "official image",
      "CUDA & ROCm tags",
      "docker-compose.yml",
      "Kubernetes example"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/otwld/ollama-helm",
    "summary": "Community Helm chart for deploying Ollama on Kubernetes with autoscaling and PVC support.",
    "source": "github",
    "date": "2023-11-08",
    "highlights": [
      "Helm install",
      "GPU node-selector",
      "ingress",
      "persistence"
    ]
  },
  {
    "title": "ollama-camunda",
    "url": "https://github.com/camunda-community-hub/ollama-camunda",
    "summary": "Camunda Community extension providing Ollama-backed service tasks for BPMN workflows.",
    "source": "github",
    "date": "2023-11-06",
    "highlights": [
      "Camunda 8 connector",
      "job worker",
      "prompt templates",
      "output mapping"
    ]
  },
  {
    "title": "ollama-n8n-node",
    "url": "https://github.com/n8n-io/n8n/tree/master/packages/nodes-base/nodes/Ollama",
    "summary": "Official n8n node that adds Ollama chat & generate actions to no-code workflows.",
    "source": "github",
    "date": "2023-11-03",
    "highlights": [
      "n8n community node",
      "credentials support",
      "chat & generate",
      "streaming toggle"
    ]
  },
  {
    "title": "ollama-discord",
    "url": "https://github.com/ollama-discord/ollama-discord",
    "summary": "Self-hosted Discord bot bringing Ollama models to slash commands and threads.",
    "source": "github",
    "date": "2023-11-04",
    "highlights": [
      "slash commands",
      "thread isolation",
      "model picker",
      "Docker ready"
    ]
  },
  {
    "title": "ollama-slack",
    "url": "https://github.com/ray-project/ray/tree/master/doc/source/serve/examples/ollama-slack-bot",
    "summary": "Ray Serve example project deploying an auto-scaling Slack bot powered by Ollama.",
    "source": "github",
    "date": "2023-11-13",
    "highlights": [
      "Ray Serve",
      "auto-scaling",
      "Slack events API",
      "model hot-swap"
    ]
  },
  {
    "title": "ollama-rag",
    "url": "https://github.com/ggerganov/ollama-rag",
    "summary": "Minimal RAG example using Ollama embeddings + Chroma vector store for local document Q&A.",
    "source": "github",
    "date": "2023-11-14",
    "highlights": [
      "embeddings API",
      "ChromaDB",
      "PDF ingestion",
      "Gradio UI"
    ]
  },
  {
    "title": "ollama-streamlit",
    "url": "https://github.com/streamlit/ollama-streamlit",
    "summary": "Streamlit chat template that connects to Ollama with session memory and markdown rendering.",
    "source": "github",
    "date": "2023-11-15",
    "highlights": [
      "pip install streamlit",
      "session state",
      "streaming chat",
      "Dockerfile"
    ]
  },
  {
    "title": "ollama-rs",
    "url": "https://github.com/pepperoni21/ollama-rs",
    "summary": "Rust crate providing strongly-typed async bindings to the Ollama REST API.",
    "source": "github",
    "date": "2023-11-16",
    "highlights": [
      "crates.io",
      "tokio/async",
      "serde types",
      "chat & generate"
    ]
  },
  {
    "title": "ollama-dart",
    "url": "https://github.com/ollama-dart/ollama-dart",
    "summary": "Dart/Flutter package for talking to Ollama, enabling on-device LLM chats in mobile apps.",
    "source": "github",
    "date": "2023-11-17",
    "highlights": [
      "pub.dev",
      "Dart FFI",
      "streaming support",
      "Flutter example"
    ]
  }
]