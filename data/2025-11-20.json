[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: get up and running with Llama 3, Mistral, Gemma, and other large language models locally.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "self-contained binary",
      "macOS/Linux/Windows",
      "Docker image",
      "REST API",
      "model library"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python SDK for Ollama; chat, generate, embed, pull, and manage models with a few lines of code.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "pip install ollama",
      "sync/async clients",
      "streaming responses",
      "type hints"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Node & browsers; same features as the Python SDK.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "npm i ollama",
      "ESM/CommonJS",
      "Promise/asyncIterator",
      "typed"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/partners/ollama",
    "summary": "LangChain integration to use any Ollama model as an LLM or chat backend.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "pip install langchain-ollama",
      "chat & generate",
      "tool calling",
      "embeddings"
    ]
  },
  {
    "title": "ollama-webui (ollama-webui/ollama-webui)",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich web UI for Ollama (chat, admin, RAG, multi-user); drop-in replacement for ChatGPT UI.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "Docker ready",
      "file upload/RAG",
      "voice input",
      "dark/light themes",
      "role-based auth"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/llama-assistant/ollama-cli",
    "summary": "Terminal UI wrapper around Ollama with history, syntax highlighting, and prompt templates.",
    "source": "github",
    "date": "2024-04-30",
    "highlights": [
      "npm i -g ollama-cli",
      "REPL mode",
      "markdown rendering",
      "shell integration"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/fostermaier/ollama-copilot",
    "summary": "VS Code extension that turns Ollama models into a GitHub-Copilot-like inline assistant.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "FIM completions",
      "custom model pick",
      "inline diff",
      "status-bar toggle"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/ollama4j/ollama4j",
    "summary": "Java/Kotlin client for Ollama with Spring Boot starters and reactive support.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "Maven Central",
      "Spring Boot auto-config",
      "Project Loom friendly"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/ollama/ollama-rb",
    "summary": "Official Ruby gem for Ollama; same generate/chat/embed API surface.",
    "source": "github",
    "date": "2024-05-04",
    "highlights": [
      "gem install ollama",
      "Fiber scheduler support",
      "Rails examples"
    ]
  },
  {
    "title": "ollama-rust",
    "url": "https://github.com/ollama/ollama-rust",
    "summary": "Community Rust crate providing typed async bindings to the Ollama REST API.",
    "source": "github",
    "date": "2024-05-03",
    "highlights": [
      "crates.io",
      "tokio client",
      "Serde models",
      "examples"
    ]
  },
  {
    "title": "ollama-gui",
    "url": "https://github.com/jmorganca/ollama-gui",
    "summary": "Minimal Tauri desktop app for chatting with Ollama models (macOS/Windows/Linux).",
    "source": "github",
    "date": "2024-05-02",
    "highlights": [
      "Rust+React",
      "single binary",
      "lightweight",
      "open-source"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/deepset-ai/haystack-integrations/tree/main/integrations/ollama",
    "summary": "Haystack integration to use Ollama models as generators or embedders in pipelines.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "pip install ollama-haystack",
      "RAG ready",
      "batch embed",
      "pipeline YAML"
    ]
  },
  {
    "title": "ollama-csharp",
    "url": "https://github.com/ollama/ollama-csharp",
    "summary": "Community .NET SDK for Ollama supporting .NET 6+ and ASP.NET Core.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "NuGet OllamaSharp",
      "Dependency injection",
      "streaming",
      "examples"
    ]
  },
  {
    "title": "ollama-docker-compose",
    "url": "https://github.com/ollama/ollama/tree/main/docker",
    "summary": "Official Docker image and compose samples (CPU/GPU, OpenAI-compatible proxy).",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "ollama/ollama",
      "CUDA/ROCm tags",
      "OpenAI bridge",
      "Kubernetes yaml"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/ollama-helm/ollama-helm",
    "summary": "Helm chart for deploying Ollama on Kubernetes with GPU autoscaling.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "auto-gpu",
      "pvc models cache",
      "ingress",
      "prometheus metrics"
    ]
  },
  {
    "title": "ollama-model-hub",
    "url": "https://github.com/ollama-model-hub/ollama-model-hub",
    "summary": "Community-curated list of custom Modelfiles (CodeLlama, SQLCoder, Zephyr, etc.).",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "pull-ready Modelfiles",
      "quantization notes",
      "benchmarks",
      "PR workflow"
    ]
  },
  {
    "title": "ollama-discord-bot",
    "url": "https://github.com/ollama-discord/ollama-discord-bot",
    "summary": "Self-hostable Discord bot that brings Ollama models to your server with slash commands.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "slash /chat",
      "model switching",
      "thread support",
      "Docker"
    ]
  },
  {
    "title": "ollama-slack-bot",
    "url": "https://github.com/ollama-slack/ollama-slack-bot",
    "summary": "Slack Bolt app that exposes Ollama models via DMs and channel mentions.",
    "source": "github",
    "date": "2024-05-04",
    "highlights": [
      "Socket mode",
      "threading",
      "app home",
      "serverless deploy"
    ]
  },
  {
    "title": "ollama-experiments",
    "url": "https://github.com/ollama-experiments/ollama-experiments",
    "summary": "Collection of notebooks and scripts benchmarking quantization, LoRA, and fine-tunes on Ollama.",
    "source": "github",
    "date": "2024-05-03",
    "highlights": [
      "jupyter notebooks",
      "latency graphs",
      "GPU memory profiling",
      "LoRA adapter load"
    ]
  },
  {
    "title": "ollama-nix",
    "url": "https://github.com/NixOS/nixpkgs/pull/302451",
    "summary": "Nix flake packaging Ollama and common models for reproducible deployments.",
    "source": "github",
    "date": "2024-05-02",
    "highlights": [
      "nix run",
      "pinned models",
      "CUDA support",
      "module"
    ]
  }
]