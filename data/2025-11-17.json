[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: get up and running with Llama 3, Mistral, Gemma and other large language models locally.",
    "source": "github",
    "date": "2024-06-01",
    "highlights": [
      "self-contained binary",
      "Docker image",
      "REST & CLI APIs",
      "model library"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python SDK for Ollama; chat, generate, embed with any local model.",
    "source": "github",
    "date": "2024-05-28",
    "highlights": [
      "pip install ollama",
      "async support",
      "streaming responses"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Ollama; works in Node & browsers.",
    "source": "github",
    "date": "2024-05-25",
    "highlights": [
      "npm i ollama",
      "Promise & stream APIs",
      "types included"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/partners/ollama",
    "summary": "LangChain integration to use Ollama models as LLMs, embedders or tool callers.",
    "source": "github",
    "date": "2024-05-20",
    "highlights": [
      "pip install langchain-ollama",
      "tool calling support",
      "streaming"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich ChatGPT-style web UI for any Ollama model; runs entirely locally.",
    "source": "github",
    "date": "2024-05-30",
    "highlights": [
      "dark/light themes",
      "multi-model chats",
      "RAG via documents"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java/Kotlin client for Ollama with fluent API and streaming support.",
    "source": "github",
    "date": "2024-05-18",
    "highlights": [
      "Maven Central",
      "Kotlin coroutines",
      "custom options"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/nileshtrivedi/ollama-rb",
    "summary": "Ruby gem wrapping Ollama REST API; generate and chat in a few lines.",
    "source": "github",
    "date": "2024-05-15",
    "highlights": [
      "gem install ollama",
      "streaming blocks",
      "Rails ready"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/salty-flower/ollama-cli",
    "summary": "Cross-platform TUI client for Ollama written in Rust; keyboard-driven chat.",
    "source": "github",
    "date": "2024-05-22",
    "highlights": [
      "offline history",
      "themes",
      "cargo install"
    ]
  },
  {
    "title": "ollama-copilot-vscode",
    "url": "https://github.com/ollama-copilot/vscode-ollama",
    "summary": "VS Code extension bringing local Ollama models into GitHub Copilot chat pane.",
    "source": "github",
    "date": "2024-05-27",
    "highlights": [
      "inline chat",
      "custom prompts",
      "no cloud required"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/otwld/ollama-helm",
    "summary": "Helm chart to deploy Ollama on Kubernetes with GPU autoscaling.",
    "source": "github",
    "date": "2024-05-19",
    "highlights": [
      "GPU node-selector",
      "PVC for cache",
      "ingress ready"
    ]
  },
  {
    "title": "ollama-models",
    "url": "https://github.com/jmorganca/ollama-models",
    "summary": "Community-curated Modelfiles for niche fine-tunes and quantized LLMs.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      " quantized GGUFs",
      "LoRA adapters",
      "pull-request workflow"
    ]
  },
  {
    "title": "ollama-chatbot-ui",
    "url": "https://github.com/ivanfioravanti/ollama-chatbot-ui",
    "summary": "Next.js chatbot template pre-wired to Ollama; one-click deploy to Vercel.",
    "source": "github",
    "date": "2024-05-26",
    "highlights": [
      "Markdown support",
      "conversation export",
      "Dockerfile"
    ]
  },
  {
    "title": "ollama-cookbook",
    "url": "https://github.com/ollama-cookbook/ollama-cookbook",
    "summary": "Community recipes for RAG, function-calling, fine-tuning and hardware setups.",
    "source": "github",
    "date": "2024-05-21",
    "highlights": [
      "Jupyter notebooks",
      "Modelfile examples",
      "GPU benchmarks"
    ]
  },
  {
    "title": "ollama-obsidian",
    "url": "https://github.com/hintergrund/ollama-obsidian",
    "summary": "Obsidian plugin to query local Ollama models from within your notes.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "custom commands",
      "template variables",
      "offline"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/ollama-haystack/ollama-haystack",
    "summary": "Haystack integration letting you use Ollama models as generators or embedders.",
    "source": "github",
    "date": "2024-05-16",
    "highlights": [
      "pip install ollama-haystack",
      "retrieval pipelines",
      "evaluation"
    ]
  },
  {
    "title": "ollama-docker-compose",
    "url": "https://github.com/valiantlynx/ollama-docker-compose",
    "summary": "Production-ready docker-compose with Ollama, WebUI, nginx, and automatic HTTPS.",
    "source": "github",
    "date": "2024-05-24",
    "highlights": [
      "Traefik labels",
      "GPU passthrough",
      "backup cron"
    ]
  },
  {
    "title": "ollama-rag",
    "url": "https://github.com/ggerganov/ollama-rag",
    "summary": "Minimal RAG example using Ollama embeddings + llama.cpp for vector search.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "pure C++",
      "no Python deps",
      "streaming retrieval"
    ]
  },
  {
    "title": "ollama-fastapi",
    "url": "https://github.com/1rgs/ollama-fastapi",
    "summary": "FastAPI service that wraps Ollama with OpenAI-compatible endpoints.",
    "source": "github",
    "date": "2024-05-17",
    "highlights": [
      "drop-in replacement",
      "/v1/chat/completions",
      "streaming"
    ]
  },
  {
    "title": "ollama-npm",
    "url": "https://www.npmjs.com/package/ollama",
    "summary": "Official npm package providing JavaScript bindings to Ollama REST API.",
    "source": "npm",
    "date": "2024-05-25",
    "highlights": [
      "TypeScript types",
      "browser & Node",
      "Promise + stream"
    ]
  },
  {
    "title": "ollama-pypi",
    "url": "https://pypi.org/project/ollama/",
    "summary": "Official PyPI package for integrating Ollama into Python applications.",
    "source": "pypi",
    "date": "2024-05-28",
    "highlights": [
      "asyncio support",
      "generate & chat",
      "embeddings"
    ]
  }
]