[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama CLI and server that lets you pull, run, and manage large language models locally with a simple API and Docker-like UX.",
    "source": "github",
    "date": "2023-06-26",
    "highlights": [
      "self-hosted LLM runtime",
      "macOS/Linux/Windows",
      "built-in model registry"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for the Ollama API\u2014chat, embed, pull, and manage models from Node or the browser.",
    "source": "github",
    "date": "2023-10-04",
    "highlights": [
      "npm install ollama",
      "Promise-based",
      "full TypeScript defs"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client library exposing chat, generate, embed, pull, and list APIs with async support.",
    "source": "github",
    "date": "2023-09-15",
    "highlights": [
      "pip install ollama",
      "async/await",
      "streaming responses"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/ollama",
    "summary": "LangChain integration package adding Ollama chat and embed endpoints as first-class components.",
    "source": "github",
    "date": "2023-11-02",
    "highlights": [
      "pip install langchain-ollama",
      "ChatOllama",
      "OllamaEmbeddings"
    ]
  },
  {
    "title": "ollama-webui (ollama-webui/ollama-webui)",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich web UI for Ollama\u2014chat threads, model management, multi-user auth, and OpenAI-compatible endpoints.",
    "source": "github",
    "date": "2023-10-12",
    "highlights": [
      "Docker image",
      "dark/light themes",
      "import/export chats"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java/Kotlin client for Ollama providing synchronous and asynchronous APIs for chat, generate, and embeddings.",
    "source": "github",
    "date": "2023-11-20",
    "highlights": [
      "Maven Central",
      "Kotlin coroutines",
      "Spring Boot starters"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/ollama/ollama-rb",
    "summary": "Official Ruby gem wrapping the Ollama REST API with idiomatic Ruby objects and streaming support.",
    "source": "github",
    "date": "2023-12-01",
    "highlights": [
      "gem install ollama",
      "Enumerable streams",
      "ActiveRecord-like syntax"
    ]
  },
  {
    "title": "ollama-cli (go)",
    "url": "https://github.com/sammcj/ollama-cli",
    "summary": "Unofficial Go CLI that adds interactive model selection, chat history, and shell completion on top of Ollama.",
    "source": "github",
    "date": "2023-11-05",
    "highlights": [
      "fuzzy finder",
      "chat logs",
      "cross-platform binary"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama/ollama-copilot",
    "summary": "VS Code extension that turns any Ollama model into a local GitHub Copilot alternative with inline suggestions.",
    "source": "github",
    "date": "2023-10-30",
    "highlights": [
      "inline completions",
      "configurable model",
      "status-bar toggle"
    ]
  },
  {
    "title": "ollama-chatbot-ui",
    "url": "https://github.com/ivanfioravanti/ollama-chatbot-ui",
    "summary": "Minimal React chatbot UI that streams responses from Ollama via the ollama-js client.",
    "source": "github",
    "date": "2023-11-18",
    "highlights": [
      "Next.js",
      "Vercel deploy",
      "Markdown rendering"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/otwld/ollama-helm",
    "summary": "Production-ready Helm chart for deploying Ollama on Kubernetes with GPU node selection and PVC support.",
    "source": "github",
    "date": "2023-11-25",
    "highlights": [
      "GPU scheduling",
      "configmaps",
      "horizontal pod autoscaler"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/deepset-ai/haystack-ollama",
    "summary": "Haystack integration offering OllamaGenerator and OllamaChatGenerator nodes for RAG pipelines.",
    "source": "github",
    "date": "2023-12-03",
    "highlights": [
      "pip install haystack-ollama",
      "RAG ready",
      "streaming mode"
    ]
  },
  {
    "title": "ollama-nix",
    "url": "https://github.com/NixOS/nixpkgs/tree/master/pkgs/tools/ai/ollama",
    "summary": "Nix flake packaging Ollama server and CLI for reproducible deployments on NixOS.",
    "source": "github",
    "date": "2023-11-10",
    "highlights": [
      "nix run nixpkgs#ollama",
      "CUDA support",
      "declarative config"
    ]
  },
  {
    "title": "ollama-docker-compose",
    "url": "https://github.com/valiantlynx/ollama-docker-compose",
    "summary": "Collection of Docker Compose stacks combining Ollama, WebUI, Postgres, and reverse proxy examples.",
    "source": "github",
    "date": "2023-11-28",
    "highlights": [
      "Traefik TLS",
      "GPU passthrough",
      "persistent volumes"
    ]
  },
  {
    "title": "ollama-express-bridge",
    "url": "https://github.com/technovangelist/ollama-express-bridge",
    "summary": "Lightweight Express proxy that adds OpenAI-compatible /v1/chat/completions endpoint to any Ollama model.",
    "source": "github",
    "date": "2023-12-05",
    "highlights": [
      "drop-in replacement",
      "streaming JSON",
      "npm package"
    ]
  },
  {
    "title": "ollama-rust",
    "url": "https://github.com/pepperoni21/ollama-rust",
    "summary": "Community Rust crate providing async/await wrappers for the entire Ollama REST API.",
    "source": "github",
    "date": "2023-11-15",
    "highlights": [
      "crates.io",
      "tokio runtime",
      "Serde types"
    ]
  },
  {
    "title": "ollama-zig",
    "url": "https://github.com/leroycep/ollama-zig",
    "summary": "Experimental Zig client for Ollama demonstrating HTTP streaming and JSON parsing in Zig.",
    "source": "github",
    "date": "2023-10-22",
    "highlights": [
      "zero-dependency",
      "streaming parser",
      "cross-compilation"
    ]
  },
  {
    "title": "ollama-discord-bot",
    "url": "https://github.com/mxyng/ollama-discord-bot",
    "summary": "Discord bot that brings local Ollama models into any server via slash commands and thread-based chats.",
    "source": "github",
    "date": "2023-11-30",
    "highlights": [
      "thread isolation",
      "rate limiting",
      "guild config"
    ]
  },
  {
    "title": "ollama-dart",
    "url": "https://github.com/marcotas/ollama-dart",
    "summary": "Dart/Flutter package for chatting with Ollama models, includes example chat UI and streaming support.",
    "source": "github",
    "date": "2023-12-02",
    "highlights": [
      "pub.dev",
      "Flutter widgets",
      "isolates for streaming"
    ]
  },
  {
    "title": "ollama-csharp",
    "url": "https://github.com/awaescher/OllamaSharp",
    "summary": ".NET library and CLI that wraps Ollama APIs with strongly-typed models and IAsyncEnumerable streaming.",
    "source": "github",
    "date": "2023-11-27",
    "highlights": [
      "NuGet package",
      ".NET 6+",
      "dependency injection ready"
    ]
  }
]