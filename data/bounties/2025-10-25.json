[
  {
    "title": "Add Comprehensive Acode Plugin Development Microagent",
    "source": "github_issues",
    "reward": "$3M",
    "summary": "## \ud83d\ude80 Feature: Comprehensive Acode Plugin Development Microagent\n\n### Overview\nThis PR adds a comprehensive microagent for the Acode Plugin development project that provides complete guidance for build",
    "url": "https://github.com/Pumpkin-Smasher-83/Acode-Plugin-Cli_Oblivions_Green-Hat_Black-Ops_Termux_All_AI-s-Hack/pull/2",
    "deadline": null,
    "date": "2025-10-15T11:53:14Z",
    "highlights": [
      "comments: 0"
    ]
  },
  {
    "title": "Migrate from Gemini to Gemma 3 (4B Parameters)",
    "source": "github_issues",
    "reward": "TBD",
    "summary": "# Bounty Points: 1500\n## PR Instructions\n  commits should be pushed to the *'local-model'* branch only \n\n---\n\n### Explanation of the Issue  \nThe project currently uses Google\u2019s **Gemini API**, which i",
    "url": "https://github.com/Rex-8/ConCore/issues/2",
    "deadline": null,
    "date": "2025-10-16T19:16:31Z",
    "highlights": [
      "comments: 0"
    ]
  },
  {
    "title": "fix: cross-domain authentication token exposure",
    "source": "github_issues",
    "reward": "TBD",
    "summary": "[EDIT: October 13th, 2025]\r\nOriginal finding credits:\r\n* Mohammed Benhelli @Fuzzinglabs \r\n* Patrick Ventuzelo @Fuzzinglabs \r\n* Date: 24/12/2024\r\n* Link: https://huntr.com/bounties/94eea285-fd65-4e01-a",
    "url": "https://github.com/ollama/ollama/pull/10750",
    "deadline": null,
    "date": "2025-05-16T20:34:49Z",
    "highlights": [
      "comments: 2"
    ]
  },
  {
    "title": "Local Model Support via Ollama $400",
    "source": "github_issues",
    "reward": "$400",
    "summary": "## Overview\n\nImplement local model support via Ollama, enabling self-hosted LLM capabilities with optimized performance.\n\n## Core Features\n- Ollama integration\n- Local model management\n- Model downloa",
    "url": "https://github.com/Spectral-Finance/lux/issues/96",
    "deadline": null,
    "date": "2025-02-25T11:06:09Z",
    "highlights": [
      "comments: 3"
    ]
  },
  {
    "title": "[bounty] script to fine tune local LLM or OpenAI on your screenpipe data",
    "source": "github_issues",
    "reward": "TBD",
    "summary": "\r\n/bounty 100 \r\n\r\ndefinition of done:\r\n- simple to use script (can be python, whatever) to fine tune model (LLM like llama3.2 or multimodal or OpenAI) on your screenpipe data\r\n- some docs to run it an",
    "url": "https://github.com/mediar-ai/screenpipe/issues/717",
    "deadline": null,
    "date": "2024-11-20T22:59:10Z",
    "highlights": [
      "comments: 4"
    ]
  },
  {
    "title": "\ud83c\udfaf Internal Bounty ($4000 USD): Complete LLM Integration System - Local Models + Cloud APIs (Gemini, Anthropic, OpenAI)",
    "source": "github_issues",
    "reward": "$4000",
    "summary": "## \ud83d\udcb0 Bounty Amount: $4,000 USD\n\n## \ud83d\udccb Overview\n\nThis is an **internal bounty issue** for implementing a comprehensive LLM (Large Language Model) integration system into the go-blueprint CLI tool. The g",
    "url": "https://github.com/MAVRICK-1/go-blueprint/issues/1",
    "deadline": null,
    "date": "2025-10-05T08:48:32Z",
    "highlights": [
      "comments: 16"
    ]
  },
  {
    "title": "[bounty] use assistant-ui across chat UIs (search, timeline)",
    "source": "github_issues",
    "reward": "TBD",
    "summary": "\r\ndefinition of done:\r\n- use https://www.assistant-ui.com/ in [search](https://github.com/mediar-ai/screenpipe/tree/main/pipes/search) and [timeline](https://github.com/mediar-ai/screenpipe/tree/main/",
    "url": "https://github.com/mediar-ai/screenpipe/issues/1058",
    "deadline": null,
    "date": "2024-12-28T19:32:20Z",
    "highlights": [
      "comments: 10"
    ]
  },
  {
    "title": "[Enhancement] Create proper manual (how to start)",
    "source": "github_issues",
    "reward": "TBD",
    "summary": "I see that there is quite good manual how to install CAI but no good description how to configure and get this up and running. There is steps for Ubuntu or Windows WSL how to `pip install cai-framewor",
    "url": "https://github.com/aliasrobotics/cai/issues/307",
    "deadline": null,
    "date": "2025-10-22T17:19:47Z",
    "highlights": [
      "comments: 3"
    ]
  },
  {
    "title": "Response parsing logic fixes!",
    "source": "github_issues",
    "reward": "TBD",
    "summary": "Update: (March 9, 2024)\r\n\r\nRemoved all the hacks!\r\n\r\n@DJ4ddi had a better way to handle it using a library for such a case and I have incorporated their changes!\r\n\r\n----\r\n(Old) Warning: I don't think ",
    "url": "https://github.com/HelgeSverre/ollama-gui/pull/19",
    "deadline": null,
    "date": "2024-02-26T22:05:15Z",
    "highlights": [
      "comments: 5"
    ]
  },
  {
    "title": "DesktopCommanderMCP integration with TheAI IDE",
    "source": "github_issues",
    "reward": "TBD",
    "summary": "Hello,\n**Feature request**\nWould be nice to have DesktopCommanderMCP integration with TheAI IDE:\n- Documentation how to configure the MCP Server in TheAI IDE.\n- Example of prompt template to use full ",
    "url": "https://github.com/wonderwhy-er/DesktopCommanderMCP/issues/109",
    "deadline": null,
    "date": "2025-05-08T13:36:27Z",
    "highlights": [
      "comments: 1"
    ]
  },
  {
    "title": "CSS Bug in AI Response Prose (Dark Mode)",
    "source": "github_issues",
    "reward": "TBD",
    "summary": "You see here that in dark mode that STRONG tag in these lists produces a color that isn't legible on the background color.\r\n\r\n<img width=\"800\" alt=\"bug in css ollama-gui\" src=\"https://github.com/Helge",
    "url": "https://github.com/HelgeSverre/ollama-gui/issues/20",
    "deadline": null,
    "date": "2024-03-09T05:13:51Z",
    "highlights": [
      "comments: 2"
    ]
  },
  {
    "title": "Make locale configurable",
    "source": "github_issues",
    "reward": "TBD",
    "summary": "The locale is [hardcoded](https://github.com/HelgeSverre/ollama-gui/blob/044090494a160fc373b1828b0172843b2be1ebd2/src/components/Sidebar.vue#L61) to be Norwegian. Please make it configurable or at lea",
    "url": "https://github.com/HelgeSverre/ollama-gui/issues/26",
    "deadline": null,
    "date": "2024-03-30T20:51:48Z",
    "highlights": [
      "comments: 6"
    ]
  },
  {
    "title": "Llama 3.1 70B high-quality HQQ quantized model - 99%+ quality of fp16 ",
    "source": "github_issues",
    "reward": "TBD",
    "summary": "I'm not really sure if that's possible but adding that to ollama could really impact the performance on 4-bit quant option:\r\n\r\n99%+ in all benchmarks in lm-eval relative performance to FP16 and simila",
    "url": "https://github.com/ollama/ollama/issues/6341",
    "deadline": null,
    "date": "2024-08-13T17:08:12Z",
    "highlights": [
      "comments: 2"
    ]
  },
  {
    "title": "OpenAI Integration with HuggingFace API",
    "source": "github_issues",
    "reward": "TBD",
    "summary": "Hello \ud83d\udc4b\nI'm using your amazing tool, but for free with HuggingFace API, so according to HF's Docs, I will replace OPENAI_API_KEY with their API key, and for sure BASELINE too, here i didn't find any e",
    "url": "https://github.com/aliasrobotics/cai/issues/211",
    "deadline": null,
    "date": "2025-06-30T23:49:21Z",
    "highlights": [
      "comments: 2"
    ]
  },
  {
    "title": "Demo Videos",
    "source": "github_issues",
    "reward": "TBD",
    "summary": "The project needs any of:\n\n- A 30 seconds video with the features highlights\n- A 10-seconds video showing quickly a feature, to be embedded in the app directly (from Youtube)\n\nFeatures that need 10s e",
    "url": "https://github.com/enricoros/big-AGI/issues/197",
    "deadline": null,
    "date": "2023-11-16T05:44:37Z",
    "highlights": [
      "comments: 5"
    ]
  },
  {
    "title": "Hacker News Daily Top 30 @2023-10-06",
    "source": "github_issues",
    "reward": "$8",
    "summary": "1. [**Where does my computer get the time from?** <code>dotat.at</code>](https://dotat.at/@/2023-05-26-whence-time.html) - [214 comments 663 points](https://news.ycombinator.com/item?id=37778496)\n2. [",
    "url": "https://github.com/meixger/hackernews-daily/issues/384",
    "deadline": null,
    "date": "2023-10-06T06:12:24Z",
    "highlights": [
      "comments: 0"
    ]
  },
  {
    "title": "Add Comprehensive Acode Plugin Development Microagent",
    "source": "github_issues",
    "reward": "$3M",
    "summary": "## \ud83d\ude80 Feature: Comprehensive Acode Plugin Development Microagent\n\n### Overview\nThis PR adds a comprehensive microagent for the Acode Plugin development project that provides complete guidance for build",
    "url": "https://github.com/Pumpkin-Smasher-83/Acode-Plugin-Cli_Oblivions_Green-Hat_Black-Ops_Termux_All_AI-s-Hack/pull/2",
    "deadline": null,
    "date": "2025-10-15T11:53:14Z",
    "highlights": [
      "comments: 0"
    ]
  },
  {
    "title": "Revert Removal of RewardValue Class and Update Test Cases",
    "source": "github_issues",
    "reward": "TBD",
    "summary": "- Reverted changes related to 'Reward value' class removal\n- Added back PR summary generator workflow with updated action version\n- Updated Ollama URL and model name in the workflow configuration\n- Mo",
    "url": "https://github.com/zluigon/rewards-converter/pull/2",
    "deadline": null,
    "date": "2025-06-15T21:58:46Z",
    "highlights": [
      "comments: 0"
    ]
  },
  {
    "title": "[ImgBot] Optimize images",
    "source": "github_issues",
    "reward": "TBD",
    "summary": "## Beep boop. Your images are optimized!\r\n\r\nYour image file size has been reduced by **24%** \ud83c\udf89\r\n\r\n<details>\r\n<summary>\r\nDetails\r\n</summary>\r\n\r\n| File | Before | After | Percent reduction |\r\n|:--|:--|:",
    "url": "https://github.com/FinickySpider/obsidian-copilot/pull/1",
    "deadline": null,
    "date": "2025-07-11T22:52:09Z",
    "highlights": [
      "comments: 0"
    ]
  },
  {
    "title": "[bounty] script to fine tune local LLM or OpenAI on your screenpipe data",
    "source": "github_issues",
    "reward": "TBD",
    "summary": "\r\n/bounty 100 \r\n\r\ndefinition of done:\r\n- simple to use script (can be python, whatever) to fine tune model (LLM like llama3.2 or multimodal or OpenAI) on your screenpipe data\r\n- some docs to run it an",
    "url": "https://github.com/mediar-ai/screenpipe/issues/717",
    "deadline": null,
    "date": "2024-11-20T22:59:10Z",
    "highlights": [
      "comments: 4"
    ]
  },
  {
    "title": "Merged code has superfluous whitespaces and removed ones, leading to 0.0 score.",
    "source": "github_issues",
    "reward": "TBD",
    "summary": "Hi, I am trying to benchmark the model for a codebase, but run into issues with the output. It adds spaces where there should be none, removes them where they are important as well as adding superfluo",
    "url": "https://github.com/Osmosis-AI/Osmosis-Apply-1.7B-MCP/issues/1",
    "deadline": null,
    "date": "2025-07-23T12:46:07Z",
    "highlights": [
      "comments: 0"
    ]
  },
  {
    "title": "[bounty] use assistant-ui across chat UIs (search, timeline)",
    "source": "github_issues",
    "reward": "TBD",
    "summary": "\r\ndefinition of done:\r\n- use https://www.assistant-ui.com/ in [search](https://github.com/mediar-ai/screenpipe/tree/main/pipes/search) and [timeline](https://github.com/mediar-ai/screenpipe/tree/main/",
    "url": "https://github.com/mediar-ai/screenpipe/issues/1058",
    "deadline": null,
    "date": "2024-12-28T19:32:20Z",
    "highlights": [
      "comments: 10"
    ]
  },
  {
    "title": "Issue in fine tunning Qwen2.5 7B coder model with llama factory and llama cpp",
    "source": "github_issues",
    "reward": "TBD",
    "summary": "### Reminder\n\n- [x] I have read the above rules and searched the existing issues.\n\n### System Info\n\n```\ndev\nOP\n \u2014 2:34\u202fPM\nWe are trying to fine tune Qwen2.5 7B coder model. Initially while fine tuning",
    "url": "https://github.com/hiyouga/LLaMA-Factory/issues/8360",
    "deadline": null,
    "date": "2025-06-11T11:41:41Z",
    "highlights": [
      "comments: 0"
    ]
  },
  {
    "title": "Florence2 image to rompt advance gives me:LayerUtility: Florence2Image2Prompt  'NoneType' object is not callable",
    "source": "github_issues",
    "reward": "TBD",
    "summary": "### Expected Behavior\n\nFor florence2 image to prompt advance to work and give me a text from the image?\n\n### Actual Behavior\n\nLayerUtility: Florence2Image2Prompt\n\n'NoneType' object is not callable\n\n##",
    "url": "https://github.com/comfyanonymous/ComfyUI/issues/7385",
    "deadline": null,
    "date": "2025-03-25T19:40:15Z",
    "highlights": [
      "comments: 9"
    ]
  },
  {
    "title": "Implement ADK-Inspired Thompson Sampling Enhancement for AI Routing System",
    "source": "github_issues",
    "reward": "TBD",
    "summary": "<open-swe-issue-content>Analyse these plans in our app context:\n\n\n# 3-Developer, 3-Week Sprint Plan \n## Unified AI System Enhancement Implementation \n**Document Version:** 1.0   \n**Planning Date:** Au",
    "url": "https://github.com/puneetrinity/literate-system/issues/6",
    "deadline": null,
    "date": "2025-08-11T11:28:55Z",
    "highlights": [
      "comments: 1"
    ]
  },
  {
    "title": "\ud83d\udccb Development Roadmap: Next Priorities After Core Fixes",
    "source": "github_issues",
    "reward": "TBD",
    "summary": "## Summary\nWith major fixes completed (music, voice, calendar, XSS), here's the prioritized roadmap for next development.\n\n## \u2705 Recently Completed\n- Fixed Jellyfin music integration (playing on Chrome",
    "url": "https://github.com/adrianwedd/ADHDo/issues/92",
    "deadline": null,
    "date": "2025-08-12T23:41:29Z",
    "highlights": [
      "comments: 1"
    ]
  },
  {
    "title": "Use with open source LLM model?",
    "source": "github_issues",
    "reward": "TBD",
    "summary": "Wondering if possible to run with models like llama2 or huggingface models, or Ollama or something like litellm. ",
    "url": "https://github.com/PWhiddy/PokemonRedExperiments/issues/125",
    "deadline": null,
    "date": "2023-10-29T02:51:19Z",
    "highlights": [
      "comments: 5"
    ]
  },
  {
    "title": "Make locale configurable",
    "source": "github_issues",
    "reward": "TBD",
    "summary": "The locale is [hardcoded](https://github.com/HelgeSverre/ollama-gui/blob/044090494a160fc373b1828b0172843b2be1ebd2/src/components/Sidebar.vue#L61) to be Norwegian. Please make it configurable or at lea",
    "url": "https://github.com/HelgeSverre/ollama-gui/issues/26",
    "deadline": null,
    "date": "2024-03-30T20:51:48Z",
    "highlights": [
      "comments: 6"
    ]
  },
  {
    "title": "Using vllm runtime generates \"unrecognized arguments\" error",
    "source": "github_issues",
    "reward": "TBD",
    "summary": "An attempt to use `vllm` runtime generates the following error:\n```\nerror: unrecognized arguments: llama-run -c 2048 --temp 0.8 -v --ngl 999 /mnt/models/model.file\n```\n\nFull log:\n```\n$ ramalama --debu",
    "url": "https://github.com/containers/ramalama/issues/758",
    "deadline": null,
    "date": "2025-02-07T12:15:31Z",
    "highlights": [
      "comments: 12"
    ]
  },
  {
    "title": "The model can't answer",
    "source": "github_issues",
    "reward": "TBD",
    "summary": "(graphrag-ollama-local) root@autodl-container-49d843b6cc-10e9e2a3:~/graphrag-local-ollama# python -m graphrag.query --root ./ragtest --method global \"What is machinelearning?\"\r\n\r\n\r\nINFO: Reading setti",
    "url": "https://github.com/TheAiSingularity/graphrag-local-ollama/issues/23",
    "deadline": null,
    "date": "2024-07-16T05:13:52Z",
    "highlights": [
      "comments: 17"
    ]
  },
  {
    "title": "Local LangGraph RAG agent with Llama 3 error",
    "source": "github_issues",
    "reward": "TBD",
    "summary": "Deprecated function throws error\n\n### Information\n\n- [x] The official example scripts\n- [ ] My own modified scripts\n\n### \ud83d\udc1b Describe the bug\n\nNotebook `3p-integrations/langchain/langgraph_rag_agent_loc",
    "url": "https://github.com/meta-llama/llama-cookbook/issues/894",
    "deadline": null,
    "date": "2025-03-06T11:11:29Z",
    "highlights": [
      "comments: 5"
    ]
  }
]