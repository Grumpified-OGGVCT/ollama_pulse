[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official CLI and Python/JS bindings to run Llama 2, Mistral, Gemma, Phi-3 and other GGUF models locally on macOS, Linux and Windows with GPU acceleration.",
    "source": "github",
    "date": "2024-05-15",
    "highlights": [
      "self-contained binary",
      "model library",
      "OpenAI-compatible REST API",
      "GPU/CPU fallback"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python SDK for Ollama; install via pip install ollama and chat with any local model in two lines.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "pip install ollama",
      "sync & async clients",
      "streaming support",
      "embeddings endpoint"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript SDK for Node & browsers; npm install ollama gives fetch-based client and CLI helpers.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "npm install ollama",
      "TypeScript types",
      "browser & node",
      "streaming JSON"
    ]
  },
  {
    "title": "langchain-community/llms/ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/community/langchain_community/llms/ollama.py",
    "summary": "First-party LangChain integration; drop-in replacement for OpenAI using local Ollama endpoints.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "pip install langchain-community",
      "chat & embed",
      "function-calling",
      "async support"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Drop-in open-source ChatGPT-style web UI for Ollama; Docker one-liner gives multi-user chat, model pull UI and code highlighting.",
    "source": "github",
    "date": "2024-05-13",
    "highlights": [
      "Docker",
      "OpenAI-compatible",
      "multi-model chat",
      "dark/light themes",
      "import/export"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java/Kotlin client for Ollama; Maven artifact offers sync & async APIs, streaming and embedding support.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "Maven Central",
      "Java 11+",
      "Kotlin DSL",
      "reactive streams"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/saltyorg/ollama-cli",
    "summary": "Community Rust CLI that wraps ollama with fuzzy model search, conversation history and shell completions.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "Rust binary",
      "fzf integration",
      "conversation memory",
      "shell completions"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama/ollama-copilot",
    "summary": "VS-Code extension that routes GitHub Copilot calls to a local Ollama model; offline code completions.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "VS Code",
      "offline",
      "inline completions",
      "configurable model"
    ]
  },
  {
    "title": "ollama-chatbot-ui",
    "url": "https://github.com/ivanfioravanti/ollama-chatbot-ui",
    "summary": "Minimal Next.js chatbot template that streams Ollama responses with Tailwind styling and Markdown rendering.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "Next.js",
      "Server-Sent Events",
      "Tailwind",
      "responsive"
    ]
  },
  {
    "title": "ollama-telegram",
    "url": "https://github.com/rueedlinger/ollama-telegram",
    "summary": "Self-hostable Telegram bot that chats with any Ollama model; supports group chats, streaming and per-user quotas.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "Docker",
      "group chat",
      "streaming",
      "rate limits"
    ]
  },
  {
    "title": "ollama-hass-addon",
    "url": "https://github.com/sabeechen/hassio-ollama-addon",
    "summary": "Home-Assistant add-on that spins up Ollama inside the supervisor; expose local LLM to automations and voice assistants.",
    "source": "github",
    "date": "2024-05-04",
    "highlights": [
      "Home Assistant",
      "one-click install",
      "ingress UI",
      "automation friendly"
    ]
  },
  {
    "title": "ollama-rag",
    "url": "https://github.com/ivanfioravanti/ollama-rag",
    "summary": "Ready-to-run RAG stack using Ollama embeddings + Chroma + LangChain; ingest PDFs and query locally.",
    "source": "github",
    "date": "2024-05-03",
    "highlights": [
      "PDF ingestion",
      "ChromaDB",
      "local embeddings",
      "Gradio UI"
    ]
  },
  {
    "title": "ollama-nest",
    "url": "https://github.com/jmcdo29/ollama-nest",
    "summary": "NestJS module that injects an Ollama client as a provider; decorators for streaming, embeddings and guardrails.",
    "source": "github",
    "date": "2024-05-02",
    "highlights": [
      "NestJS",
      "DI module",
      "decorators",
      "RxJS streams"
    ]
  },
  {
    "title": "ollama-dagger-module",
    "url": "https://github.com/shykes/daggerverse/tree/main/ollama",
    "summary": "Dagger module for CI pipelines; spin up Ollama service, pull models and run LLM-based tests inside containers.",
    "source": "github",
    "date": "2024-05-01",
    "highlights": [
      "Dagger/CUE",
      "CI friendly",
      "containerized",
      "model caching"
    ]
  },
  {
    "title": "ollama-csharp",
    "url": "https://github.com/awaescher/ollama-csharp",
    "summary": "Community C# SDK targeting .NET 6+; NuGet package with async streaming, embeddings and tool-calling helpers.",
    "source": "github",
    "date": "2024-04-30",
    "highlights": [
      "NuGet",
      ".NET 6+",
      "async streams",
      "tool calling"
    ]
  },
  {
    "title": "ollama-go",
    "url": "https://github.com/ollama/ollama-go",
    "summary": "Official Go client for Ollama; go get github.com/ollama/ollama/api gives typed structs and streaming support.",
    "source": "github",
    "date": "2024-04-29",
    "highlights": [
      "official",
      "go module",
      "typed",
      "streaming"
    ]
  },
  {
    "title": "ollama-models",
    "url": "https://github.com/ollama/ollama-models",
    "summary": "Curated registry of GGUF models optimized for Ollama; community pull-requests for new quantizations and prompt templates.",
    "source": "github",
    "date": "2024-04-28",
    "highlights": [
      "GGUF",
      "Modelfile",
      "quantization",
      "prompt templates"
    ]
  },
  {
    "title": "ollama-gui",
    "url": "https://github.com/ollama/ollama-gui",
    "summary": "Lightweight Tauri-based desktop app for macOS/Windows/Linux; wraps Ollama with native menus and system-tray controls.",
    "source": "github",
    "date": "2024-04-27",
    "highlights": [
      "Tauri",
      "native binary",
      "system tray",
      "auto-updater"
    ]
  },
  {
    "title": "ollama-discord",
    "url": "https://github.com/ollama/discord",
    "summary": "Official experimental Discord bot that brings Ollama models to any server via slash commands and thread-based chats.",
    "source": "github",
    "date": "2024-04-26",
    "highlights": [
      "slash commands",
      "threads",
      "streaming",
      "role-based access"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/deepset-ai/haystack-core-integrations/tree/main/integrations/ollama",
    "summary": "Haystack 2.x integration; use Ollama models as generators or embedders in Haystack pipelines with YAML config.",
    "source": "github",
    "date": "2024-04-25",
    "highlights": [
      "Haystack 2",
      "YAML pipelines",
      "embedders",
      "generators"
    ]
  }
]