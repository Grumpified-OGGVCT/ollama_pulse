[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: Get up and running with Llama 3, Mistral, Gemma, and other large language models locally.",
    "source": "github",
    "date": "2024-06-01",
    "highlights": [
      "self-hosted LLM runtime",
      "one-command model pull/run",
      "macOS/Linux/Windows"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Ollama.",
    "source": "github",
    "date": "2024-05-28",
    "highlights": [
      "npm install ollama",
      "Promise-based API",
      "works in Node & browsers"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client for Ollama.",
    "source": "github",
    "date": "2024-05-30",
    "highlights": [
      "pip install ollama",
      "sync/async APIs",
      "streaming support"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/partners/ollama",
    "summary": "LangChain integration to use Ollama models as LLMs, embeddings, or tool-calling agents.",
    "source": "github",
    "date": "2024-05-25",
    "highlights": [
      "pip install langchain-ollama",
      "tool use & RAG ready",
      "community & partner package"
    ]
  },
  {
    "title": "ollama-webui (ollama-webui/ollama-webui)",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich chat WebUI for Ollama (renamed to Open WebUI).",
    "source": "github",
    "date": "2024-05-29",
    "highlights": [
      "Docker one-liner",
      "multi-user, RAG uploads",
      "themes & plugins"
    ]
  },
  {
    "title": "open-webui",
    "url": "https://github.com/open-webui/open-webui",
    "summary": "Successor to ollama-webui: open-source ChatGPT-style interface for Ollama and other LLM backends.",
    "source": "github",
    "date": "2024-06-02",
    "highlights": [
      "new name & org",
      "Ollama/OpenAI API support",
      "extensible plugin system"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/ollama/ollama-cli",
    "summary": "Community Rust CLI that wraps the Ollama REST API for easier model management.",
    "source": "github",
    "date": "2024-05-20",
    "highlights": [
      "cargo install ollama-cli",
      "list/pull/run commands",
      "fuzzy finder"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/fostermaier/ollama-copilot",
    "summary": "VS Code extension that brings local Ollama models into GitHub Copilot\u2019s chat sidebar.",
    "source": "github",
    "date": "2024-05-22",
    "highlights": [
      "local Copilot alternative",
      "configurable model",
      "inline chat & completions"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/ollama4j/ollama4j",
    "summary": "Java/Kotlin client library for Ollama with Spring Boot starters.",
    "source": "github",
    "date": "2024-05-27",
    "highlights": [
      "Maven Central",
      "reactive & blocking APIs",
      "Spring Boot auto-config"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/ollama/ollama-rb",
    "summary": "Ruby gem for interacting with the Ollama REST API.",
    "source": "github",
    "date": "2024-05-19",
    "highlights": [
      "gem install ollama",
      "conversational interface",
      "streaming support"
    ]
  },
  {
    "title": "ollama-chat",
    "url": "https://github.com/sugarforever/ollama-chat",
    "summary": "Minimal Next.js chat app that uses Ollama via the ollama-js client.",
    "source": "github",
    "date": "2024-05-18",
    "highlights": [
      "Next.js 14",
      "server & client components",
      "Docker ready"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/ollama/ollama-haystack",
    "summary": "Haystack integration by deepset to use Ollama models for QA & RAG pipelines.",
    "source": "github",
    "date": "2024-05-24",
    "highlights": [
      "pip install ollama-haystack",
      "generator & embedder nodes",
      "Haystack 2.x ready"
    ]
  },
  {
    "title": "ollama-cookbook",
    "url": "https://github.com/ollama/ollama-cookbook",
    "summary": "Community recipes: fine-tune, quantize, deploy, and integrate Ollama models.",
    "source": "github",
    "date": "2024-05-26",
    "highlights": [
      "Jupyter notebooks",
      "LoRA fine-tuning",
      "Kubernetes manifests"
    ]
  },
  {
    "title": "ollama-docker-compose",
    "url": "https://github.com/ollama/ollama-docker-compose",
    "summary": "Production-ready Docker Compose stacks for Ollama with GPU support and WebUI.",
    "source": "github",
    "date": "2024-05-21",
    "highlights": [
      "NVIDIA runtime",
      "Open WebUI service",
      "volume management"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/ollama/ollama-helm",
    "summary": "Helm chart to deploy Ollama on Kubernetes with autoscaling and PVC support.",
    "source": "github",
    "date": "2024-05-23",
    "highlights": [
      "GPU node selector",
      "HorizontalPodAutoscaler",
      "configmaps for models"
    ]
  }
]