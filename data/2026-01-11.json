[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "The official Ollama CLI and server that lets you run Llama 2, CodeLlama, Mistral, Gemma, and other large language models locally with GPU/CPU acceleration and a simple REST API.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "CLI",
      "REST API",
      "Docker image",
      "macOS/Linux/Windows",
      "GGUF support"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python library for Ollama; wrap the local Ollama server with Pythonic functions for chat, generate, embed, pull, and list models.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "pip install ollama",
      "async/sync APIs",
      "streaming",
      "embeddings"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Ollama; run and chat with local LLMs from Node or browsers via the Ollama REST endpoints.",
    "source": "github",
    "date": "2024-05-13",
    "highlights": [
      "npm i ollama",
      "TypeScript types",
      "streaming",
      "Promise-based"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/ollama",
    "summary": "LangChain integration for Ollama; use any Ollama-hosted model as a LangChain LLM or chat model with callbacks, memory, and chains.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "pip install langchain-ollama",
      "chat",
      "embed",
      "tool-calling"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich web UI for Ollama (formerly Ollama-WebUI); chat, multi-model convos, file uploads, RAG, dark/light themes, admin panel.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "Docker",
      "OpenAI-compatible API",
      "RAG",
      "multi-user",
      "themes"
    ]
  },
  {
    "title": "lobe-chat",
    "url": "https://github.com/lobehub/lobe-chat",
    "summary": "Modern open-source chatbot framework with Ollama provider support; plugins, vision, TTS, multi-language, PWA, mobile-friendly.",
    "source": "github",
    "date": "2024-05-13",
    "highlights": [
      "Ollama provider",
      "plugin store",
      "vision",
      "TTS",
      "PWA"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/ollama4j/ollama4j",
    "summary": "Java/JVM client for Ollama; idiomatic Java API for chat, generate, pull, list, delete, copy, and show model info.",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "Maven Central",
      "reactive streams",
      "Kotlin-friendly",
      "Spring Boot starter"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/ollama/ollama-rb",
    "summary": "Official Ruby gem for Ollama; simple Ruby client to chat, generate, and manage local models via Ollama.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "gem install ollama",
      "streaming",
      "Faraday backend",
      "Rails ready"
    ]
  },
  {
    "title": "ollama-cli (npm)",
    "url": "https://www.npmjs.com/package/ollama-cli",
    "summary": "Community-built Node CLI wrapper around Ollama; interactive chat, model pull, list, and delete from the terminal.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "npm i -g ollama-cli",
      "interactive REPL",
      "chalk colors",
      "autocomplete"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama/ollama-copilot",
    "summary": "VS Code extension that turns any Ollama model into a GitHub Copilot-like pair programmer; inline suggestions and chat sidebar.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "VS Code marketplace",
      "inline completions",
      "chat panel",
      "configurable model"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/ollama/haystack",
    "summary": "Haystack integration by deepset; use Ollama models as generators or embedders in Haystack pipelines for RAG and QA.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "pip install ollama-haystack",
      "generator",
      "embedder",
      "RAG ready"
    ]
  },
  {
    "title": "ollama-csharp",
    "url": "https://github.com/ollama/ollama-csharp",
    "summary": "Community-maintained .NET/C# client for Ollama; async API, streaming chat, and dependency-injection helpers for ASP.NET Core.",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "NuGet Ollama",
      "System.Text.Json",
      "streaming",
      "DI extensions"
    ]
  },
  {
    "title": "ollama-camunda-bridge",
    "url": "https://github.com/camunda-community-hub/ollama-camunda-bridge",
    "summary": "Camunda Community extension that exposes Ollama models as job workers; integrate LLM steps into BPMN processes.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "Camunda 8",
      "Zeebe",
      "BPMN",
      "job worker",
      "Docker"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/ollama/ollama-helm",
    "summary": "Helm chart to deploy Ollama on Kubernetes; GPU node selection, PVC for models, autoscaling, and ingress.",
    "source": "github",
    "date": "2024-05-13",
    "highlights": [
      "Helm",
      "Kubernetes",
      "GPU",
      "PVC",
      "autoscaling"
    ]
  },
  {
    "title": "ollama-rag-langchain",
    "url": "https://github.com/ggerganov/ollama-rag-langchain",
    "summary": "Minimal RAG template combining Ollama embeddings + Llama 2 with LangChain and Chroma; PDF ingestion and Q&A.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "RAG",
      "Chroma",
      "PDF",
      "Llama 2",
      "LangChain"
    ]
  },
  {
    "title": "ollama-discord-bot",
    "url": "https://github.com/ollama-discord/ollama-discord-bot",
    "summary": "Self-hostable Discord bot that brings any Ollama model into a server; slash commands, thread support, and moderation hooks.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "Discord.py",
      "slash commands",
      "threads",
      "moderation"
    ]
  },
  {
    "title": "ollama-rust",
    "url": "https://github.com/ollama/ollama-rust",
    "summary": "Rust crate for Ollama; strongly-typed client for chat, generate, pull, and embeddings with Tokio and streaming support.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "crates.io",
      "async/await",
      "Tokio",
      "streaming",
      "typed errors"
    ]
  },
  {
    "title": "ollama-go",
    "url": "https://github.com/ollama/ollama-go",
    "summary": "Official Go client library for Ollama; idiomatic Go API with context support and streaming helpers.",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "go get",
      "context",
      "streaming",
      "error wrapping"
    ]
  },
  {
    "title": "ollama-model-library",
    "url": "https://github.com/ollama/ollama-model-library",
    "summary": "Community-curated registry of GGUF models pre-configured for Ollama; includes Modelfile snippets and performance notes.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "Modelfile",
      "GGUF",
      "benchmarks",
      "community"
    ]
  },
  {
    "title": "ollama-rag-obsidian",
    "url": "https://github.com/ollama-rag/ollama-rag-obsidian",
    "summary": "Obsidian plugin that creates a local RAG vault using Ollama embeddings; search and chat with your notes offline.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "Obsidian plugin",
      "offline",
      "RAG",
      "embeddings",
      "vault search"
    ]
  }
]