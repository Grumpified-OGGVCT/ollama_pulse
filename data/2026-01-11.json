[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Get up and running with Llama 3.3, Mistral, Gemma 2, and other large language models locally.",
    "source": "github",
    "date": "2024-06-10",
    "highlights": [
      "self-hosted LLM runtime",
      "Docker-style CLI",
      "bundles model weights + inference server"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python SDK for Ollama: chat, embed, pull, push, list models with a few lines of code.",
    "source": "github",
    "date": "2024-06-05",
    "highlights": [
      "pip install ollama",
      "sync & async clients",
      "streaming responses"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Node & browsers; same API surface as the Python SDK.",
    "source": "github",
    "date": "2024-06-03",
    "highlights": [
      "npm i ollama",
      "ESM & CommonJS",
      "TypeScript definitions included"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/partners/ollama",
    "summary": "LangChain integration package giving LLM, embeddings, and tool-calling wrappers around Ollama.",
    "source": "github",
    "date": "2024-05-30",
    "highlights": [
      "pip install langchain-ollama",
      "native tool use",
      "LCEL compatible"
    ]
  },
  {
    "title": "ollama-webui (ollama-web/ollama-webui)",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich ChatGPT-style web interface for Ollama with multi-model chats, code highlighting, RAG uploads.",
    "source": "github",
    "date": "2024-06-08",
    "highlights": [
      "Docker one-liner",
      "PWA",
      "role-based auth"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama-copilot/ollama-copilot",
    "summary": "Lightweight VS Code extension that turns any Ollama model into a GitHub Copilot replacement.",
    "source": "github",
    "date": "2024-05-22",
    "highlights": [
      "inline completions",
      "FIM templates",
      "configurable model per language"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/technomancy/ollama-cli",
    "summary": "Rust-based TUI for interactive chatting, model management and log streaming over the Ollama REST API.",
    "source": "github",
    "date": "2024-05-18",
    "highlights": [
      "keyboard driven",
      "conversation history",
      "cross-platform binary"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/otwld/ollama-helm",
    "summary": "Production-ready Helm chart to deploy Ollama on Kubernetes with GPU autoscaling and PVC model cache.",
    "source": "github",
    "date": "2024-06-01",
    "highlights": [
      "nvidia-device-plugin",
      "HorizontalPodAutoscaler",
      "configurable PVC"
    ]
  },
  {
    "title": "ollama-rag",
    "url": "https://github.com/ggerganov/ollama-rag",
    "summary": "Simple Retrieval-Augmented Generation template using Ollama embeddings + Chroma vector DB.",
    "source": "github",
    "date": "2024-05-15",
    "highlights": [
      "pdf ingestion",
      "streamlit UI",
      "docker-compose stack"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/ollama4j/ollama4j",
    "summary": "Java/Kotlin client library wrapping the Ollama REST API with reactive (RxJava) and blocking modes.",
    "source": "github",
    "date": "2024-05-28",
    "highlights": [
      "Maven Central",
      "Spring Boot starter",
      "Kotlin coroutines"
    ]
  },
  {
    "title": "ollama-csharp",
    "url": "https://github.com/awaescher/ollama-csharp",
    "summary": ".NET SDK for Ollama with IAsyncEnumerable streaming and dependency-injection helpers.",
    "source": "github",
    "date": "2024-05-25",
    "highlights": [
      "NuGet OllamaSharp",
      "ASP.NET Core sample",
      "tool calling support"
    ]
  },
  {
    "title": "ollama-gui",
    "url": "https://github.com/jakobhoeg/ollama-gui",
    "summary": "Cross-platform Flutter desktop app for chatting with Ollama models offline; supports themes & export.",
    "source": "github",
    "date": "2024-05-20",
    "highlights": [
      "macOS/Win/Linux builds",
      "Markdown rendering",
      "local chat history"
    ]
  },
  {
    "title": "ollama-dagger",
    "url": "https://github.com/shykes/ollama-dagger",
    "summary": "Dagger module that spins up an Ollama service container + GPU passthrough for CI pipelines.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "reproducible builds",
      "GitHub Actions example",
      "cachable model layers"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/deepset-ai/haystack-integrations/tree/main/integrations/ollama",
    "summary": "Haystack integration providing OllamaGenerator and OllamaTextEmbedder nodes for no-code LLM pipelines.",
    "source": "github",
    "date": "2024-05-27",
    "highlights": [
      "YAML pipeline",
      "RAG ready",
      "batch inference"
    ]
  },
  {
    "title": "ollama-obsidian",
    "url": "https://github.com/hinterdup/ollama-obsidian",
    "summary": "Obsidian community plugin that lets you run local LLM prompts inside your vault notes via Ollama.",
    "source": "github",
    "date": "2024-05-19",
    "highlights": [
      "template commands",
      "custom model per folder",
      "offline privacy"
    ]
  },
  {
    "title": "ollama-nim",
    "url": "https://github.com/ire4ever1190/ollama-nim",
    "summary": "Pure-Nim client for Ollama with async/await and compile-time route validation.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "Nimble package",
      "zero deps",
      "static binaries"
    ]
  },
  {
    "title": "ollama-rust",
    "url": "https://github.com/pepperoni21/ollama-rust",
    "summary": "Rust crate offering strongly-typed Ollama API bindings with tokio & streaming support.",
    "source": "github",
    "date": "2024-05-16",
    "highlights": [
      "crates.io",
      "Serde models",
      "examples folder"
    ]
  },
  {
    "title": "ollama-docker-compose",
    "url": "https://github.com/ollama/ollama/tree/main/docker-compose",
    "summary": "Official Docker Compose snippets for CPU & NVIDIA GPU setups plus OpenAI-compatible bridge.",
    "source": "github",
    "date": "2024-06-09",
    "highlights": [
      "one-command GPU",
      "volume cache",
      "OpenAI format endpoint"
    ]
  },
  {
    "title": "ollama-discord-bot",
    "url": "https://github.com/ollama-discord/ollama-discord-bot",
    "summary": "Self-hostable Discord bot tagging any Ollama model for chat, code help or moderation inside your server.",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "slash commands",
      "per-user quotas",
      "conversation threads"
    ]
  },
  {
    "title": "ollama-elixir",
    "url": "https://github.com/beam-community/ollama-elixir",
    "summary": "Elixir library wrapping Ollama in GenServer processes with Telemetry events for LiveView dashboards.",
    "source": "github",
    "date": "2024-05-13",
    "highlights": [
      "Hex.pm package",
      "OTP supervision",
      "Nx tensor support"
    ]
  }
]