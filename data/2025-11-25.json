[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "The official Ollama CLI and server for running large language models locally; supports Llama 2, Mistral, Gemma, etc.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "pull/push model registry",
      "REST & streaming API",
      "macOS/Linux/Windows binaries"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client library for the Ollama API; chat, generate, embed, list models.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "pip install ollama",
      "sync/async clients",
      "built-in embedding helpers"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Node & browsers; same API surface as Python client.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "npm i ollama",
      "streaming support",
      "TypeScript definitions"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/ollama",
    "summary": "LangChain integration package providing Ollama LLM, embedder and retriever components.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "pip install langchain-ollama",
      "chat & embedding wrappers",
      "native callback support"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich web UI for Ollama (ChatGPT-style); model management, code highlighting, RAG uploads.",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "Docker one-liner",
      "multi-user auth",
      "open-source MIT"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java/Kotlin client for Ollama; fluent API, streaming, model management.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "Maven Central",
      "Kotlin coroutines",
      "Spring Boot starters"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/ollama/ollama-rb",
    "summary": "Community-maintained Ruby gem for chatting and generating with local Ollama models.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "gem install ollama",
      "Fiber-based streaming",
      "Rails examples"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/salty-flower/ollama-cli",
    "summary": "Cross-platform TUI (terminal UI) client for interactive chats with Ollama models.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "Rust binary",
      "themes & keybindings",
      "markdown preview"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama/ollama-copilot",
    "summary": "VS Code extension that routes GitHub Copilot calls to a local Ollama model for private completions.",
    "source": "github",
    "date": "2024-05-04",
    "highlights": [
      "open-source",
      "configurable model",
      "inline suggestions"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/deepset-ai/haystack-integrations/tree/main/integrations/ollama",
    "summary": "Haystack integration supplying OllamaGenerator and OllamaEmbedder nodes for pipelines.",
    "source": "github",
    "date": "2024-05-03",
    "highlights": [
      "pip install haystack-ai[ollama]",
      "RAG ready",
      "batch inference"
    ]
  },
  {
    "title": "ollama-camunda",
    "url": "https://github.com/camunda-community-hub/ollama-camunda",
    "summary": "Camunda 8 connector that invokes Ollama models inside BPMN processes for human tasks.",
    "source": "github",
    "date": "2024-05-02",
    "highlights": [
      "self-hosted",
      "output mapping",
      "zero Java code"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/otwld/ollama-helm",
    "summary": "Production-ready Helm chart for deploying Ollama server on Kubernetes with GPU support.",
    "source": "github",
    "date": "2024-05-01",
    "highlights": [
      "autoscaling",
      "PVC model cache",
      "Prometheus metrics"
    ]
  },
  {
    "title": "ollama-docker",
    "url": "https://github.com/ollama/ollama/tree/main/docker",
    "summary": "Official container images (CPU & GPU) and compose examples for Ollama server.",
    "source": "github",
    "date": "2024-04-30",
    "highlights": [
      "one-liner docker run",
      "CUDA image",
      "ARM64 support"
    ]
  },
  {
    "title": "ollama-rag",
    "url": "https://github.com/glangchain/ollama-rag",
    "summary": "Minimal RAG template using Ollama embeddings + Chroma + LangChain to chat with documents.",
    "source": "github",
    "date": "2024-04-29",
    "highlights": [
      "Poetry setup",
      "PDF loader",
      "Gradio UI"
    ]
  },
  {
    "title": "ollama-discord",
    "url": "https://github.com/rizerphe/ollama-discord",
    "summary": "Self-hostable Discord bot that streams Ollama model replies in servers/DMs.",
    "source": "github",
    "date": "2024-04-28",
    "highlights": [
      "slash commands",
      "threaded chats",
      "model per channel"
    ]
  },
  {
    "title": "ollama-nestjs",
    "url": "https://github.com/seriousme/ollama-nestjs",
    "summary": "NestJS module wrapping the Ollama API with decorators and dependency injection.",
    "source": "github",
    "date": "2024-04-27",
    "highlights": [
      "npm i nestjs-ollama",
      "RxJS streams",
      "configurable providers"
    ]
  },
  {
    "title": "ollama-sdks",
    "url": "https://github.com/ollama/ollama-sdks",
    "summary": "Meta-repository tracking community SDKs for Go, C#, Swift and more.",
    "source": "github",
    "date": "2024-04-26",
    "highlights": [
      "auto-generated clients",
      "OpenAPI specs",
      "contribution guide"
    ]
  },
  {
    "title": "ollama-gpt4all-ui",
    "url": "https://github.com/nomic-ai/gpt4all-ui",
    "summary": "GPT4All chat UI that can switch backend to Ollama via REST for local model chats.",
    "source": "github",
    "date": "2024-04-25",
    "highlights": [
      "model hub browser",
      "chat history",
      "local network mode"
    ]
  },
  {
    "title": "ollama-huggingface",
    "url": "https://github.com/huggingface/transformers/pull/30991",
    "summary": "Open pull request adding OllamaLLM class to Hugging Face transformers for seamless integration.",
    "source": "github",
    "date": "2024-04-24",
    "highlights": [
      "pip install from branch",
      "generation config",
      "pipeline compatible"
    ]
  },
  {
    "title": "ollama-rust",
    "url": "https://github.com/ollama-rs/ollama-rs",
    "summary": "Community Rust crate providing async/await bindings to the Ollama HTTP API.",
    "source": "github",
    "date": "2024-04-23",
    "highlights": [
      "cargo add ollama-rs",
      "tokio streams",
      "examples folder"
    ]
  }
]