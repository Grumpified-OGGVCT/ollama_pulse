[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: get up and running with Llama 3, Mistral, Gemma, and other large language models locally.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "self-contained LLM runner",
      "macOS/Linux/Windows binaries",
      "Docker image",
      "REST & CLI APIs"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client for Ollama; chat, generate embeddings, pull/list models with a few lines of code.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "PyPI: ollama",
      "sync & async APIs",
      "streaming support",
      "type hints"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Node & browsers; same generate/chat/embed surface as Python.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "npm: ollama",
      "ESM & CJS bundles",
      "browser polyfill",
      "Promise/async iterators"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/partners/ollama",
    "summary": "First-party LangChain integration; use Ollama models as LLM or embeddings in any LangChain pipeline.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "pip: langchain-ollama",
      "chat & embed interfaces",
      "tool calling",
      "batch support"
    ]
  },
  {
    "title": "ollama-webui (Ollama-WebUI)",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich web UI for Ollama (ChatGPT-style); runs entirely in browser, no external DB needed.",
    "source": "github",
    "date": "2024-05-13",
    "highlights": [
      "Docker image",
      "multi-user, RBAC",
      "RAG via uploaded docs",
      "voice input, themes, plugins"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java/Kotlin client for Ollama; fluent builder API, streaming, embeddings, model management.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "Maven Central",
      "Android compatible",
      "reactive streams",
      "Spring Boot starter"
    ]
  },
  {
    "title": "ollama-rag",
    "url": "https://github.com/ivanfioravivi/ollama-rag",
    "summary": "Minimal RAG template using Ollama + Chroma; ingest PDFs and chat over them locally.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "Docker Compose stack",
      "Gradio UI",
      "sentence-transformers embeddings",
      "offline mode"
    ]
  },
  {
    "title": "ollama-cli (rust)",
    "url": "https://github.com/ollama-rs/ollama-cli",
    "summary": "Fast terminal UI for Ollama written in Rust; fuzzy model finder, REPL, conversation history.",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "crates.io: ollama-cli",
      "cross-platform binary",
      "themes, keybindings",
      "markdown rendering"
    ]
  },
  {
    "title": "ollama-copilot (VS Code)",
    "url": "https://github.com/mshd/ollama-copilot",
    "summary": "VS Code extension bringing Ollama models inline like GitHub Copilot; supports fill-in-the-middle.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "Marketplace: Ollama Copilot",
      "multi-model quick pick",
      "custom prompts",
      "local privacy"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/ollama-haystack/ollama-haystack",
    "summary": "Haystack integration by the community; use Ollama as generator or embedder in Haystack pipelines.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "pip: ollama-haystack",
      "generator & embedder nodes",
      "streaming answers",
      "example notebooks"
    ]
  },
  {
    "title": "ollama-cookbook",
    "url": "https://github.com/ollama/cookbook",
    "summary": "Community-contributed recipes: function-calling, voice chat, Docker Compose stacks, GPU tweaks.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "OpenAI-compatible server shim",
      "Home Assistant add-on",
      "Flutter app",
      "OpenAPI spec"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/otwld/ollama-helm",
    "summary": "Production-ready Helm chart for Ollama on Kubernetes; autoscaling, PVC, GPU node-selector.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "ArtifactHub published",
      "Prometheus metrics",
      "Ingress & TLS",
      "multi-model sidecar"
    ]
  },
  {
    "title": "ollama-nim",
    "url": "https://github.com/ITotalJustice/ollama-nim",
    "summary": "Nim client for Ollama; zero-dependency FFI, async dispatch, same API surface as official clients.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "Nimble package",
      "threads & asyncHttpClient",
      "examples & docs",
      "cross-compile friendly"
    ]
  },
  {
    "title": "ollama-dart",
    "url": "https://github.com/marcotrimeri/ollama-dart",
    "summary": "Dart/Flutter package for Ollama; chat, generate, embeddings, model management with strong typing.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "pub.dev: ollama",
      "Streams & Futures",
      "Flutter example app",
      "unit-tested"
    ]
  },
  {
    "title": "ollama-rust",
    "url": "https://github.com/pepperoni21/ollama-rust",
    "summary": "Community Rust crate; async client using reqwest, covers full Ollama REST API.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "crates.io: ollama-rs",
      "tokio/async",
      "serde types",
      "examples"
    ]
  },
  {
    "title": "ollama-csharp",
    "url": "https://github.com/AsakusaRinne/ollama-csharp",
    "summary": ".NET client for Ollama; supports .NET 6+, async enumerable streaming, dependency injection.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "NuGet: OllamaSharp",
      "strong naming",
      "source generators for JSON",
      "Blazor demo"
    ]
  },
  {
    "title": "ollama-modal",
    "url": "https://github.com/ericdb/ollama-modal",
    "summary": "Run Ollama models on Modal serverless GPUs; pay-per-second scaling with simple CLI.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "pip: ollama-modal",
      "one-command deploy",
      "A100/L40S GPUs",
      "persistent volume cache"
    ]
  },
  {
    "title": "ollama-obsidian",
    "url": "https://github.com/hintergrund/ollama-obsidian",
    "summary": "Obsidian plugin that adds Ollama commands: summarize note, brainstorm tags, translate, Q&A vault.",
    "source": "github",
    "date": "2024-05-04",
    "highlights": [
      "Community plugin list",
      "custom prompt templates",
      "offline privacy",
      "command palette"
    ]
  },
  {
    "title": "ollama-slack-bot",
    "url": "https://github.com/roychri/ollama-slack-bot",
    "summary": "Slack bot server that forwards channel DMs to Ollama and streams answers back as threaded replies.",
    "source": "github",
    "date": "2024-05-03",
    "highlights": [
      "Docker image",
      "Socket-Mode support",
      "per-channel model config",
      "rate limiting"
    ]
  },
  {
    "title": "ollama-discord",
    "url": "https://github.com/sbaildon/ollama-discord",
    "summary": "Discord bot using slash commands to chat with any Ollama model; streams responses with typing indicator.",
    "source": "github",
    "date": "2024-05-02",
    "highlights": [
      "npm package",
      "Docker Compose",
      "role-based access",
      "conversation memory"
    ]
  }
]