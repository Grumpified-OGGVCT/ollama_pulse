[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama CLI and server that lets you run Llama 2, Mistral, Gemma, and other large language models locally with GPU/CPU acceleration and a simple REST API.",
    "source": "github",
    "date": "2024-05-20",
    "highlights": [
      "Docker image",
      "macOS/Linux/Windows",
      "Model library",
      "OpenAI-compatible endpoints"
    ]
  },
  {
    "title": "ollama/ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Ollama; chat, generate, embed, pull, and manage models from Node or the browser.",
    "source": "github",
    "date": "2024-05-15",
    "highlights": [
      "npm install ollama",
      "Promise-based API",
      "Streaming support",
      "TypeScript defs"
    ]
  },
  {
    "title": "ollama/ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client for Ollama with sync/async APIs, streaming, embeddings, and built-in retries.",
    "source": "github",
    "date": "2024-05-18",
    "highlights": [
      "pip install ollama",
      "Asyncio support",
      "Pydantic models",
      "Jupyter ready"
    ]
  },
  {
    "title": "jmorganca/ollama",
    "url": "https://pypi.org/project/ollama/",
    "summary": "PyPI landing page for the official ollama Python package (mirror of GitHub repo).",
    "source": "pypi",
    "date": "2024-05-17",
    "highlights": [
      "pip installable",
      "Same API as GitHub",
      "Wheel for macOS/Linux/Windows"
    ]
  },
  {
    "title": "ollama/ollama-npm",
    "url": "https://www.npmjs.com/package/ollama",
    "summary": "npm registry page for the official ollama JavaScript package (mirror of GitHub repo).",
    "source": "npm",
    "date": "2024-05-16",
    "highlights": [
      "Zero deps",
      "ESM & CJS exports",
      "Typedoc docs"
    ]
  },
  {
    "title": "langchain-ai/langchain/tree/master/libs/community/langchain_community/llms/ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/community/langchain_community/llms/ollama.py",
    "summary": "LangChain community integration that wraps Ollama\u2019s REST API for chat, generate, and embed functions.",
    "source": "github",
    "date": "2024-05-19",
    "highlights": [
      "pip install langchain-community",
      "Standard LLM/Chat interface",
      "Callback streaming"
    ]
  },
  {
    "title": "langchain-ai/langchainjs/ollama",
    "url": "https://github.com/langchain-ai/langchainjs/tree/main/libs/langchain-ollama",
    "summary": "LangChain.js Ollama integration providing chat and generate methods with streaming and tool-calling support.",
    "source": "github",
    "date": "2024-05-18",
    "highlights": [
      "npm install @langchain/ollama",
      "OpenAI-format tools",
      "Structured output"
    ]
  },
  {
    "title": "embedchain/embedchain",
    "url": "https://github.com/embedchain/embedchain",
    "summary": "RAG framework with built-in Ollama support for local embeddings and chat; ingest PDFs, web pages, videos, and query with citations.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "pip install embedchain[ollama]",
      "30+ loaders",
      "Docker Compose stack"
    ]
  },
  {
    "title": "continuedev/continue",
    "url": "https://github.com/continuedev/continue",
    "summary": "VS Code & JetBrains plugin that adds local LLM coding assistant via Ollama (code autocomplete, /commands, highlight-to-ask).",
    "source": "github",
    "date": "2024-05-20",
    "highlights": [
      "Free & open-source",
      "Inline editing",
      "Bring-your-own-model"
    ]
  },
  {
    "title": "jina-ai/ollama-instructor",
    "url": "https://github.com/jina-ai/ollama-instructor",
    "summary": "Lightweight Python helper that turns any Ollama model into an instruction-following agent with structured JSON output.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "pip install ollama-instructor",
      "Pydantic schemas",
      "Retries & validation"
    ]
  },
  {
    "title": "ollama-webui/ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich ChatGPT-style web client for Ollama with multi-model chats, code highlighting, RAG uploads, and user management.",
    "source": "github",
    "date": "2024-05-19",
    "highlights": [
      "Docker one-liner",
      "OpenAI-compat API",
      "Dark/light themes"
    ]
  },
  {
    "title": "otra/ollama-cli",
    "url": "https://github.com/otra/ollama-cli",
    "summary": "Interactive TUI for Ollama written in Go\u2014browse, pull, chat, and manage models from the terminal.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "fuzzy search",
      "chat history",
      "single binary"
    ]
  },
  {
    "title": "pepperoni21/ollama-rag",
    "url": "https://github.com/pepperoni21/ollama-rag",
    "summary": "Minimal Python repo showing how to build a private RAG pipeline with Ollama embeddings and Chroma vector store.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "FastAPI backend",
      "Streamlit frontend",
      "Dockerized"
    ]
  },
  {
    "title": "sugarforever/ollama-node-red",
    "url": "https://github.com/sugarforever/ollama-node-red",
    "summary": "Node-RED nodes to chat and generate text with Ollama models inside IoT & automation flows.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "npm install node-red-contrib-ollama",
      "Visual wiring",
      "Streaming msg"
    ]
  },
  {
    "title": "rick-github/ollama-docker",
    "url": "https://github.com/rick-github/ollama-docker",
    "summary": "Ready-made Docker Compose stacks for running Ollama server with GPU (CUDA/ROCm) or CPU-only plus optional web UI.",
    "source": "github",
    "date": "2024-05-15",
    "highlights": [
      "nvidia-docker",
      "AMD ROCm",
      "Volume caching"
    ]
  },
  {
    "title": "ollama/ollama-hub",
    "url": "https://github.com/ollama/ollama-hub",
    "summary": "Community registry of custom Modelfiles, quantized GGUFs, and example prompts curated for Ollama.",
    "source": "github",
    "date": "2024-05-13",
    "highlights": [
      "Pull-request workflow",
      "Tag search",
      "License badges"
    ]
  },
  {
    "title": "ggerganov/llama.cpp #ollama",
    "url": "https://github.com/ggerganov/llama.cpp/discussions/categories/ollama",
    "summary": "Discussion board where Ollama users share benchmarks, quantization tips, and feature requests related to llama.cpp backend.",
    "source": "github",
    "date": "2024-05-20",
    "highlights": [
      "Performance threads",
      "Quant recipes",
      "Hardware tuning"
    ]
  },
  {
    "title": "r/ollama on Reddit",
    "url": "https://www.reddit.com/r/ollama/",
    "summary": "Active subreddit for troubleshooting, model recommendations, and showcasing projects built on Ollama.",
    "source": "reddit",
    "date": "2024-05-19",
    "highlights": [
      "3k+ members",
      "Daily Q&A",
      "Show-off Saturday"
    ]
  },
  {
    "title": "Hacker News: Show HN: Ollama \u2013 Run LLMs locally with one command",
    "url": "https://news.ycombinator.com/item?id=38512345",
    "summary": "Launch thread with benchmarks, security discussion, and maintainer answers about roadmap.",
    "source": "hackernews",
    "date": "2024-05-17",
    "highlights": [
      "700+ comments",
      "M1 vs RTX tests",
      "MIT license"
    ]
  },
  {
    "title": "mchiang0610/ollama-azure",
    "url": "https://github.com/mchiang0610/ollama-azure",
    "summary": "Terraform & Bicep templates to deploy Ollama on Azure Container Instances with GPU SKU and secure networking.",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "Spot pricing",
      "Private endpoints",
      "Log Analytics"
    ]
  }
]