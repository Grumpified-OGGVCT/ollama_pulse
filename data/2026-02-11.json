[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official CLI and Python/JS bindings to pull and run Llama 2, Mistral, Gemma, Phi, etc. locally with one command.",
    "source": "github",
    "date": "2024-05-01",
    "highlights": [
      "self-contained binary",
      "modelfile DSL",
      "REST & streaming API",
      "macOS/Linux/Windows"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "First-party async/sync Python client generated from the OpenAPI spec; chat, embed, pull, push, list, delete.",
    "source": "github",
    "date": "2024-04-30",
    "highlights": [
      "pip install ollama",
      "full type hints",
      "built-in embedding helpers"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Node, Deno & browsers; promises & streams, ESM/CJS dual pkg.",
    "source": "github",
    "date": "2024-04-29",
    "highlights": [
      "npm i ollama",
      "browser-compatible",
      "auto-abort signal"
    ]
  },
  {
    "title": "langchain-community/llms/ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/community/langchain_community/llms/ollama.py",
    "summary": "LangChain integration exposing chat, generate, embed and tool-calling with any Ollama model.",
    "source": "github",
    "date": "2024-04-28",
    "highlights": [
      "native tool use",
      "async support",
      "callback streaming"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich ChatGPT-like web UI for Ollama: folders, share links, multimodal, RAG, admin panel, dark mode.",
    "source": "github",
    "date": "2024-04-27",
    "highlights": [
      "Docker one-liner",
      "OpenAI-compat endpoint",
      "PDF/CSV ingestion"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java/Kotlin client with fluent builder API, async wrappers, and Spring Boot starter.",
    "source": "github",
    "date": "2024-04-25",
    "highlights": [
      "Maven Central",
      "reactive templates",
      "Spring autoconfig"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/gbaptista/ollama-rb",
    "summary": "Ruby gem wrapping the REST API; supports chat, completion, embeddings, model management.",
    "source": "github",
    "date": "2024-04-24",
    "highlights": [
      "gem install ollama",
      "Fiber-based streaming",
      "Rails examples"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/salty-flower/ollama-cli",
    "summary": "Rust TUI client with fuzzy model finder, conversation history, markdown rendering, key-bindings like Vim.",
    "source": "github",
    "date": "2024-04-23",
    "highlights": [
      "cross-platform binary",
      "config themes",
      "offline history"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama/ollama-copilot",
    "summary": "VS Code extension that turns any Ollama model into inline GitHub Copilot replacement.",
    "source": "github",
    "date": "2024-04-22",
    "highlights": [
      "inline completions",
      "custom prompts",
      "multifile context"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/deepset-ai/haystack-core-integrations/tree/main/integrations/ollama",
    "summary": "Haystack 2.0 component to use Ollama generators & embedders in production pipelines.",
    "source": "github",
    "date": "2024-04-21",
    "highlights": [
      "pipeline YAML",
      "batch embed",
      "tracing integration"
    ]
  },
  {
    "title": "ollama-cookbook",
    "url": "https://github.com/ollama/ollama-cookbook",
    "summary": "Community recipes: function-calling, PDF chat, voice, Docker Compose stacks, GPU tuning snippets.",
    "source": "github",
    "date": "2024-04-20",
    "highlights": [
      "ready-to-run notebooks",
      "Modelfile gallery",
      "k8s helm chart"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/otwld/ollama-helm",
    "summary": "Production Helm chart for Kubernetes with autoscaling, PVC, ingress, GPU node-selectors.",
    "source": "github",
    "date": "2024-04-19",
    "highlights": [
      "Helm repo",
      "Prometheus metrics",
      "HPA support"
    ]
  },
  {
    "title": "ollama-docker",
    "url": "https://github.com/ollama/ollama/tree/main/docker",
    "summary": "Official container images (cuda/rocm/cpu) and compose examples with persistent volumes.",
    "source": "github",
    "date": "2024-04-18",
    "highlights": [
      "multi-arch",
      "rootless",
      "GPU flags"
    ]
  },
  {
    "title": "ollama-nix",
    "url": "https://github.com/NixOS/nixpkgs/tree/master/pkgs/tools/misc/ollama",
    "summary": "Nix flake packaging Ollama server & CLI with CUDA and ROCm optional accelerators.",
    "source": "github",
    "date": "2024-04-17",
    "highlights": [
      "nix run",
      "pinned hashes",
      "module service"
    ]
  },
  {
    "title": "ollama-rag",
    "url": "https://github.com/ivanfioravivi/ollama-rag",
    "summary": "Minimal RAG template using Ollama embeddings + Chroma + Streamlit to chat over your docs.",
    "source": "github",
    "date": "2024-04-16",
    "highlights": [
      "pipenv lock",
      "chunking strategies",
      "Gradio alt UI"
    ]
  },
  {
    "title": "ollama-discord",
    "url": "https://github.com/mxyng/ollama-discord",
    "summary": "Discord bot that streams Ollama replies in threads; supports slash commands, system prompts, model swap.",
    "source": "github",
    "date": "2024-04-15",
    "highlights": [
      "Docker",
      "role-based limits",
      "chat history"
    ]
  },
  {
    "title": "ollama-slack",
    "url": "https://github.com/andyj/ollama-slack",
    "summary": "Slack Bolt app that brings local LLMs into channels with event subscriptions and modals.",
    "source": "github",
    "date": "2024-04-14",
    "highlights": [
      "socket mode",
      "app home",
      "rate limiting"
    ]
  },
  {
    "title": "ollama-dagger",
    "url": "https://github.com/sagikazarmark/daggerverse/tree/main/ollama",
    "summary": "Dagger module to spin up Ollama as a CI service for testing LLM-powered features in pipelines.",
    "source": "github",
    "date": "2024-04-13",
    "highlights": [
      "cue SDK",
      "cachable models",
      "test examples"
    ]
  },
  {
    "title": "ollama-mistral-ft",
    "url": "https://github.com/ollama/ollama/tree/main/examples/finetune",
    "summary": "Official example showing how to fine-tune Mistral-7b on custom JSONL and serve it with Ollama.",
    "source": "github",
    "date": "2024-04-12",
    "highlights": [
      "LoRA adapter",
      "Modelfile FROM adapter",
      "training script"
    ]
  },
  {
    "title": "reddit/r/ollama",
    "url": "https://www.reddit.com/r/ollama/",
    "summary": "Active subreddit for model announcements, troubleshooting, benchmarks and community Modelfiles.",
    "source": "reddit",
    "date": "2024-05-02",
    "highlights": [
      "weekly Q&A",
      "hardware advice",
      "model requests"
    ]
  }
]