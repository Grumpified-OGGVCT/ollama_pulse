[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama CLI and server that lets you pull, run, and manage large language models locally.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "CLI",
      "Docker image",
      "macOS/Linux/Windows",
      "GGUF support",
      "OpenAI-compatible API"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client for Ollama; chat, embed, generate, pull, list, and delete models with a few lines of code.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "pip install ollama",
      "async/sync APIs",
      "streaming",
      "embeddings",
      "type hints"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Node and browsers (with proxy) to interact with the Ollama server.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "npm i ollama",
      "TypeScript",
      "streaming",
      "Promise-based",
      "browser support"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://pypi.org/project/langchain-ollama/",
    "summary": "PyPI package adding Ollama chat, embeddings, and tool-calling as first-class LangChain components.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "pip install langchain-ollama",
      "tool calling",
      "streaming",
      "embeddings",
      "LLM & ChatModel"
    ]
  },
  {
    "title": "ollama-webui (open-webui)",
    "url": "https://github.com/open-webui/open-webui",
    "summary": "Self-hosted WebUI for Ollama with chat UI, RAG, document upload, user auth, and admin panel.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "Docker image",
      "RAG",
      "multi-user",
      "document QA",
      "themeable",
      "import/export chats"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java/Kotlin client for Ollama with fluent API, streaming, and embeddings support.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "Maven Central",
      "Kotlin DSL",
      "async streaming",
      "embeddings",
      "tool calling beta"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/nilsding/ollama-rb",
    "summary": "Lightweight Ruby gem to chat, generate, and manage models via the Ollama REST API.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "gem install ollama-rb",
      "Faraday backend",
      "streaming",
      "list/pull/delete models"
    ]
  },
  {
    "title": "ollama-cli (typer-rich)",
    "url": "https://github.com/sugarforever/ollama-cli",
    "summary": "Community CLI built with Typer & Rich adding conversation history, markdown, and REPL mode.",
    "source": "github",
    "date": "2024-05-04",
    "highlights": [
      "pip install ollama-cli",
      "conversation memory",
      "syntax highlighting",
      "REPL"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama/ollama-copilot",
    "summary": "Experimental GitHub Copilot-like VS-Code extension powered by Ollama models.",
    "source": "github",
    "date": "2024-05-03",
    "highlights": [
      "VSIX",
      "inline suggestions",
      "local model",
      "configurable model choice"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/ollama/ollama-haystack",
    "summary": "Haystack integration letting you use Ollama models as generators or embedders in Haystack pipelines.",
    "source": "github",
    "date": "2024-05-02",
    "highlights": [
      "pip install ollama-haystack",
      "generator",
      "embedder",
      "streaming",
      "Haystack 2.x ready"
    ]
  },
  {
    "title": "ollama-cookbook",
    "url": "https://github.com/ollama/ollama-cookbook",
    "summary": "Community recipes for running Ollama in Docker, Kubernetes, with GPU, CI/CD, and edge devices.",
    "source": "github",
    "date": "2024-05-01",
    "highlights": [
      "Docker Compose",
      "K8s Helm",
      "Jetson",
      "CI examples",
      "GPU enablement"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/llama-assistant/ollama-helm",
    "summary": "Helm chart to deploy Ollama server and WebUI on Kubernetes with GPU node selector.",
    "source": "github",
    "date": "2024-04-30",
    "highlights": [
      "Helm",
      "GPU support",
      "PVC for models",
      "ingress",
      "autoscaling"
    ]
  },
  {
    "title": "ollama-gpt4all-importer",
    "url": "https://github.com/ollama/ollama-gpt4all-importer",
    "summary": "Tool to convert and import GPT4All model binaries into Ollama\u2019s GGUF format.",
    "source": "github",
    "date": "2024-04-29",
    "highlights": [
      "GGUF conversion",
      "bulk import",
      "checksum verify",
      "macOS/Linux"
    ]
  },
  {
    "title": "ollama-docker-mod",
    "url": "https://github.com/linuxserver/docker-mods/tree/ollama",
    "summary": "LinuxServer.io Docker mod that adds Ollama binary to any of their containers.",
    "source": "github",
    "date": "2024-04-28",
    "highlights": [
      "Docker mod",
      "automatic updates",
      "LinuxServer base images",
      "s6 service"
    ]
  },
  {
    "title": "ollama-discord-bot",
    "url": "https://github.com/ollama/ollama-discord-bot",
    "summary": "Discord bot that chats and generates images using local Ollama models via slash commands.",
    "source": "github",
    "date": "2024-04-27",
    "highlights": [
      "slash commands",
      "conversation threads",
      "model switching",
      "self-hosted"
    ]
  },
  {
    "title": "ollama-slack-bot",
    "url": "https://github.com/ollama/ollama-slack-bot",
    "summary": "Slack Bolt app bringing Ollama completions and embeddings into Slack channels.",
    "source": "github",
    "date": "2024-04-26",
    "highlights": [
      "Bolt JS",
      "mention trigger",
      "threading",
      "modal config",
      "embeddings search"
    ]
  },
  {
    "title": "ollama-obsidian",
    "url": "https://github.com/ollama/ollama-obsidian",
    "summary": "Obsidian community plugin for AI-assisted writing using Ollama models offline.",
    "source": "github",
    "date": "2024-04-25",
    "highlights": [
      "Obsidian plugin",
      "offline",
      "custom prompts",
      "template variables",
      "streaming insert"
    ]
  },
  {
    "title": "ollama-nim",
    "url": "https://github.com/ollama/ollama-nim",
    "summary": "Nim client library for Ollama with synchronous and asynchronous APIs.",
    "source": "github",
    "date": "2024-04-24",
    "highlights": [
      "Nimble package",
      "asyncdispatch",
      "streams",
      "JSON marshalling"
    ]
  },
  {
    "title": "ollama-dart",
    "url": "https://github.com/ollama/ollama-dart",
    "summary": "Dart/Flutter package for chatting and embedding with Ollama servers.",
    "source": "github",
    "date": "2024-04-23",
    "highlights": [
      "pub.dev",
      "Dart",
      "Flutter",
      "streaming",
      "embeddings"
    ]
  },
  {
    "title": "ollama-rust",
    "url": "https://github.com/ollama/ollama-rust",
    "summary": "Rust crate providing typed, async bindings to the Ollama REST API.",
    "source": "github",
    "date": "2024-04-22",
    "highlights": [
      "crates.io",
      "tokio",
      "serde",
      "streaming",
      "full API coverage"
    ]
  }
]