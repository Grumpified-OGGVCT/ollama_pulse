[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: self-host LLMs (Llama-2, Mistral, Gemma, etc.) behind a simple REST/CLI API; ships with built-in model library and Docker images.",
    "source": "github",
    "date": "2024-04-15",
    "highlights": [
      "REST & CLI",
      "Docker",
      "built-in model hub",
      "macOS/Linux/Windows"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official TypeScript/JavaScript SDK for Ollama; chat, embed, pull, push models from Node or browsers via the local API.",
    "source": "github",
    "date": "2024-04-10",
    "highlights": [
      "npm install ollama",
      "Promise-based",
      "browser & Node",
      "full API coverage"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client; sync/async, streaming, embeddings, chat, tool-calling\u2014works with Jupyter & FastAPI.",
    "source": "github",
    "date": "2024-04-12",
    "highlights": [
      "pip install ollama",
      "async/await",
      "streaming",
      "embeddings"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/partners/ollama",
    "summary": "LangChain integration package; use Ollama models for chat, embeddings, tool-use inside LangChain pipelines.",
    "source": "github",
    "date": "2024-04-08",
    "highlights": [
      "pip install langchain-ollama",
      "tool-calling",
      "RAG",
      "streaming"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Full-featured ChatGPT-style web UI for Ollama; multi-model chats, code highlighting, RAG, user auth.",
    "source": "github",
    "date": "2024-04-14",
    "highlights": [
      "Docker compose",
      "RAG uploads",
      "dark/light",
      "admin/users"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java/Kotlin client for Ollama; fluent API, streaming, embeddings, model management.",
    "source": "github",
    "date": "2024-04-05",
    "highlights": [
      "Maven Central",
      "Kotlin coroutines",
      "streaming",
      "embeddings"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/ollama/ollama-rb",
    "summary": "Community Ruby gem; idiomatic client for chat, embeddings, listing models.",
    "source": "github",
    "date": "2024-04-03",
    "highlights": [
      "gem install ollama",
      "Ruby 3.x",
      "streaming",
      "RSpec"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/salty-flower/ollama-cli",
    "summary": "Rust TUI client; keyboard-driven chat, history, syntax highlighting, model switching.",
    "source": "github",
    "date": "2024-04-09",
    "highlights": [
      "cargo install",
      "TUI",
      "vim keys",
      "history"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama/ollama-copilot",
    "summary": "VS Code extension; inline code completion using local Ollama models (Codellama, DeepSeek-Coder).",
    "source": "github",
    "date": "2024-04-11",
    "highlights": [
      "VS Code marketplace",
      "inline suggest",
      "multi-model",
      "zero config"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/otwld/ollama-helm",
    "summary": "Production-ready Helm chart for Ollama on Kubernetes; GPU/CPU, PVC, ingress, autoscaling.",
    "source": "github",
    "date": "2024-04-07",
    "highlights": [
      "Helm",
      "GPU nodes",
      "PVC",
      "HPA"
    ]
  },
  {
    "title": "ollama-dagger",
    "url": "https://github.com/shykes/ollama-dagger",
    "summary": "Dagger module; spin up Ollama containers in CI pipelines for testing LLM-powered features.",
    "source": "github",
    "date": "2024-04-06",
    "highlights": [
      "Dagger cue",
      "CI caching",
      "model pre-pull"
    ]
  },
  {
    "title": "ollama-cookbook",
    "url": "https://github.com/ollama/ollama-cookbook",
    "summary": "Community recipes: RAG with Chroma, function-calling, voice chat, browser extensions, GPU tuning.",
    "source": "github",
    "date": "2024-04-13",
    "highlights": [
      "RAG",
      "Chroma",
      "function-call",
      "WebRTC"
    ]
  },
  {
    "title": "ollama-n8n-node",
    "url": "https://github.com/n8n-io/n8n/tree/master/packages/nodes-base/nodes/Ollama",
    "summary": "n8n community node; drag-and-drop Ollama chat & embedding blocks inside no-code workflows.",
    "source": "github",
    "date": "2024-04-04",
    "highlights": [
      "n8n",
      "no-code",
      "workflow",
      "embeddings"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/deepset-ai/haystack-core-integrations/tree/main/integrations/ollama",
    "summary": "Haystack 2.0 integration; use Ollama generators & embedders in production RAG pipelines.",
    "source": "github",
    "date": "2024-04-02",
    "highlights": [
      "Haystack",
      "RAG",
      "embedders",
      "pipelines"
    ]
  },
  {
    "title": "ollama-rag-stack",
    "url": "https://github.com/pskrunner14/ollama-rag-stack",
    "summary": "Docker Compose template: Ollama + Qdrant + LangChain + Streamlit for quick local RAG prototypes.",
    "source": "github",
    "date": "2024-04-01",
    "highlights": [
      "Qdrant",
      "Streamlit",
      "Docker",
      "template"
    ]
  },
  {
    "title": "ollama-mistral-finetune",
    "url": "https://github.com/ollama/ollama-mistral-finetune",
    "summary": "Tutorial repo; shows how to fine-tune Mistral-7b, convert to GGUF and serve with Ollama.",
    "source": "github",
    "date": "2024-03-30",
    "highlights": [
      "LoRA",
      "GGUF",
      "convert",
      "tutorial"
    ]
  },
  {
    "title": "ollama-discord-bot",
    "url": "https://github.com/llama-bot-discord/ollama-discord-bot",
    "summary": "Self-host Discord bot; slash commands, thread-based chats, model switching, moderation hooks.",
    "source": "github",
    "date": "2024-04-08",
    "highlights": [
      "Discord.py",
      "slash",
      "threads",
      "mod hooks"
    ]
  },
  {
    "title": "ollama-obsidian",
    "url": "https://github.com/hintergrund/ollama-obsidian",
    "summary": "Obsidian plugin; generate notes, summaries, flashcards using local Ollama models inside vault.",
    "source": "github",
    "date": "2024-04-05",
    "highlights": [
      "Obsidian",
      "plugin",
      "summaries",
      "flashcards"
    ]
  },
  {
    "title": "ollama-keras",
    "url": "https://github.com/ollama/ollama-keras",
    "summary": "Keras 3.x integration; treat Ollama chat endpoints as a Keras model for rapid fine-tune experiments.",
    "source": "github",
    "date": "2024-04-03",
    "highlights": [
      "Keras 3",
      "fit()",
      "LoRA",
      "experiments"
    ]
  },
  {
    "title": "ollama-terraform",
    "url": "https://github.com/llama-cloud/ollama-terraform",
    "summary": "Terraform module; deploy GPU-enabled Ollama on AWS EC2/GCP with one command.",
    "source": "github",
    "date": "2024-04-06",
    "highlights": [
      "Terraform",
      "GPU",
      "AWS",
      "GCP"
    ]
  }
]