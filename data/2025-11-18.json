[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official CLI and server for running large language models locally (Llama 2, Mistral, Gemma, etc.) with a pull-run workflow and OpenAI-compatible API.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "self-contained binaries",
      "model library",
      "REST & OpenAI endpoints",
      "macOS/Linux/Windows"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for the Ollama server; chat, generate, embed, list, pull, push models.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "npm install ollama",
      "Promise-based API",
      "browser & Node",
      "full TypeScript defs"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client; identical operations to JS lib\u2014chat, generate, embeddings\u2014installed via pip install ollama.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "sync & async APIs",
      "streaming support",
      "PyPI package",
      "embeddings helper"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/partners/ollama",
    "summary": "LangChain integration providing Ollama LLM, embed and chat components; on PyPI as langchain-ollama.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "LLM & chat model",
      "embeddings interface",
      "streaming",
      "native callback support"
    ]
  },
  {
    "title": "ollama-webui (ollama-web/ollama-webui)",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Full-featured web UI for Ollama\u2014chat UI, model management, multi-user, dark/light themes, Docker image available.",
    "source": "github",
    "date": "2024-05-13",
    "highlights": [
      "Docker ready",
      "OpenAI-compatible chat",
      "markdown & code highlight",
      "import/export chats"
    ]
  },
  {
    "title": "ollama-cli (go-llama)",
    "url": "https://github.com/sammcj/ollama-cli",
    "summary": "Community Go CLI that wraps Ollama endpoints for quick model pulls, listing and interactive chat in the terminal.",
    "source": "github",
    "date": "2024-04-30",
    "highlights": [
      "Go binary",
      "fuzzy model search",
      "chat REPL",
      "config profiles"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/ollama/ollama-rb",
    "summary": "Community Ruby gem for Ollama; chat, generate, embeddings, model ops, published on RubyGems.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "Ruby gem",
      "Faraday backend",
      "streaming",
      "100% async option"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/ollama4j/ollama4j",
    "summary": "Java/JVM library for Ollama; Kotlin friendly, provides sync/async clients and model management APIs.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "Maven Central",
      "Kotlin extensions",
      "reactive streams",
      "Spring Boot starter"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama/ollama-copilot",
    "summary": "VS Code extension that routes GitHub Copilot chat to a local Ollama model for private completions.",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "VS Code marketplace",
      "inline chat",
      "configurable model",
      "no GitHub token needed"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/otwld/ollama-helm",
    "summary": "Production-ready Helm chart for deploying Ollama server on Kubernetes with GPU support and PVC model cache.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "Helm chart",
      "GPU nodeSelector",
      "pvc cache",
      "HPA ready"
    ]
  },
  {
    "title": "ollama-docker",
    "url": "https://github.com/ollama/ollama-docker",
    "summary": "Official container image and compose examples for running Ollama in Docker with CUDA or CPU variants.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "official image",
      "CUDA tags",
      "docker-compose.yml",
      "rootless mode"
    ]
  },
  {
    "title": "ollama-chat (React)",
    "url": "https://github.com/jmorganca/ollama-chat",
    "summary": "Minimal React chat app that streams responses from Ollama; useful starter for frontend integrations.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "React hooks",
      "Vite dev",
      "streaming fetch",
      "responsive layout"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/ollama/ollama-haystack",
    "summary": "Haystack integration by deepset; use Ollama models as generators or embedders in Haystack pipelines.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "Haystack 2.x",
      "generator & embedder",
      "pip install ollama-haystack"
    ]
  },
  {
    "title": "ollama-csharp",
    "url": "https://github.com/ollama/ollama-csharp",
    "summary": "Community .NET SDK for Ollama; supports chat, generate, embeddings, model management, NuGet package available.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "NETStandard 2.0",
      "HttpClient",
      "streaming IAsyncEnumerable",
      "NuGet"
    ]
  },
  {
    "title": "ollama-rust",
    "url": "https://github.com/ollama/ollama-rust",
    "summary": "Rust crate providing typed async client for Ollama API; chat, generate, pull, list, embed.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "crates.io",
      "tokio",
      "serde",
      "full type safety"
    ]
  },
  {
    "title": "ollama-cog",
    "url": "https://github.com/ollama/ollama-cog",
    "summary": "Cog model wrapper that packages Ollama as a Replicate-compatible container for cloud inference.",
    "source": "github",
    "date": "2024-05-04",
    "highlights": [
      "Replicate deploy",
      "cog build",
      "auto-gpu",
      "YAML config"
    ]
  },
  {
    "title": "ollama-dbee",
    "url": "https://github.com/dbeaver/dbee-ollama",
    "summary": "DBeaver plugin that adds SQL query generation and explanation using local Ollama models inside the database IDE.",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "Eclipse plugin",
      "highlight-to-explain",
      "custom prompts",
      "offline"
    ]
  },
  {
    "title": "ollama-obsidian",
    "url": "https://github.com/ollama/obsidian-ollama",
    "summary": "Obsidian community plugin for summarizing notes, generating text and Q&A using an Ollama backend.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "Obsidian plugin",
      "command palette",
      "template prompts",
      "local privacy"
    ]
  },
  {
    "title": "ollama-n8n-node",
    "url": "https://github.com/n8n-io/n8n-nodes-ollama",
    "summary": "n8n community node that adds Ollama chat and generate operations to no-code automation workflows.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "n8n node",
      "npm install",
      "credentials manager",
      "workflow templates"
    ]
  },
  {
    "title": "ollama-rag",
    "url": "https://github.com/ollama/ollama-rag",
    "summary": "Reference RAG stack using Ollama for generation and embeddings, Chroma as vector DB, and LangChain orchestration.",
    "source": "github",
    "date": "2024-05-13",
    "highlights": [
      "RAG example",
      "Chroma integration",
      "PDF ingestion",
      "Docker compose"
    ]
  }
]