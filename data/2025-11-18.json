[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repository providing the CLI and server to run Llama 2, Mistral, Gemma, and other large language models locally with a simple API.",
    "source": "github",
    "date": "2023-10-01",
    "highlights": [
      "self-contained binaries",
      "macOS/Linux/Windows",
      "Docker image",
      "OpenAI-compatible API"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Ollama, published on npm as 'ollama'.",
    "source": "github",
    "date": "2023-09-15",
    "highlights": [
      "Promise-based",
      "TypeScript definitions",
      "chat & generate endpoints",
      "embedding support"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client for Ollama, available on PyPI as 'ollama'.",
    "source": "github",
    "date": "2023-09-20",
    "highlights": [
      "sync & async APIs",
      "streaming responses",
      "chat & generate",
      "embedding support"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://pypi.org/project/langchain-ollama/",
    "summary": "PyPI package integrating Ollama models into LangChain LLM and embeddings interfaces.",
    "source": "github",
    "date": "2023-11-01",
    "highlights": [
      "LangChain LLM wrapper",
      "embeddings wrapper",
      "streaming",
      "callback support"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich web UI for Ollama (renamed to Open WebUI), installable via Docker or pip.",
    "source": "github",
    "date": "2023-10-10",
    "highlights": [
      "ChatGPT-like interface",
      "model management",
      "RAG uploads",
      "multi-user",
      "Docker"
    ]
  },
  {
    "title": "continue",
    "url": "https://github.com/continuedev/continue",
    "summary": "VS Code & JetBrains extension that connects to Ollama for local code-completion and chat.",
    "source": "github",
    "date": "2023-11-05",
    "highlights": [
      "IDE plugin",
      "inline autocomplete",
      "highlight & ask",
      "configurable models"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java/Kotlin client library for Ollama, published to Maven Central.",
    "source": "github",
    "date": "2023-10-12",
    "highlights": [
      "Java SDK",
      "Kotlin extensions",
      "async support",
      "streaming chat"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/nileshtrivedi/ollama-rb",
    "summary": "Ruby gem providing a simple client for the Ollama API.",
    "source": "github",
    "date": "2023-10-25",
    "highlights": [
      "Ruby gem",
      "Faraday HTTP",
      "chat & generate",
      "streaming"
    ]
  },
  {
    "title": "helm-ollama",
    "url": "https://github.com/ollama/helm",
    "summary": "Official Helm chart to deploy Ollama on Kubernetes clusters.",
    "source": "github",
    "date": "2023-11-02",
    "highlights": [
      "Kubernetes",
      "Helm chart",
      "GPU support",
      "persistent volumes"
    ]
  },
  {
    "title": "ollama-cli-chat",
    "url": "https://github.com/sugarforever/ollama-cli-chat",
    "summary": "Interactive CLI chat wrapper around Ollama with conversation history and markdown rendering.",
    "source": "github",
    "date": "2023-10-18",
    "highlights": [
      "interactive REPL",
      "history",
      "markdown",
      "colorized output"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama/ollama-copilot",
    "summary": "Experimental GitHub Copilot-style VS Code extension backed by Ollama models.",
    "source": "github",
    "date": "2023-11-07",
    "highlights": [
      "inline suggestions",
      "local model",
      "VS Code",
      "Copilot clone"
    ]
  },
  {
    "title": "ollama-discord",
    "url": "https://github.com/mxyng/ollama-discord",
    "summary": "Discord bot that streams Ollama model responses into Discord channels.",
    "source": "github",
    "date": "2023-10-05",
    "highlights": [
      "Discord bot",
      "streaming replies",
      "slash commands",
      "multi-model"
    ]
  },
  {
    "title": "ollama-streamlit",
    "url": "https://github.com/richawo/ollama-streamlit",
    "summary": "Streamlit chat interface that connects to a local Ollama instance.",
    "source": "github",
    "date": "2023-10-22",
    "highlights": [
      "Streamlit UI",
      "session memory",
      "model selector",
      "Docker"
    ]
  },
  {
    "title": "ollama-nix",
    "url": "https://github.com/NixOS/nixpkgs/tree/master/pkgs/tools/misc/ollama",
    "summary": "Nix derivation for installing Ollama on NixOS or via Home Manager.",
    "source": "github",
    "date": "2023-11-10",
    "highlights": [
      "Nix package",
      "declarative config",
      "systemd service",
      "GPU flags"
    ]
  },
  {
    "title": "ollama-dagger",
    "url": "https://github.com/sagikazarmark/daggerverse/tree/main/ollama",
    "summary": "Dagger module that spins up Ollama as a service for CI pipelines.",
    "source": "github",
    "date": "2023-11-12",
    "highlights": [
      "Dagger module",
      "CI service",
      "caching",
      "GPU optional"
    ]
  },
  {
    "title": "ollama-curl",
    "url": "https://github.com/technomancy/ollama-curl",
    "summary": "Tiny Bash library wrapping curl to call the Ollama REST API interactively.",
    "source": "github",
    "date": "2023-10-30",
    "highlights": [
      "Bash functions",
      "curl only",
      "no deps",
      "streaming"
    ]
  },
  {
    "title": "ollama-logseq",
    "url": "https://github.com/omagdy/ollama-logseq",
    "summary": "Logseq plugin that sends selected blocks to Ollama for summarization or Q&A.",
    "source": "github",
    "date": "2023-11-03",
    "highlights": [
      "Logseq plugin",
      "block queries",
      "summarize",
      "local model"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/ollama/ollama-haystack",
    "summary": "Haystack integration letting Ollama models act as generators or embedders in Haystack pipelines.",
    "source": "github",
    "date": "2023-11-08",
    "highlights": [
      "Haystack nodes",
      "RAG pipelines",
      "embeddings",
      "generator"
    ]
  },
  {
    "title": "ollama-camunda",
    "url": "https://github.com/rob2universe/ollama-camunda",
    "summary": "Camunda 8 connector that invokes Ollama models from BPMN service tasks.",
    "source": "github",
    "date": "2023-11-14",
    "highlights": [
      "Camunda connector",
      "BPMN",
      "service task",
      "JSON mapping"
    ]
  },
  {
    "title": "ollama-rust",
    "url": "https://github.com/pepperoni21/ollama-rs",
    "summary": "Rust crate providing async and sync clients for the Ollama API.",
    "source": "github",
    "date": "2023-11-15",
    "highlights": [
      "Rust crate",
      "tokio support",
      "serde",
      "streaming chat"
    ]
  }
]