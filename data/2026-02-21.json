[
  {
    "title": "Ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repository - get up and running with Llama 2, Mistral, Gemma, and other large language models locally.",
    "source": "github",
    "date": "2024-04-20",
    "highlights": [
      "local LLM inference",
      "REST API",
      "model library",
      "macOS/Linux/Windows"
    ]
  },
  {
    "title": "Ollama Web UI",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "User-friendly WebUI for Ollama with model management, chat interface, and multi-user support.",
    "source": "github",
    "date": "2024-04-19",
    "highlights": [
      "chat interface",
      "model management",
      "multi-user",
      "Docker support"
    ]
  },
  {
    "title": "LangChain Ollama Integration",
    "url": "https://python.langchain.com/docs/integrations/llms/ollama",
    "summary": "Official LangChain integration for Ollama allowing easy use of local models in LangChain applications.",
    "source": "blog",
    "date": "2024-04-15",
    "highlights": [
      "LangChain integration",
      "Python SDK",
      "chain orchestration",
      "RAG support"
    ]
  },
  {
    "title": "LlamaIndex Ollama Integration",
    "url": "https://docs.llamaindex.ai/en/stable/examples/llm/ollama/",
    "summary": "Use Ollama models with LlamaIndex for building RAG and agent applications with local LLMs.",
    "source": "blog",
    "date": "2024-04-18",
    "highlights": [
      "RAG applications",
      "document indexing",
      "agent frameworks",
      "local processing"
    ]
  },
  {
    "title": "Ollama Python Library",
    "url": "https://pypi.org/project/ollama/",
    "summary": "Official Python library for interacting with Ollama's API to run and manage local language models.",
    "source": "github",
    "date": "2024-04-20",
    "highlights": [
      "Python SDK",
      "async support",
      "model management",
      "chat completions"
    ]
  },
  {
    "title": "Ollama JS/TS Library",
    "url": "https://www.npmjs.com/package/ollama",
    "summary": "Official JavaScript/TypeScript library for Ollama with full API support for Node.js and browsers.",
    "source": "github",
    "date": "2024-04-19",
    "highlights": [
      "TypeScript support",
      "Node.js",
      "browser support",
      "promise-based API"
    ]
  },
  {
    "title": "Ollama Commander",
    "url": "https://github.com/ggozad/ollama-commander",
    "summary": "Command-line interface for Ollama with advanced features like conversation history and model switching.",
    "source": "github",
    "date": "2024-04-10",
    "highlights": [
      "CLI tool",
      "conversation history",
      "model switching",
      "terminal UI"
    ]
  },
  {
    "title": "Ollama Desktop",
    "url": "https://github.com/nomic-ai/gpt4all",
    "summary": "Desktop application that supports Ollama models alongside other local LLM backends.",
    "source": "github",
    "date": "2024-04-15",
    "highlights": [
      "desktop GUI",
      "cross-platform",
      "multiple backends",
      "model browser"
    ]
  },
  {
    "title": "Ollama Discord Bot",
    "url": "https://github.com/ollama-bot/discord-ollama-bot",
    "summary": "Discord bot integration for Ollama allowing server members to chat with local LLMs.",
    "source": "github",
    "date": "2024-04-12",
    "highlights": [
      "Discord integration",
      "multi-server support",
      "role-based access",
      "slash commands"
    ]
  },
  {
    "title": "Ollama with Haystack",
    "url": "https://haystack.deepset.ai/integrations/ollama-generator",
    "summary": "Haystack integration for Ollama enabling use of local models in Haystack pipelines.",
    "source": "blog",
    "date": "2024-04-16",
    "highlights": [
      "Haystack integration",
      "pipeline support",
      "generator backend",
      "document search"
    ]
  },
  {
    "title": "Ollama API Wrapper",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python wrapper for Ollama API with comprehensive model management capabilities.",
    "source": "github",
    "date": "2024-04-20",
    "highlights": [
      "official wrapper",
      "model operations",
      "streaming support",
      "async/await"
    ]
  },
  {
    "title": "Ollama Chat UI",
    "url": "https://github.com/ivanfioravanti/chatbot-ollama",
    "summary": "Simple and clean chat interface for Ollama built with Next.js and TypeScript.",
    "source": "github",
    "date": "2024-04-14",
    "highlights": [
      "Next.js",
      "TypeScript",
      "responsive design",
      "markdown support"
    ]
  },
  {
    "title": "Ollama Model Registry",
    "url": "https://github.com/ollama/ollama/tree/main/models",
    "summary": "Official model library with instructions for pulling and running various open-source LLMs.",
    "source": "github",
    "date": "2024-04-19",
    "highlights": [
      "model library",
      "Llama 2",
      "Mistral",
      "Code Llama",
      "Gemma"
    ]
  },
  {
    "title": "Ollama with Flowise",
    "url": "https://github.com/FlowiseAI/Flowise",
    "summary": "Drag-and-drop UI builder that supports Ollama for creating LLM workflows without coding.",
    "source": "github",
    "date": "2024-04-17",
    "highlights": [
      "visual builder",
      "no-code",
      "workflow automation",
      "Ollama node"
    ]
  },
  {
    "title": "Ollama Swift SDK",
    "url": "https://github.com/kevinhermawan/OllamaSwift",
    "summary": "Swift package for integrating Ollama into iOS and macOS applications.",
    "source": "github",
    "date": "2024-04-11",
    "highlights": [
      "Swift package",
      "iOS support",
      "macOS support",
      "native integration"
    ]
  },
  {
    "title": "Ollama Docker Compose",
    "url": "https://github.com/ollama/ollama/tree/main/docker",
    "summary": "Official Docker setup for running Ollama in containerized environments with GPU support.",
    "source": "github",
    "date": "2024-04-18",
    "highlights": [
      "Docker support",
      "GPU acceleration",
      "containerization",
      "docker-compose"
    ]
  },
  {
    "title": "Ollama Reddit Community",
    "url": "https://www.reddit.com/r/ollama/",
    "summary": "Active Reddit community discussing Ollama usage, models, troubleshooting, and integrations.",
    "source": "reddit",
    "date": "2024-04-20",
    "highlights": [
      "community support",
      "troubleshooting",
      "model discussions",
      "feature requests"
    ]
  },
  {
    "title": "Ollama Go Client",
    "url": "https://github.com/ollama/ollama-go",
    "summary": "Official Go client library for Ollama with full API coverage and streaming support.",
    "source": "github",
    "date": "2024-04-19",
    "highlights": [
      "Go SDK",
      "official client",
      "streaming",
      "concurrent safe"
    ]
  }
]