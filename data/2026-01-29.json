[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama CLI and server to run Llama 2, Code Llama, and other large language models locally with GPU/CPU acceleration.",
    "source": "github",
    "date": "2023-10-15",
    "highlights": [
      "self-contained binaries",
      "Docker image",
      "macOS/Linux/Windows",
      "REST API",
      "model library"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for the Ollama server; chat, generate, embed, pull, and manage models from Node or browsers.",
    "source": "github",
    "date": "2023-11-02",
    "highlights": [
      "npm package",
      "Promise-based",
      "TypeScript definitions",
      "browser & Node",
      "full API coverage"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client library exposing chat, generate, embeddings, and model management via simple synchronous & async APIs.",
    "source": "github",
    "date": "2023-11-05",
    "highlights": [
      "PyPI package",
      "async/await",
      "streaming responses",
      "built-in embeddings",
      "100% open-source"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/community/langchain_community/llms/ollama",
    "summary": "LangChain integration allowing Ollama models to be used as LLM, chat, or embedding endpoints in LangChain pipelines.",
    "source": "github",
    "date": "2023-11-10",
    "highlights": [
      "pip install langchain-community",
      "streaming support",
      "chat & embeddings",
      "callback handlers"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich web UI for Ollama (ChatGPT-style) with model switching, chat history, multi-user support, and markdown rendering.",
    "source": "github",
    "date": "2023-11-12",
    "highlights": [
      "Docker ready",
      "Dark/light theme",
      "code highlighting",
      "import/export chats",
      "modelfile editor"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/technomancy/ollama-cli",
    "summary": "Rust-based interactive CLI for chatting with Ollama models, featuring syntax highlighting and readline support.",
    "source": "github",
    "date": "2023-11-01",
    "highlights": [
      "Rust binary",
      "cross-platform",
      "line editing",
      "syntax highlighting",
      "lightweight"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/fostermaier/ollama-copilot",
    "summary": "VS Code extension that brings local Ollama models into GitHub Copilot-style inline suggestions and chat pane.",
    "source": "github",
    "date": "2023-11-08",
    "highlights": [
      "VS Code marketplace",
      "inline completions",
      "chat sidebar",
      "configurable model",
      "no cloud required"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java/Kotlin client for Ollama with fluent builders, streaming, and Android compatibility published to Maven Central.",
    "source": "github",
    "date": "2023-11-06",
    "highlights": [
      "Maven Central",
      "Java 8+",
      "Android support",
      "streaming",
      "fluent API"
    ]
  },
  {
    "title": "ollama-workflows",
    "url": "https://github.com/sammcj/ollama-workflows",
    "summary": "Collection of GitHub Actions workflows to automate pulling, testing, and benchmarking Ollama models in CI.",
    "source": "github",
    "date": "2023-11-09",
    "highlights": [
      "GitHub Actions",
      "automated benchmarks",
      "model caching",
      "PR comments",
      "matrix builds"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/otwld/ollama-helm",
    "summary": "Production-ready Helm chart for deploying Ollama server on Kubernetes with GPU node selection and autoscaling.",
    "source": "github",
    "date": "2023-11-11",
    "highlights": [
      "Helm chart",
      "GPU support",
      "ingress",
      "persistence",
      "autoscaling"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/ollama/ollama-rb",
    "summary": "Official Ruby gem wrapping Ollama REST API for chat, generate, embeddings, and model management.",
    "source": "github",
    "date": "2023-11-04",
    "highlights": [
      "Ruby gem",
      "streaming support",
      "100% documented",
      "Rails ready",
      "official"
    ]
  },
  {
    "title": "ollama-chatbot-ui",
    "url": "https://github.com/ivanfioravivi/ollama-chatbot-ui",
    "summary": "Minimal React chatbot UI that connects to local Ollama server via REST API, packaged as a static Docker image.",
    "source": "github",
    "date": "2023-11-07",
    "highlights": [
      "React SPA",
      "Docker image",
      "responsive",
      "markdown",
      "easy theming"
    ]
  },
  {
    "title": "ollama-discord",
    "url": "https://github.com/sbplat/ollama-discord",
    "summary": "Self-hosted Discord bot that lets servers chat with Ollama models using slash commands and thread support.",
    "source": "github",
    "date": "2023-11-03",
    "highlights": [
      "Discord.py",
      "slash commands",
      "threaded chats",
      "multi-model",
      "easy config"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/deepset-ai/haystack-core-integrations/tree/main/integrations/ollama",
    "summary": "Haystack 2.0 integration providing OllamaGenerator and OllamaChatGenerator nodes for RAG pipelines.",
    "source": "github",
    "date": "2023-11-13",
    "highlights": [
      "pip install haystack-ai[ollama]",
      "RAG ready",
      "streaming",
      "generator & chat"
    ]
  },
  {
    "title": "ollama-csharp",
    "url": "https://github.com/ollama/ollama-csharp",
    "summary": "Official C# / .NET client library for Ollama with async streaming, published as NuGet package.",
    "source": "github",
    "date": "2023-11-14",
    "highlights": [
      "NuGet package",
      ".NET 6+",
      "async enumerable",
      "official",
      "well documented"
    ]
  },
  {
    "title": "ollama-models-zoo",
    "url": "https://github.com/jmorganca/ollama-models-zoo",
    "summary": "Community-curated list of custom Modelfiles and quantized GGUFs ready to import into Ollama.",
    "source": "github",
    "date": "2023-11-15",
    "highlights": [
      "Modelfile recipes",
      "quantization tips",
      "community PRs",
      "GGUF links"
    ]
  },
  {
    "title": "ollama-obsidian",
    "url": "https://github.com/hintergrund/ollama-obsidian",
    "summary": "Obsidian plugin that adds a local AI assistant sidebar powered by Ollama for note-taking help and summarization.",
    "source": "github",
    "date": "2023-11-16",
    "highlights": [
      "Obsidian plugin",
      "local AI",
      "summarization",
      "custom prompts",
      "community"
    ]
  },
  {
    "title": "ollama-slack",
    "url": "https://github.com/raycad/ollama-slack",
    "summary": "Slack bot integration that answers questions using Ollama models via socket-mode events and slash commands.",
    "source": "github",
    "date": "2023-11-17",
    "highlights": [
      "Bolt framework",
      "socket mode",
      "slash commands",
      "thread replies",
      "easy deploy"
    ]
  },
  {
    "title": "ollama-llamaindex",
    "url": "https://github.com/run-llama/llama_index/blob/main/llama-index-integrations/llms/llama-index-llms-ollama",
    "summary": "LlamaIndex integration enabling Ollama models as LLM and embedding backends for building local RAG applications.",
    "source": "github",
    "date": "2023-11-18",
    "highlights": [
      "pip install llama-index-llms-ollama",
      "embeddings support",
      "RAG examples",
      "streaming"
    ]
  },
  {
    "title": "ollama-fastapi",
    "url": "https://github.com/1rgs/ollama-fastapi",
    "summary": "Lightweight FastAPI service that proxies and extends Ollama endpoints with JWT auth and request logging.",
    "source": "github",
    "date": "2023-11-19",
    "highlights": [
      "FastAPI",
      "JWT auth",
      "request logs",
      "rate limiting",
      "Docker ready"
    ]
  }
]