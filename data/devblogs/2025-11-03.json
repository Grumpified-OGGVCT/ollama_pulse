[
  {
    "title": "Semantic search with embeddings in PHP: a hands-on guide using Neuron AI and Ollama",
    "date": "Sat, 01 Nov 2025 21:55:17 +0000",
    "summary": "<p>Imagine you run an e-commerce or content website. A user searches for ‚Äúholiday gifts‚Äù, but your product catalog includes titles like ‚ÄúChristmas stocking‚Äù, ‚ÄúDecember sale‚Äù, or ‚Äúwinter celebration bundle‚Äù.</p>\n\n<p>A traditional keyword search will struggle to find these items if the exact words don",
    "url": "https://dev.to/robertobutti/semantic-search-with-embeddings-in-php-a-hands-on-guide-using-neuron-ai-and-ollama-16c",
    "source": "devto",
    "turbo_score": 0.7,
    "highlights": [
      "tutorial",
      "dev.to"
    ]
  },
  {
    "title": "ü™® IBM Granite 4.0-Nano",
    "date": "Wed, 29 Oct 2025 12:02:35 +0000",
    "summary": "<p>You can use it on your everyday‚Äôs laptop ü§©</p>\n\n<p><a class=\"article-body-image-wrapper\" href=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fk1rnaczvk4pxixsagfa3.png\"><img ",
    "url": "https://dev.to/aairom/ibm-granite-40-nano-1dom",
    "source": "devto",
    "turbo_score": 0.7,
    "highlights": [
      "tutorial",
      "dev.to"
    ]
  },
  {
    "title": "Using Chonkie",
    "date": "Fri, 24 Oct 2025 09:40:22 +0000",
    "summary": "<p>Testing Chonkie üß™</p>\n\n<p><a class=\"article-body-image-wrapper\" href=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fvq6ccq8ftaviqeoj0b3e.png\"><img alt=\" \" height=\"426\" src=",
    "url": "https://dev.to/aairom/using-chonkie-4glg",
    "source": "devto",
    "turbo_score": 0.7,
    "highlights": [
      "tutorial",
      "dev.to"
    ]
  },
  {
    "title": "A Beginner's Guide to Ollama Cloud Models",
    "date": "Sun, 19 Oct 2025 22:35:08 +0000",
    "summary": "<p>Ollama's cloud models are a new feature that allows users to run large language models without needing a powerful local GPU. These models are automatically offloaded to Ollama's cloud service, providing the same capabilities as local models while enabling the use of larger models that would typic",
    "url": "https://dev.to/coderforfun/a-beginners-guide-to-ollama-cloud-models-3lc2",
    "source": "devto",
    "turbo_score": 0.7,
    "highlights": [
      "tutorial",
      "dev.to"
    ]
  },
  {
    "title": "Building 100% local AI memory with cognee",
    "date": "Sat, 18 Oct 2025 09:21:55 +0000",
    "summary": "<p>If you've explored AI memory frameworks, you've probably encountered Cognee </p>\n<div class=\"ltag-github-readme-tag\">\n  <div class=\"readme-overview\">\n    <h2>\n      <img alt=\"GitHub logo\" src=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/ht",
    "url": "https://dev.to/chinmay_bhosale_9ceed796b/cognee-with-ollama-3pp8",
    "source": "devto",
    "turbo_score": 0.7,
    "highlights": [
      "tutorial",
      "dev.to"
    ]
  },
  {
    "title": "PyLlamaUI Update",
    "date": "Sat, 18 Oct 2025 07:48:30 +0000",
    "summary": "<h2>\n  \n  \n  Markdown Output\n</h2>\n\n<h2>\n  \n  \n  Offline Agentic Mode Coming Soon\n</h2>\n\n<p>I'm thrilled to share that <strong>PyLlamaUI now supports structured Markdown output ‚Äî fully offline</strong>.<br /><br />\nThis lets you view beautifully formatted text, code blocks, tables, and responses dir",
    "url": "https://dev.to/bhuvaneshm_dev/pyllamaui-update-1fmh",
    "source": "devto",
    "turbo_score": 0.7,
    "highlights": [
      "tutorial",
      "dev.to"
    ]
  },
  {
    "title": "Testing qwen3-vl‚Ä¶ quite impressive!",
    "date": "Fri, 17 Oct 2025 09:56:00 +0000",
    "summary": "<p>Rapid test using qwen3 vision language</p>\n\n<p><a class=\"article-body-image-wrapper\" href=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2F8kwmbntbs6spnj4rvz4e.png\"><img alt=",
    "url": "https://dev.to/aairom/testing-qwen3-vl-quite-impressive-3e3o",
    "source": "devto",
    "turbo_score": 0.7,
    "highlights": [
      "tutorial",
      "dev.to"
    ]
  },
  {
    "title": "Building a Multi-Agent Crypto Trading Bot with Local LLMs, Recall, and Agno",
    "date": "Tue, 14 Oct 2025 06:33:00 +0000",
    "summary": "<p>In this post, I'll walk you through how I built a fully autonomous, multi-agent crypto trading team. This system uses a local LLM (via <strong>Ollama</strong>) for its reasoning, fetches real-time news from the web, and executes sandboxed trades on the <strong>Recall Network</strong>, a decentral",
    "url": "https://dev.to/harishkotra/building-a-multi-agent-crypto-trading-bot-with-local-llms-recall-and-agno-46mg",
    "source": "devto",
    "turbo_score": 0.7,
    "highlights": [
      "tutorial",
      "dev.to"
    ]
  },
  {
    "title": "Ollama SDKs in Go: Overview and Code Examples",
    "date": "Sun, 12 Oct 2025 00:37:13 +0000",
    "summary": "<p>Here is a little guide to <a href=\"https://www.glukhov.org/post/2025/10/using-ollama-in-go/\" rel=\"noopener noreferrer\">Ollama SDKs in Go</a>: Packages, Usage, and Comparison.</p>\n\n<p>Integrating Ollama models into Go applications is streamlined by several SDK options, each suited to different dev",
    "url": "https://dev.to/rosgluk/ollama-sdks-in-go-overview-and-code-examples-42n3",
    "source": "devto",
    "turbo_score": 0.7,
    "highlights": [
      "tutorial",
      "dev.to"
    ]
  },
  {
    "title": "Local LLMs: Running Ollama and Open‚ÄØWebUI in Docker on Ubuntu",
    "date": "Wed, 08 Oct 2025 13:00:00 +0000",
    "summary": "<p><a href=\"https://docs.ollama.com/\" rel=\"noopener noreferrer\">Ollama</a> is a popular tool for running large language models (LLMs) locally on your machine. It provides a simple interface to interact with various models without needing an internet connection. <a href=\"https://docs.openwebui.com\" r",
    "url": "https://dev.to/pauldotyu/running-ollama-locally-with-open-webui-ol1",
    "source": "devto",
    "turbo_score": 0.7,
    "highlights": [
      "tutorial",
      "dev.to"
    ]
  },
  {
    "title": "Mixture of Experts Implementation using Granite4: Harnessing Specialization with the Latest Granite Family Model",
    "date": "Sun, 05 Oct 2025 12:39:12 +0000",
    "summary": "<p>A sample implementation of Mixture of Experts (MOE) using the latest Granite family LLM!</p>\n\n<p><a class=\"article-body-image-wrapper\" href=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fupload",
    "url": "https://dev.to/aairom/mixture-of-experts-implementation-using-granite4-harnessing-specialization-with-the-latest-granite-5c",
    "source": "devto",
    "turbo_score": 0.7,
    "highlights": [
      "tutorial",
      "dev.to"
    ]
  },
  {
    "title": "Building Your First AI Agent in PHP with Symfony‚Äôs New AI Component and Ollama",
    "date": "Sat, 04 Oct 2025 15:38:43 +0000",
    "summary": "<blockquote>\n<p>Learn how to build an AI agent in PHP using Symfony‚Äôs new AI Component and Ollama. This hands-on guide walks you through the installation, configuration, and running of a simple real-world example that rewrites and improves Markdown content locally with Gemma 3. Perfect for developer",
    "url": "https://dev.to/robertobutti/building-your-first-ai-agent-in-php-with-symfonys-new-ai-component-and-ollama-399a",
    "source": "devto",
    "turbo_score": 0.7,
    "highlights": [
      "tutorial",
      "dev.to"
    ]
  },
  {
    "title": "Ollama is most popular, but not always the best solution: Your GPU matters",
    "date": "Sun, 02 Nov 2025 23:52:14 GMT",
    "summary": "<div class=\"medium-feed-item\"><p class=\"medium-feed-image\"><a href=\"https://medium.com/@humble92/ollama-is-most-popular-but-not-always-the-best-solution-your-gpu-matters-4f4ce2b3402a?source=rss------ollama-5\"><img src=\"https://cdn-images-1.medium.com/max/600/1*DCHtbnOrhe5eYPNHjGaUrg.png\" width=\"600\"",
    "url": "https://medium.com/@humble92/ollama-is-most-popular-but-not-always-the-best-solution-your-gpu-matters-4f4ce2b3402a?source=rss------ollama-5",
    "source": "medium",
    "turbo_score": 0.7,
    "highlights": [
      "article",
      "medium"
    ]
  },
  {
    "title": "Open WebUI‚Ää‚Äî‚ÄäTalk to Local LLMs",
    "date": "Sun, 02 Nov 2025 18:44:21 GMT",
    "summary": "<div class=\"medium-feed-item\"><p class=\"medium-feed-image\"><a href=\"https://medium.com/@sritharrajan/open-webui-talk-to-local-llms-63a3fa2c429f?source=rss------ollama-5\"><img src=\"https://cdn-images-1.medium.com/max/2334/1*-kIaC6vqUqpQsFGHMe56WQ.png\" width=\"2334\" /></a></p><p class=\"medium-feed-snip",
    "url": "https://medium.com/@sritharrajan/open-webui-talk-to-local-llms-63a3fa2c429f?source=rss------ollama-5",
    "source": "medium",
    "turbo_score": 0.7,
    "highlights": [
      "article",
      "medium"
    ]
  },
  {
    "title": "Build a coding agents with CrewAI‚Ää‚Äî‚ÄäNext.js Webpage",
    "date": "Sun, 02 Nov 2025 15:42:30 GMT",
    "summary": "<div class=\"medium-feed-item\"><p class=\"medium-feed-image\"><a href=\"https://medium.com/@lchlaw/build-a-coding-agents-with-crewai-next-js-webpage-cda128a9599b?source=rss------ollama-5\"><img src=\"https://cdn-images-1.medium.com/max/908/1*WwT4nOhs9HwYkvphR2dJ1g.png\" width=\"908\" /></a></p><p class=\"medi",
    "url": "https://medium.com/@lchlaw/build-a-coding-agents-with-crewai-next-js-webpage-cda128a9599b?source=rss------ollama-5",
    "source": "medium",
    "turbo_score": 0.7,
    "highlights": [
      "article",
      "medium"
    ]
  },
  {
    "title": "Setting Up Ollama on a Local Machine",
    "date": "Sun, 02 Nov 2025 09:25:12 GMT",
    "summary": "<div class=\"medium-feed-item\"><p class=\"medium-feed-image\"><a href=\"https://medium.com/@lchlaw/setting-up-ollama-on-a-local-machine-96f474343f92?source=rss------ollama-5\"><img src=\"https://cdn-images-1.medium.com/max/1180/1*8KeBczcVCKXtYTDfw58z0Q.png\" width=\"1180\" /></a></p><p class=\"medium-feed-sni",
    "url": "https://medium.com/@lchlaw/setting-up-ollama-on-a-local-machine-96f474343f92?source=rss------ollama-5",
    "source": "medium",
    "turbo_score": 0.7,
    "highlights": [
      "article",
      "medium"
    ]
  },
  {
    "title": "‰ΩøÁî® mlx-lm ‰ª• LoRA ÂæÆË™ø LLM ‰∏¶ÈÄèÈÅé Ollama ÂëºÂè´‰æÜÁøªË≠ØÊäÄË°ìÊñá‰ª∂Ôºà‰∏âÔºâ",
    "date": "Sun, 02 Nov 2025 07:15:01 GMT",
    "summary": "<div class=\"medium-feed-item\"><p class=\"medium-feed-snippet\">&#x63a5;&#x7e8c;&#x524d;&#x7bc7;&#x8a13;&#x7df4;&#x5b8c;&#x6a21;&#x578b;&#x4e4b;&#x5f8c;&#xff0c;&#x9019;&#x7bc7;&#x4ecb;&#x7d39;&#x5982;&#x4f55;&#x5c07;&#x8a13;&#x7df4;&#x7d50;&#x679c;&#x5408;&#x4f75;&#x56de;&#x6a21;&#x578b;&#xff0c;&#x4e26",
    "url": "https://medium.com/@minghx/llm-fine-tune-with-lora-for-pytw-3-06dfe1b54d31?source=rss------ollama-5",
    "source": "medium",
    "turbo_score": 0.7,
    "highlights": [
      "article",
      "medium"
    ]
  },
  {
    "title": "askGPT v1.0.0‚Ää‚Äî‚ÄäCLI Agents Unleashed",
    "date": "Sat, 01 Nov 2025 05:58:34 GMT",
    "summary": "<div class=\"medium-feed-item\"><p class=\"medium-feed-image\"><a href=\"https://medium.com/@meirgotroot/askgpt-v1-0-0-cli-agents-unleashed-876bc52c632a?source=rss------ollama-5\"><img src=\"https://cdn-images-1.medium.com/max/1024/1*04Zaq5KqXCbskvqsZewX4A.png\" width=\"1024\" /></a></p><p class=\"medium-feed-",
    "url": "https://medium.com/@meirgotroot/askgpt-v1-0-0-cli-agents-unleashed-876bc52c632a?source=rss------ollama-5",
    "source": "medium",
    "turbo_score": 0.7,
    "highlights": [
      "article",
      "medium"
    ]
  },
  {
    "title": "Ollama Meets Neovim",
    "date": "Thu, 30 Oct 2025 14:12:43 GMT",
    "summary": "<div class=\"medium-feed-item\"><p class=\"medium-feed-image\"><a href=\"https://medium.com/globant/ollama-meets-neovim-9ab99e9b15af?source=rss------ollama-5\"><img src=\"https://cdn-images-1.medium.com/max/1024/1*h6wHhOv-wkPuMOj6P_nB_A.jpeg\" width=\"1024\" /></a></p><p class=\"medium-feed-snippet\">The Power ",
    "url": "https://medium.com/globant/ollama-meets-neovim-9ab99e9b15af?source=rss------ollama-5",
    "source": "medium",
    "turbo_score": 0.7,
    "highlights": [
      "article",
      "medium"
    ]
  },
  {
    "title": "RAG approach for Maven dependencies with Spring AI and Ollama",
    "date": "Thu, 30 Oct 2025 13:52:55 GMT",
    "summary": "<div class=\"medium-feed-item\"><p class=\"medium-feed-image\"><a href=\"https://medium.com/@anastasios.savvopoulos/rag-approach-for-maven-dependencies-with-spring-ai-and-ollama-0259c542d4a5?source=rss------ollama-5\"><img src=\"https://cdn-images-1.medium.com/max/600/1*oa6FZSIehwaDzelg7oMKSw.png\" width=\"6",
    "url": "https://medium.com/@anastasios.savvopoulos/rag-approach-for-maven-dependencies-with-spring-ai-and-ollama-0259c542d4a5?source=rss------ollama-5",
    "source": "medium",
    "turbo_score": 0.7,
    "highlights": [
      "article",
      "medium"
    ]
  },
  {
    "title": "Building Your First AI Chatbot with Ollama and Gradio",
    "date": "Thu, 30 Oct 2025 08:06:01 GMT",
    "summary": "<div class=\"medium-feed-item\"><p class=\"medium-feed-image\"><a href=\"https://medium.com/analytics-vidhya/building-your-first-ai-chatbot-with-ollama-and-gradio-e9667878941b?source=rss------ollama-5\"><img src=\"https://cdn-images-1.medium.com/max/1536/1*g4Bp33iN7lyzciOLBltCxQ.png\" width=\"1536\" /></a></p",
    "url": "https://medium.com/analytics-vidhya/building-your-first-ai-chatbot-with-ollama-and-gradio-e9667878941b?source=rss------ollama-5",
    "source": "medium",
    "turbo_score": 0.7,
    "highlights": [
      "article",
      "medium"
    ]
  },
  {
    "title": "Using ollama models locally using python and docker",
    "date": "Thu, 30 Oct 2025 05:25:26 GMT",
    "summary": "<div class=\"medium-feed-item\"><p class=\"medium-feed-snippet\">Here is step by step guid on how to use llama3.1 locally on mac also how to use it with python.</p><p class=\"medium-feed-link\"><a href=\"https://medium.com/@ompatel1911/using-llama3-1-locally-using-python-2598624430f5?source=rss------ollama",
    "url": "https://medium.com/@ompatel1911/using-llama3-1-locally-using-python-2598624430f5?source=rss------ollama-5",
    "source": "medium",
    "turbo_score": 0.7,
    "highlights": [
      "article",
      "medium"
    ]
  }
]