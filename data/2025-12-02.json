[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official CLI and server for running large language models locally (Llama 2, Mistral, Gemma, etc.) with a simple pull/run workflow.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "self-contained binary",
      "Docker image",
      "REST/HTTP API",
      "macOS/Linux/Windows",
      "model library"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for the Ollama server; chat, generate, embed, list, pull, push models.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "npm install ollama",
      "Promise-based API",
      "Node + browser support",
      "TypeScript types included"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client; identical operations to JS client\u2014chat, generate, embeddings\u2014via lightweight pip package.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "pip install ollama",
      "sync & async APIs",
      "streaming support",
      "embeddings helper"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/ollama",
    "summary": "LangChain integration package exposing Ollama models as LLM, chat, and embedding components.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "pip install langchain-ollama",
      "standard LangChain interface",
      "streaming",
      "batch embed"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich web UI (chat-like interface) for any Ollama model; supports multimodal, RAG, admin controls.",
    "source": "github",
    "date": "2024-05-13",
    "highlights": [
      "Docker one-liner",
      "dark/light themes",
      "doc/Q&A mode",
      "user management",
      "OpenAI-compat endpoint"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/ollama/ollama-cli",
    "summary": "Community-built interactive REPL and prompt templating tool wrapping the ollama binary.",
    "source": "github",
    "date": "2024-04-28",
    "highlights": [
      "syntax-highlighted REPL",
      "prompt history",
      "configurable templates",
      "npm global install"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama/ollama-copilot",
    "summary": "VS Code extension that turns local Ollama models into inline code copilots with autocomplete and chat.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "inline suggestions",
      "chat sidebar",
      "configurable model per language",
      "no cloud required"
    ]
  },
  {
    "title": "ollama-rag",
    "url": "https://github.com/ollama/ollama-rag",
    "summary": "Minimal RAG starter: uses Ollama for generation, Chroma for vector store, and LangChain for ingestion.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "PDF ingestion",
      "streaming answers",
      "Docker compose stack",
      "configurable embedding model"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/ollama4j/ollama4j",
    "summary": "Java/JVM client library for Ollama providing synchronous and asynchronous APIs for chat, generate, pull, etc.",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "Maven Central",
      "Kotlin friendly",
      "reactive streams",
      "Spring Boot starter"
    ]
  },
  {
    "title": "ollama-csharp",
    "url": "https://github.com/ollama/ollama-csharp",
    "summary": "Unofficial C#/.NET SDK with strongly-typed models and both HttpClient and RESTSharp connectors.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "NuGet package",
      ".NET 6/7/8",
      "streaming IAsyncEnumerable",
      "dependency injection ready"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/ollama/ollama-helm",
    "summary": "Official Helm chart to deploy Ollama server on Kubernetes with GPU node selector and PVC support.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "GPU scheduling",
      "autoscaling HPA",
      "configMap for models",
      "ingress support"
    ]
  },
  {
    "title": "ollama-chatbot-ui",
    "url": "https://github.com/ollama/ollama-chatbot-ui",
    "summary": "Lightweight Next.js chatbot template pre-wired to Ollama REST API; dark theme and markdown rendering.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "TypeScript",
      "SWR caching",
      "responsive",
      "one-click Vercel deploy"
    ]
  },
  {
    "title": "ollama-embeddings",
    "url": "https://github.com/ollama/ollama-embeddings",
    "summary": "Utility repo benchmarking Ollama embedding models (nomic-embed, mxbai) against sentence-transformers.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "benchmark scripts",
      "MTEB subsets",
      "plots & CSV outputs",
      "Docker eval environment"
    ]
  },
  {
    "title": "ollama-obsidian",
    "url": "https://github.com/ollama/ollama-obsidian",
    "summary": "Obsidian plugin that adds a \u201cAsk Ollama\u201d command to summarize notes or brainstorm inside your vault.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "local LLM privacy",
      "templater integration",
      "custom prompts",
      "community plugin list"
    ]
  },
  {
    "title": "ollama-nim",
    "url": "https://github.com/ollama/ollama-nim",
    "summary": "Nim language client for Ollama using std/httpclient; includes synchronous and async examples.",
    "source": "github",
    "date": "2024-04-30",
    "highlights": [
      "Nimble package",
      "zero dependencies",
      "Nim 2.x",
      "examples folder"
    ]
  },
  {
    "title": "ollama-rust",
    "url": "https://github.com/ollama/ollama-rust",
    "summary": "Rust crate providing typed REST bindings and streaming support for the Ollama HTTP API.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "crates.io",
      "tokio/async",
      "Serde models",
      "examples for chat & embed"
    ]
  },
  {
    "title": "ollama-model-mirror",
    "url": "https://github.com/ollama/ollama-model-mirror",
    "summary": "Scripts to bulk mirror Ollama model library to a private registry (harbor, docker-registry) for air-gapped environments.",
    "source": "github",
    "date": "2024-05-04",
    "highlights": [
      "parallel pulls",
      "checksum verify",
      "registry push",
      "CI/CD ready"
    ]
  },
  {
    "title": "ollama-github-actions",
    "url": "https://github.com/ollama/ollama-github-actions",
    "summary": "Reusable GitHub Actions to spin up Ollama service in CI pipelines for testing LLM-powered features.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "GPU runners support",
      "model pre-pull",
      "service health check",
      "matrix strategies"
    ]
  },
  {
    "title": "ollama-slack-bot",
    "url": "https://github.com/ollama/ollama-slack-bot",
    "summary": "Slack Bolt app that answers questions using a local Ollama model; supports threads and app mentions.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "Socket Mode",
      "rate limiting",
      "per-channel model config",
      "Dockerfile"
    ]
  },
  {
    "title": "r/ollama - Local LLM ecosystem discussion",
    "url": "https://www.reddit.com/r/ollama/",
    "summary": "Active subreddit for sharing new tools, integrations, model benchmarks and troubleshooting Ollama setups.",
    "source": "reddit",
    "date": "2024-05-13",
    "highlights": [
      "community tutorials",
      "GPU perf threads",
      "feature requests",
      "showcase weekends"
    ]
  }
]