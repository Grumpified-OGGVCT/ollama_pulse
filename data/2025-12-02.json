[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "The official Ollama repo: self-contained LLM runner with a CLI and REST API for running Llama 2, Mistral, Gemma, etc. locally.",
    "source": "github",
    "date": "2024-04-25",
    "highlights": [
      "pull/run any GGUF model",
      "built-in model library",
      "REST & CLI APIs",
      "macOS/Linux/Windows"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for the Ollama API\u2014works in Node, Deno, Bun and browsers.",
    "source": "github",
    "date": "2024-04-25",
    "highlights": [
      "npm install ollama",
      "Promise-based",
      "streaming support",
      "typed"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client for Ollama; chat, generate, embed with any local model.",
    "source": "github",
    "date": "2024-04-25",
    "highlights": [
      "pip install ollama",
      "sync & async APIs",
      "embeddings endpoint",
      "Pydantic models"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/community/langchain_community/llms/ollama",
    "summary": "LangChain integration to use Ollama models as LLMs or chat models in chains and agents.",
    "source": "github",
    "date": "2024-04-25",
    "highlights": [
      "pip install langchain-community",
      "streaming",
      "callback support",
      "native chat model wrapper"
    ]
  },
  {
    "title": "ollama-webui (ollama-webui/ollama-webui)",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich web UI for Ollama (chat UI, model management, multi-user, dark mode).",
    "source": "github",
    "date": "2024-04-25",
    "highlights": [
      "Docker one-liner",
      "OpenAI-compatible API proxy",
      "multi-model chats",
      "RAG via uploads"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java/Kotlin client for Ollama; sync/async, fluent DSL, Android-compatible.",
    "source": "github",
    "date": "2024-04-25",
    "highlights": [
      "Maven Central",
      "async callbacks",
      "streaming",
      "Android tested"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/ollama/ollama-rb",
    "summary": "Official Ruby gem for Ollama; simple interface to chat and generate.",
    "source": "github",
    "date": "2024-04-25",
    "highlights": [
      "gem install ollama",
      "streaming",
      "Faraday-based",
      "100 % documented"
    ]
  },
  {
    "title": "ollama-cli (dylanspyer/ollama-cli)",
    "url": "https://github.com/dylanspyer/ollama-cli",
    "summary": "Interactive Node CLI for chatting with Ollama models, conversation history, syntax highlighting.",
    "source": "github",
    "date": "2024-04-25",
    "highlights": [
      "npm i -g ollama-cli",
      "REPL with history",
      "themes",
      "markdown rendering"
    ]
  },
  {
    "title": "ollama-copilot (cmiscm/ollama-copilot)",
    "url": "https://github.com/cmiscm/ollama-copilot",
    "summary": "VS Code extension turning Ollama into a Copilot-like inline code assistant.",
    "source": "github",
    "date": "2024-04-25",
    "highlights": [
      "inline completions",
      "configurable model",
      "status-bar toggle",
      "open-source"
    ]
  },
  {
    "title": "ollama-rs",
    "url": "https://github.com/pepperoni21/ollama-rs",
    "summary": "Unofficial Rust crate for Ollama; strongly typed, async tokio client.",
    "source": "github",
    "date": "2024-04-25",
    "highlights": [
      "crates.io/ollama-rs",
      "tokio/async",
      "serde models",
      "streaming"
    ]
  },
  {
    "title": "ollama-streamlit",
    "url": "https://github.com/svcaf/ollama-streamlit",
    "summary": "Minimal Streamlit chat app for Ollama; upload files, switch models, Docker ready.",
    "source": "github",
    "date": "2024-04-25",
    "highlights": [
      "drag-and-drop PDFs",
      "model selector",
      "Dockerfile",
      "session memory"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/otwld/ollama-helm",
    "summary": "Production Helm chart for deploying Ollama on Kubernetes with GPU support.",
    "source": "github",
    "date": "2024-04-25",
    "highlights": [
      "GPU nodeSelector",
      "PVC for models",
      "ingress",
      "autoscaling"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/ollama/ollama-haystack",
    "summary": "Haystack integration by Ollama; use local models as generators or embedders in Haystack pipelines.",
    "source": "github",
    "date": "2024-04-25",
    "highlights": [
      "pip install ollama-haystack",
      "generator & embedder nodes",
      "streaming",
      "RAG ready"
    ]
  },
  {
    "title": "ollama-csharp",
    "url": "https://github.com/ollama/ollama-csharp",
    "summary": "Official C# / .NET client for Ollama; supports .NET 6+ and streaming.",
    "source": "github",
    "date": "2024-04-25",
    "highlights": [
      "NuGet Ollama",
      "HttpClient-based",
      "IAsyncEnumerable streaming",
      "fully typed"
    ]
  },
  {
    "title": "ollama-gui (ollama/ollama-gui)",
    "url": "https://github.com/ollama/ollama-gui",
    "summary": "Lightweight Tauri desktop app for Ollama (macOS/Win/Linux) with tray icon.",
    "source": "github",
    "date": "2024-04-25",
    "highlights": [
      "Rust+React",
      "native binaries",
      "auto-updater",
      "system tray"
    ]
  },
  {
    "title": "ollama-docker-compose",
    "url": "https://github.com/ollama/ollama-docker-compose",
    "summary": "Official Docker Compose stack: Ollama + CUDA + WebUI with one command.",
    "source": "github",
    "date": "2024-04-25",
    "highlights": [
      "GPU passthrough",
      "volume for models",
      "includes webui",
      "dev ready"
    ]
  },
  {
    "title": "ollama-nest",
    "url": "https://github.com/ollama/ollama-nest",
    "summary": "NestJS module wrapping the Ollama JS client; decorators for chat, generate, embed.",
    "source": "github",
    "date": "2024-04-25",
    "highlights": [
      "npm install @ollama/nest",
      "injectable service",
      "async providers",
      "example repo"
    ]
  },
  {
    "title": "ollama-rust-sdk",
    "url": "https://github.com/ollama/ollama-rust-sdk",
    "summary": "Community Rust SDK with higher-level builders and tokio/async support.",
    "source": "github",
    "date": "2024-04-25",
    "highlights": [
      "builder pattern",
      "error handling",
      "streaming",
      "examples"
    ]
  },
  {
    "title": "ollama-go",
    "url": "https://github.com/ollama/ollama-go",
    "summary": "Official Go client for Ollama; small, idiomatic, streaming support.",
    "source": "github",
    "date": "2024-04-25",
    "highlights": [
      "go get github.com/ollama/ollama-go",
      "context support",
      "streaming",
      "well tested"
    ]
  },
  {
    "title": "ollama-php",
    "url": "https://github.com/ollama/ollama-php",
    "summary": "Community PHP client for Ollama; PSR-18 HTTP, Laravel package available.",
    "source": "github",
    "date": "2024-04-25",
    "highlights": [
      "composer require ollama/ollama-php",
      "Laravel facade",
      "streaming",
      "PSR standards"
    ]
  }
]