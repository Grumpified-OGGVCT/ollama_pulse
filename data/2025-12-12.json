[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: self-hosted LLM runner with a built-in model library and simple CLI/API.",
    "source": "github",
    "date": "2023-06-26",
    "highlights": [
      "CLI",
      "REST API",
      "pull/run any GGUF",
      "macOS/Linux/Windows"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client/SDK for Ollama; chat, embed, pull models in a few lines.",
    "source": "github",
    "date": "2023-07-18",
    "highlights": [
      "pip install ollama",
      "sync/async",
      "embeddings",
      "chat"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Node & browsers; same API surface as Python.",
    "source": "github",
    "date": "2023-07-21",
    "highlights": [
      "npm i ollama",
      "TypeScript",
      "chat/embed",
      "Promise/async"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/langchain-ollama",
    "summary": "LangChain integration package to use Ollama models for chat, tools, retrieval.",
    "source": "github",
    "date": "2023-09-05",
    "highlights": [
      "pip install langchain-ollama",
      "ChatOllama",
      "embeddings",
      "RAG"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich web UI for Ollama (chat, model manager, multi-user, dark mode).",
    "source": "github",
    "date": "2023-10-02",
    "highlights": [
      "Docker",
      "multi-chat",
      "import/export",
      "admin panel"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java/Kotlin client for Ollama; sync/async, streaming, embeddings, tools support.",
    "source": "github",
    "date": "2023-11-12",
    "highlights": [
      "Maven Central",
      "Kotlin coroutines",
      "streaming",
      "tools"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/ollama/ollama-rb",
    "summary": "Official Ruby gem for Ollama; chat, pull, delete, list, show, copy models.",
    "source": "github",
    "date": "2023-12-01",
    "highlights": [
      "gem install ollama",
      "streaming",
      "Ruby 3.x",
      "official"
    ]
  },
  {
    "title": "ollama-cli (npm)",
    "url": "https://www.npmjs.com/package/ollama-cli",
    "summary": "Lightweight Node CLI wrapper around Ollama REST API; chat, pull, list, ps.",
    "source": "github",
    "date": "2023-08-14",
    "highlights": [
      "npm i -g ollama-cli",
      "interactive chat",
      "global install"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama/ollama-copilot",
    "summary": "VS Code extension bringing local Ollama models inline as GitHub-Copilot-style suggestions.",
    "source": "github",
    "date": "2023-11-20",
    "highlights": [
      "VS Code",
      "inline completions",
      "local LLM",
      "no API key"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/otwld/ollama-helm",
    "summary": "Production-ready Helm chart for deploying Ollama on Kubernetes with GPU support.",
    "source": "github",
    "date": "2023-10-30",
    "highlights": [
      "Helm",
      "K8s",
      "GPU nodeSelector",
      "persistence",
      "autoscaling"
    ]
  },
  {
    "title": "ollama-dagger",
    "url": "https://github.com/shykes/ollama-dagger",
    "summary": "Dagger module to run Ollama containers in CI pipelines for testing LLM-powered apps.",
    "source": "github",
    "date": "2023-12-03",
    "highlights": [
      "Dagger",
      "CI",
      "reproducible",
      "caching",
      "GitHub Actions"
    ]
  },
  {
    "title": "ollama-cookbook",
    "url": "https://github.com/ollama/ollama-cookbook",
    "summary": "Community recipes: PDF chat, voice, function-calling, RAG, fine-tune, Docker Compose.",
    "source": "github",
    "date": "2023-09-18",
    "highlights": [
      "examples",
      "RAG",
      "function calling",
      "fine-tune",
      "Compose"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/deepset-ai/haystack-integrations/tree/main/integrations/ollama",
    "summary": "Haystack integration to use Ollama models as generators or embedders in pipelines.",
    "source": "github",
    "date": "2023-11-05",
    "highlights": [
      "Haystack",
      "pipelines",
      "RAG",
      "embeddings",
      "generator"
    ]
  },
  {
    "title": "ollama-csharp",
    "url": "https://github.com/ollama/ollama-csharp",
    "summary": "Official C# / .NET client for Ollama; supports chat, streaming, embeddings, tools.",
    "source": "github",
    "date": "2023-12-10",
    "highlights": [
      "NuGet",
      ".NET 6+",
      "streaming",
      "official",
      "embeddings"
    ]
  },
  {
    "title": "ollama-llamaindex",
    "url": "https://github.com/run-llama/llama_index/tree/main/llama-index-integrations/llms/llama-index-llms-ollama",
    "summary": "LlamaIndex LLM & embedding drivers for Ollama; one-line swap for local models.",
    "source": "github",
    "date": "2023-10-12",
    "highlights": [
      "pip install llama-index-llms-ollama",
      "RAG",
      "embeddings",
      "chat"
    ]
  },
  {
    "title": "ollama-discord-bot",
    "url": "https://github.com/ollama-discord/ollama-discord-bot",
    "summary": "Self-hostable Discord bot that lets servers chat with any Ollama model via slash commands.",
    "source": "github",
    "date": "2023-11-25",
    "highlights": [
      "Discord.py",
      "slash commands",
      "multi-model",
      "Docker"
    ]
  },
  {
    "title": "ollama-gui",
    "url": "https://github.com/jmorganca/ollama-gui",
    "summary": "Minimal Tauri-based desktop GUI for Ollama (macOS/Linux/Windows) with chat interface.",
    "source": "github",
    "date": "2023-08-20",
    "highlights": [
      "Tauri",
      "desktop",
      "cross-platform",
      "lightweight",
      "chat"
    ]
  },
  {
    "title": "ollama-nvidia-jetson",
    "url": "https://github.com/dusty-nv/ollama-nvidia-jetson",
    "summary": "Dockerfile & scripts to run GPU-accelerated Ollama on NVIDIA Jetson devices.",
    "source": "github",
    "date": "2023-10-15",
    "highlights": [
      "Jetson",
      "CUDA",
      "Docker",
      "GPU",
      "ARM64"
    ]
  },
  {
    "title": "ollama-rust",
    "url": "https://github.com/ollama/ollama-rust",
    "summary": "Official Rust crate providing strongly-typed async client for Ollama REST API.",
    "source": "github",
    "date": "2023-12-12",
    "highlights": [
      "crates.io",
      "async",
      "tokio",
      "official",
      "streaming"
    ]
  },
  {
    "title": "ollama-model-hub",
    "url": "https://github.com/ollama-model-hub/ollama-model-hub",
    "summary": "Community-curated list of custom GGUF models ready to pull into Ollama with one command.",
    "source": "github",
    "date": "2023-11-30",
    "highlights": [
      "community",
      "Modelfile",
      "GGUF",
      "pull scripts",
      "README badges"
    ]
  }
]