[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Ollama\u2019s official CLI and server for running Llama 2, Mistral, Gemma, and other LLMs locally with one command.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "self-contained binaries",
      "model pulling from registry",
      "REST API",
      "macOS/Linux/Windows"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client library for the Ollama server; chat, generate, embed, pull, and manage models.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "pip install ollama",
      "sync & async APIs",
      "type hints",
      "embeddings support"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Node & browsers; same generate/chat/embed API surface.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "npm i ollama",
      "ESM & CommonJS",
      "streaming responses",
      "typed"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/langchain-ollama",
    "summary": "LangChain integration package that wraps Ollama for local LLM chains, agents, and retrieval.",
    "source": "github",
    "date": "2024-05-13",
    "highlights": [
      "pip install langchain-ollama",
      "ChatOllama",
      "OllamaEmbeddings",
      "tool-calling"
    ]
  },
  {
    "title": "ollama-webui (ollama-web/ollama-webui)",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich ChatGPT-style web UI for any Ollama model; folders, sharing, prompts, multimodal.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "docker-compose one-liner",
      "dark/light themes",
      "code highlighting",
      "role-play"
    ]
  },
  {
    "title": "Open WebUI (formerly Ollama WebUI)",
    "url": "https://github.com/open-webui/open-webui",
    "summary": "Community fork adding admin panel, RAG, LDAP, and plugin ecosystem atop Ollama.",
    "source": "github",
    "date": "2024-05-15",
    "highlights": [
      "RAG w/ embeddings",
      "user management",
      "whisper voice input",
      "extensible plugins"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/sugarforever/ollama-cli",
    "summary": "Rust-based interactive CLI with chat history, syntax highlighting, and model switching.",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "cross-platform binary",
      "readline",
      "conversation save/load",
      "themes"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama-copilot/ollama-copilot",
    "summary": "VS Code extension bringing local Ollama models into inline suggestions & chat sidebar.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "inline completions",
      "custom prompts",
      "multi-model switch",
      "privacy-first"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/ollama-helm/ollama-helm",
    "summary": "Helm chart for deploying Ollama server & models on Kubernetes with GPU autoscaling.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "GPU node-selector",
      "model pre-pull init",
      "ingress",
      "persistence"
    ]
  },
  {
    "title": "ollama-docker",
    "url": "https://github.com/ollama/ollama/tree/main/docker",
    "summary": "Official container images (CPU & CUDA) and compose examples for Ollama.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "official",
      "CUDA 11/12 tags",
      "rootless",
      "compose with webui"
    ]
  },
  {
    "title": "ollama-rag",
    "url": "https://github.com/ggerganov/ollama-rag",
    "summary": "Minimal RAG example using Ollama embeddings + Chroma for local document Q&A.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "Chroma vector store",
      "PDF ingestion",
      "streamlit UI",
      "offline"
    ]
  },
  {
    "title": "ollama-agents",
    "url": "https://github.com/jmorganca/ollama-agents",
    "summary": "Experimental framework for building tool-using agents backed by Ollama LLMs.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "ReAct loop",
      "tool registry",
      "parallel calls",
      "JSON mode"
    ]
  },
  {
    "title": "ollama-nvim",
    "url": "https://github.com/nomnivore/ollama-nvim",
    "summary": "Neovim plugin to generate, refactor, and chat with Ollama models inside the editor.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "Lua config",
      "selection prompts",
      "side-chat",
      "telescope picker"
    ]
  },
  {
    "title": "ollama-models",
    "url": "https://github.com/ollama/ollama/tree/main/models",
    "summary": "Official Modelfile collection (Llama 3, Phi-3, Mistral, CodeLlama, etc.) with build instructions.",
    "source": "github",
    "date": "2024-05-13",
    "highlights": [
      "quantized GGUF",
      "custom Modelfiles",
      "system prompts",
      "fine-tune notes"
    ]
  },
  {
    "title": "ollama-hub",
    "url": "https://github.com/ollama-hub/ollama-hub",
    "summary": "Community-curated registry of Modelfiles, adapters, and tools for Ollama.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "user submissions",
      "star ratings",
      "tags",
      "one-click import"
    ]
  },
  {
    "title": "ollama-grpc",
    "url": "https://github.com/ollama-grpc/ollama-grpc",
    "summary": "gRPC server shim exposing Ollama generate/chat with protobuf & streaming.",
    "source": "github",
    "date": "2024-05-04",
    "highlights": [
      "protobuf schema",
      "bidirectional stream",
      "Go server",
      "Python client"
    ]
  },
  {
    "title": "ollama-streamlit",
    "url": "https://github.com/streamlit/ollama-streamlit",
    "summary": "Streamlit chat component template that plugs into any local Ollama model.",
    "source": "github",
    "date": "2024-05-03",
    "highlights": [
      "pip install streamlit-ollama",
      "chat memory",
      "file upload",
      "voice input"
    ]
  },
  {
    "title": "ollama-rs",
    "url": "https://github.com/ollama-rs/ollama-rs",
    "summary": "Async Rust crate for Ollama REST API with serde types and streaming support.",
    "source": "github",
    "date": "2024-05-02",
    "highlights": [
      "tokio",
      "futures stream",
      "strong typing",
      "examples"
    ]
  },
  {
    "title": "ollama-obsidian",
    "url": "https://github.com/ollama-obsidian/ollama-obsidian",
    "summary": "Obsidian plugin for local AI autocomplete and note Q&A via Ollama.",
    "source": "github",
    "date": "2024-05-01",
    "highlights": [
      "offline",
      "vault RAG",
      "custom templates",
      "community plugins"
    ]
  },
  {
    "title": "ollama-slack-bot",
    "url": "https://github.com/ollama-slack/ollama-slack-bot",
    "summary": "Slack Bolt bot that answers channel questions using Ollama models.",
    "source": "github",
    "date": "2024-04-30",
    "highlights": [
      "slash commands",
      "threading",
      "rate limiting",
      "mention trigger"
    ]
  }
]