[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: get up and running with Llama 2, Mistral, Gemma, and other large language models locally.",
    "source": "github",
    "date": "2024-05-19",
    "highlights": [
      "self-contained LLM runner",
      "macOS/Linux/Windows",
      "Docker images",
      "Modelfile DSL"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python SDK for Ollama: chat, generate, embed, pull, and manage models with a few lines of code.",
    "source": "github",
    "date": "2024-05-15",
    "highlights": [
      "pip install ollama",
      "sync/async APIs",
      "streaming responses",
      "built-in embeddings"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Node, Deno, and browsers to interact with the Ollama server.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "npm install ollama",
      "ESM & CommonJS",
      "TypeScript types",
      "streaming chat"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://python.langchain.com/docs/integrations/llms/ollama",
    "summary": "LangChain integration: use any Ollama model as an LLM, chat, or embeddings component inside LangChain pipelines.",
    "source": "blog",
    "date": "2024-04-22",
    "highlights": [
      "pip install langchain-ollama",
      "tool calling support",
      "retrieval QA",
      "agent loops"
    ]
  },
  {
    "title": "ollama-webui (Ollama-WebUI)",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich web UI for Ollama: chat UI, model management, multi-user, RAG uploads, voice input, themes.",
    "source": "github",
    "date": "2024-05-18",
    "highlights": [
      "Docker one-liner",
      "OpenAI-compatible API",
      "PDF/CSV ingestion",
      "dark/light modes"
    ]
  },
  {
    "title": "ollama4j \u2013 Java Ollama Client",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Unofficial Java/Kotlin client providing synchronous & asynchronous APIs for chat, generate, pull, and embed.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "Maven Central",
      "Kotlin coroutines",
      "streaming support",
      "POJO mapping"
    ]
  },
  {
    "title": "ollama-rag \u2013 Minimal RAG example",
    "url": "https://github.com/ollama/ollama-rag",
    "summary": "Official sample repo showing how to build a retrieval-augmented generation pipeline with Ollama embeddings.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "ChromaDB vector store",
      "sentence-transformers",
      "streamlit UI",
      "step-by-step notebook"
    ]
  },
  {
    "title": "ollama-copilot \u2013 VS Code extension",
    "url": "https://github.com/michaelneale/ollama-copilot",
    "summary": "Free local GitHub Copilot alternative: inline completions, chat panel, and explain-code actions powered by Ollama.",
    "source": "github",
    "date": "2024-05-17",
    "highlights": [
      "VS Code marketplace",
      "configurable model",
      "inline suggestions",
      "no API keys"
    ]
  },
  {
    "title": "chainlit-ollama \u2013 ChatGPT-style UI in 5 lines",
    "url": "https://github.com/Chainlit/chainlit/tree/main/examples/ollama",
    "summary": "Chainlit example repo: drop-in replacement for OpenAI backend using Ollama to get a shareable chat UI.",
    "source": "github",
    "date": "2024-05-16",
    "highlights": [
      "pip install chainlit",
      "real-time feedback",
      "session replay",
      "data persistence"
    ]
  },
  {
    "title": "ollama-haystack \u2013 Haystack integration",
    "url": "https://github.com/deepset-ai/haystack-integrations/tree/main/integrations/ollama",
    "summary": "Use Ollama models as generators or embedders within Haystack pipelines for document search & QA.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "pip install haystack-ai[ollama]",
      "retrieval pipelines",
      "batch inference",
      "YAML config"
    ]
  },
  {
    "title": "ollama-n8n \u2013 N8n community node",
    "url": "https://github.com/n8n-io/n8n-nodes-ollama",
    "summary": "Community node for n8n workflow automation: chat, generate, and embed steps without writing code.",
    "source": "github",
    "date": "2024-05-13",
    "highlights": [
      "npm install n8n-nodes-ollama",
      "drag-and-drop",
      "credential-less",
      "workflow templates"
    ]
  },
  {
    "title": "ollama-rs \u2013 Rust client library",
    "url": "https://github.com/pepperoni21/ollama-rs",
    "summary": "Async Rust crate exposing strongly-typed APIs for chat, generate, embeddings, and model management.",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "crates.io",
      "Tokio runtime",
      "Serde models",
      "streaming futures"
    ]
  },
  {
    "title": "ollama-discord \u2013 Discord bot",
    "url": "https://github.com/ollama-discord/ollama-discord",
    "summary": "Host your own local LLM bot on Discord: slash commands, thread support, moderation, and model switching.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "Docker compose",
      "role-based access",
      "context per channel",
      "typing indicators"
    ]
  },
  {
    "title": "ollama-helm \u2013 Kubernetes Helm charts",
    "url": "https://github.com/otwld/ollama-helm",
    "summary": "Production-ready Helm chart to deploy Ollama on Kubernetes with GPU support, PVC, and autoscaling.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "Helm repo",
      "GPU node selector",
      "ingress",
      "prometheus metrics"
    ]
  },
  {
    "title": "ollama-dagger \u2013 Dagger CI module",
    "url": "https://github.com/dagger/dagger/tree/main/modules/ollama",
    "summary": "Reusable Dagger module that spins up Ollama containers in CI pipelines for integration testing of LLM features.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "CUE config",
      "caching layers",
      "GPU passthrough",
      "GitHub Actions example"
    ]
  },
  {
    "title": "ollama-csharp \u2013 .NET client",
    "url": "https://github.com/awaescher/OllamaSharp",
    "summary": "Community C# library with async/chat/embedding APIs and ready-to-use dependency-injection helpers for ASP.NET.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "NuGet package",
      "ASP.NET sample",
      "streaming IAsyncEnumerable",
      "strong naming"
    ]
  },
  {
    "title": "ollama-cli \u2013 Rich terminal UI",
    "url": "https://github.com/jmorganca/ollama-cli",
    "summary": "Experimental TUI for Ollama built with Charm Bubbletea: interactive model picker, markdown chat, and logs viewer.",
    "source": "github",
    "date": "2024-05-04",
    "highlights": [
      "go install",
      "vim keys",
      "offline help",
      "themes"
    ]
  },
  {
    "title": "ollama-obsidian \u2013 Obsidian plugin",
    "url": "https://github.com/hinterdupfinger/ollama-obsidian",
    "summary": "Bring local LLM power into Obsidian: summarize notes, brainstorm ideas, and Q&A over your knowledge base.",
    "source": "github",
    "date": "2024-05-03",
    "highlights": [
      "Community plugin",
      "template commands",
      "local embeddings",
      "privacy first"
    ]
  },
  {
    "title": "ollama-rustic \u2013 Axum web starter",
    "url": "https://github.com/pepperoni21/ollama-rustic",
    "summary": "Boilerplate Axum web server exposing REST and WebSocket endpoints backed by Ollama for chat and embeddings.",
    "source": "github",
    "date": "2024-05-02",
    "highlights": [
      "Dockerfile",
      "JWT auth",
      "Swagger UI",
      "WebSocket streaming"
    ]
  },
  {
    "title": "r/ollama \u2013 Community subreddit",
    "url": "https://reddit.com/r/ollama",
    "summary": "Active Reddit community sharing model tips, integrations, benchmarks, and troubleshooting help.",
    "source": "reddit",
    "date": "2024-05-19",
    "highlights": [
      "30k members",
      "weekly Q&A",
      "model requests",
      "showcase flair"
    ]
  }
]