[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: self-host LLMs (Llama 2, Mistral, Gemma, \u2026) behind a simple REST/CLI API with GPU/CPU support.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "CLI pull/run",
      "REST API",
      "macOS/Linux/Windows",
      "Docker image"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "First-party Python client for the Ollama API; sync & async, streaming, embeddings.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "PyPI: ollama",
      "asyncio",
      "chat & embed endpoints"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Node & browsers; tree-shake, ESM/CJS.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "npm: ollama",
      "streaming",
      "types included"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/langchain-ollama",
    "summary": "LangChain integration layer; chat, embeddings, tool-calling via Ollama.",
    "source": "github",
    "date": "2024-05-13",
    "highlights": [
      "pip: langchain-ollama",
      "tool usage",
      "RAG ready"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich ChatGPT-style web UI for Ollama; folders, presets, multi-user.",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "Docker one-liner",
      "dark/light",
      "import/export chats"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java/Kotlin client for Ollama; fluent builder, streaming, Android compatible.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "Maven Central",
      "async",
      "embedding support"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/ollama/ollama-rb",
    "summary": "Ruby gem wrapping the Ollama REST API; fibers for streaming.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "gem: ollama",
      "Fiber-based",
      "Rails ready"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama/ollama-copilot",
    "summary": "VS-Code extension bringing local LLM code completion via Ollama.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "inline suggestions",
      "FIM templates",
      "configurable model"
    ]
  },
  {
    "title": "ollama-cli-chat",
    "url": "https://github.com/sugarforever/ollama-cli-chat",
    "summary": "Terminal UI (rich markdown) for chatting with Ollama models; history, vim keys.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "pip install",
      "rich markdown",
      "persistent history"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/otwld/ollama-helm",
    "summary": "Helm chart to deploy Ollama on Kubernetes with GPU node-selector & autoscaling.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "GPU/CPU",
      "PVC",
      "Ingress",
      "HPA"
    ]
  },
  {
    "title": "ollama-gui",
    "url": "https://github.com/jmorganca/ollama-gui",
    "summary": "Minimal Tauri desktop app for Ollama; cross-platform, single binary.",
    "source": "github",
    "date": "2024-05-04",
    "highlights": [
      "Rust+React",
      "lightweight",
      "auto-updater"
    ]
  },
  {
    "title": "Ollama Reddit community",
    "url": "https://www.reddit.com/r/ollama/",
    "summary": "Active subreddit for model tips, integrations, troubleshooting.",
    "source": "reddit",
    "date": "2024-05-14",
    "highlights": [
      "show-and-tell",
      "model requests",
      "benchmarks"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/deepset-ai/haystack-ollama",
    "summary": "Haystack integration for retrieval & generative pipelines using Ollama.",
    "source": "github",
    "date": "2024-05-03",
    "highlights": [
      "pip: haystack-ollama",
      "embedding & generator",
      "RAG"
    ]
  },
  {
    "title": "ollama-docker-compose",
    "url": "https://github.com/ollama/ollama/tree/main/docker-compose",
    "summary": "Official compose stacks with GPU, CPU, Open-WebUI variants.",
    "source": "github",
    "date": "2024-05-02",
    "highlights": [
      "one-command",
      "CUDA",
      "Open-WebUI service"
    ]
  },
  {
    "title": "ollama-csharp",
    "url": "https://github.com/awaescher/ollama-csharp",
    "summary": ".NET client for Ollama; supports chat, completion, embeddings, streaming.",
    "source": "github",
    "date": "2024-05-01",
    "highlights": [
      "NuGet: OllamaSharp",
      "async IAsyncEnumerable",
      "strong types"
    ]
  },
  {
    "title": "ollama-powershell",
    "url": "https://github.com/ollama/ollama-powershell",
    "summary": "PowerShell module to manage models and chat from the terminal.",
    "source": "github",
    "date": "2024-04-30",
    "highlights": [
      "Install-Module Ollama",
      "tab-completion",
      "pipeline friendly"
    ]
  },
  {
    "title": "ollama-n8n-node",
    "url": "https://github.com/8go/ollama-n8n-node",
    "summary": "Custom n8n node to call Ollama workflows; no API key needed.",
    "source": "github",
    "date": "2024-04-29",
    "highlights": [
      "npm install",
      "workflow templates",
      "local LLM"
    ]
  },
  {
    "title": "ollama-go",
    "url": "https://github.com/ollama/ollama-go",
    "summary": "Official Go client library; small, idiomatic, streaming support.",
    "source": "github",
    "date": "2024-04-28",
    "highlights": [
      "go get github.com/ollama/ollama-go",
      "context cancellation"
    ]
  }
]