[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: self-hosted LLM runner with a built-in model library and Docker-style CLI.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "run Llama-3, Phi-3, Mistral locally",
      "Modelfile packaging",
      "REST & Go SDK APIs"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for the Ollama HTTP API, published to npm.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "Promise-based",
      "Node & browser support",
      "Stream chat completions"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client for Ollama; install via PyPI and integrate with LangChain, LlamaIndex, etc.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "sync & async APIs",
      "embeddings endpoint",
      "native Pydantic models"
    ]
  },
  {
    "title": "langchain-ollama (PyPI)",
    "url": "https://pypi.org/project/langchain-ollama/",
    "summary": "LangChain adapter that exposes Ollama models as standard LLM & chat interfaces.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "drop-in replacement for OpenAI",
      "streaming support",
      "callback handlers"
    ]
  },
  {
    "title": "ollama-webui (ollama-web/ollama-webui)",
    "url": "https://github.com/ollama-web/ollama-webui",
    "summary": "Popular open-source ChatGPT-style web UI that connects to a local Ollama instance.",
    "source": "github",
    "date": "2024-05-13",
    "highlights": [
      "markdown & code highlighting",
      "multi-model chats",
      "Docker image ready"
    ]
  },
  {
    "title": "ollama-cli (npm)",
    "url": "https://www.npmjs.com/package/ollama-cli",
    "summary": "Community-built interactive CLI for chatting, pulling, and managing Ollama models.",
    "source": "github",
    "date": "2024-04-30",
    "highlights": [
      "REPL mode",
      "conversation history file",
      "auto-pull missing models"
    ]
  },
  {
    "title": "ollama-copilot (GitHub)",
    "url": "https://github.com/ollama-copilot/ollama-copilot",
    "summary": "VS Code extension that routes GitHub Copilot calls to a local Ollama model for private coding assistance.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "open-source copilot replacement",
      "inline completions",
      "configurable model per language"
    ]
  },
  {
    "title": "ollama-rag (PyPI)",
    "url": "https://pypi.org/project/ollama-rag/",
    "summary": "Lightweight RAG (retrieval-augmented generation) wrapper that pairs Ollama embeddings with vector DBs.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "Chroma & Qdrant support",
      "PDF ingestion CLI",
      "streamed citations"
    ]
  },
  {
    "title": "ollama4j (Java SDK)",
    "url": "https://github.com/ollama4j/ollama4j",
    "summary": "Community Java/Kotlin SDK for Ollama; available on Maven Central.",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "Spring Boot starters",
      "reactive WebClient",
      "model management API"
    ]
  },
  {
    "title": "ollama discord bot",
    "url": "https://github.com/sawa-zen/ollama-discord",
    "summary": "Self-hostable Discord bot that lets servers chat with local Ollama models via slash commands.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "thread isolation per user",
      "modelfile switching",
      "typing indicators"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/otwld/ollama-helm",
    "summary": "Community-maintained Helm chart for deploying Ollama on Kubernetes with GPU node selection.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "nvidia-device-plugin support",
      "PVC model cache",
      "autoscaling HPA"
    ]
  },
  {
    "title": "reddit/r/ollama - Model discussion thread",
    "url": "https://www.reddit.com/r/ollama/comments/1c5y2kx/which_models_are_you_running_may_2024/",
    "summary": "Active community discussion comparing performance of Llama-3, Phi-3, Gemma, and Mistral on consumer hardware.",
    "source": "reddit",
    "date": "2024-05-12",
    "highlights": [
      "VRAM usage stats",
      "quantization tips",
      "speed benchmarks"
    ]
  },
  {
    "title": "Hacker News - Show HN: Ollama REST bridge for Rails",
    "url": "https://news.ycombinator.com/item?id=40351234",
    "summary": "Developer showcases a Rails engine that mounts Ollama as an internal AI service with authentication.",
    "source": "hackernews",
    "date": "2024-05-10",
    "highlights": [
      "JWT auth",
      "background job queue",
      "streaming Turbo responses"
    ]
  },
  {
    "title": "ollama-dart (pub.dev)",
    "url": "https://github.com/ollama-dart/ollama-dart",
    "summary": "Unofficial Dart/Flutter package that wraps the Ollama API for cross-platform desktop/mobile apps.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "isolates for inference",
      "model pull progress streams",
      "example Flutter chat UI"
    ]
  },
  {
    "title": "ollama-csharp (NuGet)",
    "url": "https://github.com/ollama-csharp/ollama-csharp",
    "summary": "Community .NET SDK for Ollama with async I/O and nullable-ref type safety.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "ASP.NET Core sample",
      "dependency-injection friendly",
      "cancellation tokens"
    ]
  },
  {
    "title": "ollama-obsidian",
    "url": "https://github.com/hintergrund/ollama-obsidian",
    "summary": "Obsidian plugin that adds \u201cAI continue writing\u201d commands using a local Ollama model.",
    "source": "github",
    "date": "2024-05-04",
    "highlights": [
      "template prompts",
      "front-matter context",
      "offline privacy"
    ]
  },
  {
    "title": "ollama-terraform",
    "url": "https://github.com/ollama-terraform/ollama-aws",
    "summary": "Terraform module that spins up GPU-enabled EC2 instances with Ollama pre-installed and systemd service.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "spot-instance friendly",
      "CloudWatch logs",
      "optional EFS model cache"
    ]
  },
  {
    "title": "ollama-slack-bot",
    "url": "https://github.com/omkar/ollama-slack",
    "summary": "Lightweight Go service that bridges Ollama to Slack workflows via socket-mode.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "mention-trigger",
      "threaded replies",
      "rate-limit per channel"
    ]
  },
  {
    "title": "ollama-logseq",
    "url": "https://github.com/logseq-community/ollama-logseq",
    "summary": "Logseq plugin for summarizing blocks and generating flashcards using Ollama.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "custom prompt files",
      "local graph context",
      "command palette"
    ]
  },
  {
    "title": "ollama-ray",
    "url": "https://github.com/ray-project/ollama-ray",
    "summary": "Ray Serve deployment example that scales multiple Ollama models behind a single endpoint.",
    "source": "github",
    "date": "2024-05-03",
    "highlights": [
      "GPU autoscaling",
      "A/B test routers",
      "Prometheus metrics"
    ]
  }
]