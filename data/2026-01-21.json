[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: self-contained LLM runner with a REST API and CLI for macOS, Linux, and Windows.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "CLI",
      "REST API",
      "Docker image",
      "Model library",
      "macOS/Linux/Windows"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python SDK for Ollama; chat, generate, embed, pull, and manage models with a few lines of code.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "PyPI package",
      "sync/async clients",
      "embeddings",
      "model management"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript SDK for Node & browsers; same features as the Python client.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "npm package",
      "TypeScript",
      "streaming responses",
      "browser support"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/ollama",
    "summary": "LangChain integration for Ollama models; drop-in replacement for OpenAI in chains, agents, RAG, etc.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "PyPI: langchain-ollama",
      "chat & embed",
      "tool-calling",
      "RAG ready"
    ]
  },
  {
    "title": "ollama-webui (ollama-webui/ollama-webui)",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich web UI for Ollama (ChatGPT-style); supports multi-user, RAG, plugins, Docker one-liner.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "Docker",
      "RAG uploads",
      "Dark/light themes",
      "Admin panel",
      "OpenAI-compat API"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java/Kotlin client for Ollama; streaming, chat, embeddings, model ops, Android compatible.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "Maven Central",
      "Android support",
      "Kotlin coroutines",
      "embeddings"
    ]
  },
  {
    "title": "ollama-cli (sugarforever/ollama-cli)",
    "url": "https://github.com/sugarforever/ollama-cli",
    "summary": "Interactive CLI REPL with syntax highlighting, conversation history, and markdown rendering.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "REPL",
      "history",
      "syntax highlight",
      "pip installable"
    ]
  },
  {
    "title": "ollama-copilot.nvim",
    "url": "https://github.com/zhongzhongzhongzhong/ollama-copilot.nvim",
    "summary": "Neovim plugin that turns Ollama models into a GitHub-Copilot-style code-completion engine.",
    "source": "github",
    "date": "2024-05-04",
    "highlights": [
      "Neovim",
      "inline completions",
      "fim templates",
      "lazy.nvim ready"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/otwld/ollama-helm",
    "summary": "Production-ready Helm chart for deploying Ollama on Kubernetes with GPU autoscaling.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "Helm",
      "GPU nodes",
      "PVC models",
      "Ingress",
      "Autoscaling"
    ]
  },
  {
    "title": "ollama-chat-telegram",
    "url": "https://github.com/ironman5366/ollama-telegram",
    "summary": "Self-hosted Telegram bot that chats with any Ollama model; supports groups, streaming, and sessions.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "Telegram bot",
      "group chats",
      "session memory",
      "Docker"
    ]
  },
  {
    "title": "ollama-rag",
    "url": "https://github.com/ivanfioravivi/ollama-rag",
    "summary": "Minimal RAG template using Ollama embeddings + Chroma + Streamlit; ready for PDF uploads.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "RAG",
      "ChromaDB",
      "Streamlit",
      "PDF ingestion",
      "Docker"
    ]
  },
  {
    "title": "ollama-cookbook",
    "url": "https://github.com/ollama/ollama-cookbook",
    "summary": "Community recipes: FastAPI backend, Next.js chat, Flutter app, model fine-tune scripts, and more.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "FastAPI",
      "Next.js",
      "Flutter",
      "fine-tuning",
      "examples"
    ]
  },
  {
    "title": "ollama-discord",
    "url": "https://github.com/mxyng/ollama-discord",
    "summary": "Lightweight Discord bot that streams Ollama replies into any channel with slash commands.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "Discord.py",
      "slash commands",
      "streaming",
      "Docker"
    ]
  },
  {
    "title": "ollama-dagger",
    "url": "https://github.com/shykes/ollama-dagger",
    "summary": "Dagger module for CI pipelines: pull, test, and benchmark Ollama models inside any container.",
    "source": "github",
    "date": "2024-05-04",
    "highlights": [
      "Dagger",
      "CI/CD",
      "benchmarks",
      "container native"
    ]
  },
  {
    "title": "ollama-express",
    "url": "https://github.com/ollama-express/ollama-express",
    "summary": "Express.js starter that exposes an OpenAI-compatible REST endpoint backed by Ollama.",
    "source": "github",
    "date": "2024-05-03",
    "highlights": [
      "Express",
      "OpenAI-compat",
      "npm",
      "/v1/chat/completions"
    ]
  },
  {
    "title": "ollama-rust",
    "url": "https://github.com/pepperoni21/ollama-rust",
    "summary": "Async Rust crate for Ollama; generate, chat, pull, and delete models with Tokio.",
    "source": "github",
    "date": "2024-05-02",
    "highlights": [
      "crates.io",
      "async",
      "Tokio",
      "streaming"
    ]
  },
  {
    "title": "ollama-csharp",
    "url": "https://github.com/awaescher/ollama-csharp",
    "summary": ".NET client for Ollama with full chat, embeddings, and model management; includes Blazor demo.",
    "source": "github",
    "date": "2024-05-01",
    "highlights": [
      "NuGet",
      "Blazor sample",
      "streaming",
      "embeddings"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/ollama-haystack/ollama-haystack",
    "summary": "Haystack integration letting you use Ollama models as generators or embedders in pipelines.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "PyPI: ollama-haystack",
      "pipelines",
      "RAG",
      "embedders"
    ]
  },
  {
    "title": "ollama-sdks",
    "url": "https://github.com/ollama-community/ollama-sdks",
    "summary": "Community-maintained SDK index: Go, Ruby, PHP, Swift, Dart, Elixir, and more.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "Community",
      "multi-language",
      "index",
      "README badges"
    ]
  },
  {
    "title": "ollama-models",
    "url": "https://github.com/ollama/ollama/blob/main/docs/models.md",
    "summary": "Official registry of 100+ models (Llama-3, Phi-3, Mistral, Gemma, etc.) with one-line pull commands.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "Registry",
      "Llama-3",
      "Mistral",
      "Gemma",
      "Modelfile"
    ]
  }
]