[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: get up and running with Llama 3, Mistral, Gemma, and other large language models locally.",
    "source": "github",
    "date": "2024-05-02",
    "highlights": [
      "CLI + REST API",
      "macOS/Linux/Windows",
      "Model library (Llama 3, Phi-3, Gemma, \u2026)"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python SDK for Ollama; chat, generate, embed, pull models with a few lines of code.",
    "source": "github",
    "date": "2024-04-30",
    "highlights": [
      "pip install ollama",
      "sync & async clients",
      "embedding support"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Node and browsers; same API surface as Python SDK.",
    "source": "github",
    "date": "2024-04-29",
    "highlights": [
      "npm install ollama",
      "TypeScript types",
      "streaming responses"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/ollama",
    "summary": "LangChain integration package letting you swap Ollama models into any LangChain pipeline.",
    "source": "github",
    "date": "2024-04-28",
    "highlights": [
      "pip install langchain-ollama",
      "LLM & chat wrappers",
      "tool-calling support"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich chat WebUI for Ollama (formerly Ollama-WebUI); folders, sharing, multimodal, RAG.",
    "source": "github",
    "date": "2024-05-01",
    "highlights": [
      "Docker one-liner",
      "Open-WebUI rebrand",
      "rag & voice input"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java/Kotlin client for Ollama; fluent API, streaming, embeddings, model management.",
    "source": "github",
    "date": "2024-04-25",
    "highlights": [
      "Maven Central",
      "Android friendly",
      "Kotlin coroutines"
    ]
  },
  {
    "title": "ollama-rust",
    "url": "https://github.com/pepperoni21/ollama-rust",
    "summary": "Community Rust crate that wraps the Ollama REST API with strongly typed models.",
    "source": "github",
    "date": "2024-04-20",
    "highlights": [
      "tokio/async",
      "cargo add ollama-rs",
      "examples included"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama/ollama-copilot",
    "summary": "VS Code extension that turns any Ollama model into a GitHub Copilot replacement inside the editor.",
    "source": "github",
    "date": "2024-04-27",
    "highlights": [
      "inline completions",
      "custom prompts",
      "local only"
    ]
  },
  {
    "title": "ollama-zsh",
    "url": "https://github.com/ollama/ollama-zsh",
    "summary": "Zsh plugin with completions and helper aliases for the ollama CLI.",
    "source": "github",
    "date": "2024-04-18",
    "highlights": [
      "tab completion",
      "git-info style prompt",
      "oh-my-zsh compatible"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/ollama/helm",
    "summary": "Helm chart to deploy Ollama in Kubernetes with GPU autoscaling and PVC model cache.",
    "source": "github",
    "date": "2024-04-26",
    "highlights": [
      "GPU node-selector",
      "model pre-load list",
      "ingress ready"
    ]
  },
  {
    "title": "ollama-docker",
    "url": "https://github.com/ollama/ollama/tree/main/docker",
    "summary": "Official container images (cpu & cuda) plus compose examples for Ollama server.",
    "source": "github",
    "date": "2024-04-30",
    "highlights": [
      "official image",
      "cuda tags",
      "compose examples"
    ]
  },
  {
    "title": "ollama-nix",
    "url": "https://github.com/NixOS/nixpkgs/tree/master/pkgs/tools/misc/ollama",
    "summary": "Nix derivation for Ollama server and CLI; pinned builds with CUDA support.",
    "source": "github",
    "date": "2024-04-22",
    "highlights": [
      "nixpkgs upstream",
      "cuda override",
      "systemd service"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/deepset-ai/haystack-integrations/tree/main/integrations/ollama",
    "summary": "Haystack integration to use Ollama models as generators or embedders in Haystack pipelines.",
    "source": "github",
    "date": "2024-04-24",
    "highlights": [
      "pip install haystack-ai[ollama]",
      "RAG ready",
      "embedding provider"
    ]
  },
  {
    "title": "ollama-cli-chat",
    "url": "https://github.com/jmorganca/ollama-cli-chat",
    "summary": "Terminal UI chat client with markdown, history, and multi-model sessions.",
    "source": "github",
    "date": "2024-04-21",
    "highlights": [
      "rich markdown",
      "session save/load",
      "keybinding friendly"
    ]
  },
  {
    "title": "ollama-gui",
    "url": "https://github.com/ollama/ollama-gui",
    "summary": "Lightweight Tauri desktop app for chatting with Ollama models; cross-platform binary.",
    "source": "github",
    "date": "2024-04-23",
    "highlights": [
      "Rust + React",
      "single binary",
      "dark/light themes"
    ]
  },
  {
    "title": "ollama-streamlit",
    "url": "https://github.com/streamlit/ollama-streamlit",
    "summary": "Streamlit chat component that proxies to Ollama; drop-in for data apps.",
    "source": "github",
    "date": "2024-04-19",
    "highlights": [
      "pip install streamlit-ollama",
      "chat widget",
      "session state"
    ]
  },
  {
    "title": "ollama-obsidian",
    "url": "https://github.com/ollama/obsidian-ollama",
    "summary": "Obsidian plugin that lets you query local Ollama models from within your notes.",
    "source": "github",
    "date": "2024-04-17",
    "highlights": [
      "command palette",
      "template variables",
      "completely local"
    ]
  },
  {
    "title": "ollama-rag",
    "url": "https://github.com/ollama/ollama-rag",
    "summary": "Minimal RAG template using Ollama + ChromaDB + LangChain to chat with your documents.",
    "source": "github",
    "date": "2024-04-16",
    "highlights": [
      "docker compose",
      "pdf loader",
      "embeddings cached"
    ]
  },
  {
    "title": "ollama-discord",
    "url": "https://github.com/ollama/discord-bot",
    "summary": "Self-hosted Discord bot that answers questions using any Ollama model.",
    "source": "github",
    "date": "2024-04-15",
    "highlights": [
      "slash commands",
      "thread support",
      "guild config"
    ]
  },
  {
    "title": "ollama-minecraft",
    "url": "https://github.com/ollama/minecraft-ollama",
    "summary": "Spigot plugin that adds an in-game NPC powered by a local Ollama model.",
    "source": "github",
    "date": "2024-04-14",
    "highlights": [
      "NPC chat",
      "/ollama command",
      "offline capable"
    ]
  }
]