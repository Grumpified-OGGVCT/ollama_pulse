[
  {
    "title": "Ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Get up and running with Llama 3.3, Mistral, Gemma 2, and other large language models locally.",
    "source": "github",
    "date": "2024-12-19",
    "highlights": [
      "self-hosted LLM runner",
      "Docker-like CLI",
      "macOS/Linux/Windows"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Ollama.",
    "source": "github",
    "date": "2024-12-19",
    "highlights": [
      "npm package",
      "Promise-based API",
      "full TypeScript defs"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client for Ollama.",
    "source": "github",
    "date": "2024-12-19",
    "highlights": [
      "PyPI package",
      "sync/async APIs",
      "streaming support"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/partners/ollama",
    "summary": "LangChain integration to use Ollama models as LLMs and embeddings.",
    "source": "github",
    "date": "2024-12-19",
    "highlights": [
      "pip install langchain-ollama",
      "chat & embed",
      "community provider"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "ChatGPT-style web UI to interact with Ollama models (now renamed Open WebUI).",
    "source": "github",
    "date": "2024-12-19",
    "highlights": [
      "self-hosted UI",
      "Docker image",
      "multi-user, RAG, plugins"
    ]
  },
  {
    "title": "open-webui",
    "url": "https://github.com/open-webui/open-webui",
    "summary": "Former ollama-webui; feature-rich WebUI for Ollama and OpenAI-compatible APIs.",
    "source": "github",
    "date": "2024-12-19",
    "highlights": [
      "RAG pipelines",
      "admin panel",
      "extensive plugin system"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/technomancy/ollama-cli",
    "summary": "Simple Ruby CLI wrapper around Ollama HTTP API.",
    "source": "github",
    "date": "2024-12-19",
    "highlights": [
      "Ruby gem",
      "REPL mode",
      "prompt templates"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/fcsonline/ollama-copilot",
    "summary": "GitHub Copilot-like VS Code extension that uses local Ollama models.",
    "source": "github",
    "date": "2024-12-19",
    "highlights": [
      "VS Code extension",
      "inline completions",
      "configurable model"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/otwld/ollama-helm",
    "summary": "Helm chart to deploy Ollama on Kubernetes clusters.",
    "source": "github",
    "date": "2024-12-19",
    "highlights": [
      "Kubernetes manifests",
      "GPU node support",
      "persistent volumes"
    ]
  },
  {
    "title": "ollama-compose",
    "url": "https://github.com/valiantlynx/ollama-compose",
    "summary": "Docker-Compose stack bundling Ollama, Open WebUI, and optional NVIDIA GPU support.",
    "source": "github",
    "date": "2024-12-19",
    "highlights": [
      "one-command spin-up",
      "GPU passthrough",
      "includes WebUI"
    ]
  },
  {
    "title": "ollama-rag",
    "url": "https://github.com/ivanfioravici/ollama-rag",
    "summary": "Minimal retrieval-augmented generation example using Ollama + ChromaDB.",
    "source": "github",
    "date": "2024-12-19",
    "highlights": [
      "Python notebook",
      "Chroma vector store",
      "PDF ingestion"
    ]
  },
  {
    "title": "ollama-rs",
    "url": "https://github.com/pepperoni21/ollama-rs",
    "summary": "Community Rust crate for interacting with the Ollama HTTP API.",
    "source": "github",
    "date": "2024-12-19",
    "highlights": [
      "crates.io",
      "async/tokio",
      "streaming responses"
    ]
  },
  {
    "title": "ollama-go",
    "url": "https://github.com/jmorganca/ollama-go",
    "summary": "Unofficial Go client library for Ollama (archived, community superseded).",
    "source": "github",
    "date": "2024-12-19",
    "highlights": [
      "Go mod",
      "simple API wrapper",
      "archived reference"
    ]
  },
  {
    "title": "ollama-discord",
    "url": "https://github.com/jeffrey-zhao/ollama-discord",
    "summary": "Discord bot that streams responses from local Ollama models.",
    "source": "github",
    "date": "2024-12-19",
    "highlights": [
      "slash commands",
      "streaming replies",
      "Docker image"
    ]
  },
  {
    "title": "ollama-nix",
    "url": "https://github.com/NixOS/nixpkgs/tree/master/pkgs/tools/misc/ollama",
    "summary": "Nix package derivation for installing Ollama on NixOS.",
    "source": "github",
    "date": "2024-12-19",
    "highlights": [
      "declarative install",
      "CUDA support",
      "NixOS service module"
    ]
  },
  {
    "title": "ollama-slack",
    "url": "https://github.com/roychri/ollama-slack",
    "summary": "Slack bot integration that queries local Ollama models.",
    "source": "github",
    "date": "2024-12-19",
    "highlights": [
      "Bolt framework",
      "threading support",
      "easy env config"
    ]
  },
  {
    "title": "ollama-dagger",
    "url": "https://github.com/dagger/dagger/tree/main/pkg/ollama",
    "summary": "Dagger module to spin up Ollama containers in CI pipelines.",
    "source": "github",
    "date": "2024-12-19",
    "highlights": [
      "CUE SDK",
      "CI caching",
      "on-demand models"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/deepset-ai/haystack-integrations/tree/main/integrations/ollama",
    "summary": "Haystack integration to use Ollama models as generators in NLP pipelines.",
    "source": "github",
    "date": "2024-12-19",
    "highlights": [
      "pip install farm-haystack[ollama]",
      "generator & embedder",
      "Haystack 2.x ready"
    ]
  },
  {
    "title": "ollama-cookbook",
    "url": "https://github.com/ollama/ollama-cookbook",
    "summary": "Community recipes and examples for using Ollama in various scenarios.",
    "source": "github",
    "date": "2024-12-19",
    "highlights": [
      "Jupyter notebooks",
      "RAG samples",
      "function-calling demos"
    ]
  },
  {
    "title": "ollama-vscode",
    "url": "https://github.com/lfberlanga/ollama-vscode",
    "summary": "VS Code extension to chat with Ollama models inside the editor sidebar.",
    "source": "github",
    "date": "2024-12-19",
    "highlights": [
      "side-panel chat",
      "custom prompts",
      "multi-model switch"
    ]
  }
]