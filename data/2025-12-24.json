[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: lightweight, extensible framework for running Llama 2, Mistral, Gemma and other LLMs locally with a single CLI or REST API.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "self-contained binary",
      "Docker image",
      "model library",
      "OpenAI-compatible endpoints"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python SDK for Ollama: chat, generate, embed, pull, list and delete models with a few lines of code.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "pip install ollama",
      "async support",
      "streaming responses",
      "embedding helpers"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript / TypeScript client for Node and browsers; same API surface as the Python SDK.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "npm i ollama",
      "TypeScript types",
      "streaming fetch",
      "browser compatible"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://python.langchain.com/docs/integrations/llms/ollama",
    "summary": "LangChain integration: use any Ollama model as an LLM or chat component inside LangChain pipelines.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "pip install langchain-ollama",
      "chat model wrapper",
      "callback streaming",
      "tool calling"
    ]
  },
  {
    "title": "ollama-webui (ollama-webui/ollama-webui)",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich, self-hosted web UI for Ollama: chat, manage models, multi-user, dark mode, mobile friendly.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "Docker one-liner",
      "OpenAI-compatible API proxy",
      "RAG uploads",
      "role-based auth"
    ]
  },
  {
    "title": "ollama-cli-copilot",
    "url": "https://github.com/sugarforever/ollama-cli-copilot",
    "summary": "Copilot-style CLI that wraps Ollama for inline code suggestions and shell completions.",
    "source": "github",
    "date": "2024-04-30",
    "highlights": [
      "bash/zsh/fish",
      "inline diff",
      "configurable shortcuts",
      "git diff context"
    ]
  },
  {
    "title": "chatdoll-ollama",
    "url": "https://github.com/uezo/chatdoll-ollama",
    "summary": "3D anime avatar chat UI that streams Ollama responses with lip-sync and expressions.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "Unity WebGL export",
      "WebRTC voice",
      "emotion tags",
      "Docker compose"
    ]
  },
  {
    "title": "ollama-rag",
    "url": "https://github.com/ollama/ollama-rag",
    "summary": "Minimal RAG example using Ollama embeddings + Chroma vector DB + Streamlit UI.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "PDF ingestion",
      "streaming answers",
      "Dockerfile",
      "pip requirements"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java / Kotlin client for Ollama with synchronous, asynchronous and reactive APIs.",
    "source": "github",
    "date": "2024-05-04",
    "highlights": [
      "Maven Central",
      "Spring Boot starter",
      "Kotlin coroutines",
      "model management"
    ]
  },
  {
    "title": "ollama-copilot.nvim",
    "url": "https://github.com/zbirenbaum/ollama-copilot.nvim",
    "summary": "Neovim plugin that brings Ollama-powered code completion, inline chat and refactoring.",
    "source": "github",
    "date": "2024-05-03",
    "highlights": [
      "lazy.nvim ready",
      "streaming insert",
      "selection explain",
      "custom prompts"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/ollama/haystack",
    "summary": "Haystack integration: use Ollama models as generators or embedders in Haystack pipelines.",
    "source": "github",
    "date": "2024-05-02",
    "highlights": [
      "pip install ollama-haystack",
      "prompt node",
      "embedding node",
      "batch support"
    ]
  },
  {
    "title": "ollama-cookbook",
    "url": "https://github.com/ollama/ollama-cookbook",
    "summary": "Community cookbook with 30+ recipes: PDF chat, voice bots, function calling, fine-tuning, etc.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "Jupyter notebooks",
      "step-by-step",
      "Docker setups",
      "community PRs"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/ollama/helm",
    "summary": "Official Helm chart for deploying Ollama on Kubernetes with GPU autoscaling and PVC support.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "GPU nodeSelector",
      "horizontal pod autoscaler",
      "persistent model cache",
      "ingress"
    ]
  },
  {
    "title": "ollama-gpt-cli",
    "url": "https://github.com/kieran/ollama-gpt-cli",
    "summary": "TUI chat client written in Go featuring markdown rendering, conversation history and themes.",
    "source": "github",
    "date": "2024-05-01",
    "highlights": [
      "single binary",
      "sqlite history",
      "solarized themes",
      "keyboard shortcuts"
    ]
  },
  {
    "title": "ollama-slack-bot",
    "url": "https://github.com/ollama-slack/ollama-slack-bot",
    "summary": "Slack Bolt app that exposes Ollama as a slash-command and threaded chat bot.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "Socket Mode",
      "thread context",
      "app home",
      "rate limiting"
    ]
  }
]