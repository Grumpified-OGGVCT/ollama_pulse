[
  {
    "title": "Model: gpt-ossOpenAI‚Äôs open-weight models designed for powerful reasoning, agentic tasks, and versatile developer use cases.toolsthinkingcloud20b120b3.9MPulls5TagsUpdated3 weeks ago",
    "date": "2025-11-03T01:21:49.738080",
    "summary": "Ollama model available in library: gpt-ossOpenAI‚Äôs open-weight models designed for powerful reasoning, agentic tasks, and versatile developer use cases.toolsthinkingcloud20b120b3.9MPulls5TagsUpdated3 weeks ago",
    "url": "https://ollama.com/library/gpt-oss",
    "source": "ollama_models",
    "turbo_score": 0.7,
    "highlights": [
      "model registry",
      "ollama library"
    ]
  },
  {
    "title": "Model: qwen3-vlThe most powerful vision-language model in the Qwen model family to date.visioncloud2b4b8b30b32b235b64KPulls59TagsUpdated4 days ago",
    "date": "2025-11-03T01:21:49.738113",
    "summary": "Ollama model available in library: qwen3-vlThe most powerful vision-language model in the Qwen model family to date.visioncloud2b4b8b30b32b235b64KPulls59TagsUpdated4 days ago",
    "url": "https://ollama.com/library/qwen3-vl",
    "source": "ollama_models",
    "turbo_score": 0.7,
    "highlights": [
      "model registry",
      "ollama library"
    ]
  },
  {
    "title": "Model: deepseek-r1DeepSeek-R1 is a family of open reasoning models with performance approaching that of leading models, such as O3 and Gemini 2.5 Pro.toolsthinking1.5b7b8b14b32b70b671b69MPulls35TagsUpdated4 months ago",
    "date": "2025-11-03T01:21:49.738138",
    "summary": "Ollama model available in library: deepseek-r1DeepSeek-R1 is a family of open reasoning models with performance approaching that of leading models, such as O3 and Gemini 2.5 Pro.toolsthinking1.5b7b8b14b32b70b671b69MPulls35TagsUpdated4 months ago",
    "url": "https://ollama.com/library/deepseek-r1",
    "source": "ollama_models",
    "turbo_score": 0.7,
    "highlights": [
      "model registry",
      "ollama library"
    ]
  },
  {
    "title": "Model: qwen3-coderAlibaba's performant long context models for agentic and coding tasks.toolscloud30b480b597.8KPulls10TagsUpdated1 month ago",
    "date": "2025-11-03T01:21:49.738159",
    "summary": "Ollama model available in library: qwen3-coderAlibaba's performant long context models for agentic and coding tasks.toolscloud30b480b597.8KPulls10TagsUpdated1 month ago",
    "url": "https://ollama.com/library/qwen3-coder",
    "source": "ollama_models",
    "turbo_score": 0.7,
    "highlights": [
      "model registry",
      "ollama library"
    ]
  },
  {
    "title": "Model: gemma3The current, most capable model that runs on a single GPU.vision270m1b4b12b27b23.7MPulls26TagsUpdated2 months ago",
    "date": "2025-11-03T01:21:49.738182",
    "summary": "Ollama model available in library: gemma3The current, most capable model that runs on a single GPU.vision270m1b4b12b27b23.7MPulls26TagsUpdated2 months ago",
    "url": "https://ollama.com/library/gemma3",
    "source": "ollama_models",
    "turbo_score": 0.7,
    "highlights": [
      "model registry",
      "ollama library"
    ]
  },
  {
    "title": "Model: glm-4.6Advanced agentic, reasoning and coding capabilities.cloud14.2KPulls1TagUpdated2 weeks ago",
    "date": "2025-11-03T01:21:49.738204",
    "summary": "Ollama model available in library: glm-4.6Advanced agentic, reasoning and coding capabilities.cloud14.2KPulls1TagUpdated2 weeks ago",
    "url": "https://ollama.com/library/glm-4.6",
    "source": "ollama_models",
    "turbo_score": 0.7,
    "highlights": [
      "model registry",
      "ollama library"
    ]
  },
  {
    "title": "Model: embeddinggemmaEmbeddingGemma is a 300M parameter embedding model from Google.embedding300m119.4KPulls5TagsUpdated1 month ago",
    "date": "2025-11-03T01:21:49.738224",
    "summary": "Ollama model available in library: embeddinggemmaEmbeddingGemma is a 300M parameter embedding model from Google.embedding300m119.4KPulls5TagsUpdated1 month ago",
    "url": "https://ollama.com/library/embeddinggemma",
    "source": "ollama_models",
    "turbo_score": 0.7,
    "highlights": [
      "model registry",
      "ollama library"
    ]
  },
  {
    "title": "Model: qwen3Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models.toolsthinking0.6b1.7b4b8b14b30b32b235b12.2MPulls58TagsUpdated3 weeks ago",
    "date": "2025-11-03T01:21:49.738252",
    "summary": "Ollama model available in library: qwen3Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models.toolsthinking0.6b1.7b4b8b14b30b32b235b12.2MPulls58TagsUpdated3 weeks ago",
    "url": "https://ollama.com/library/qwen3",
    "source": "ollama_models",
    "turbo_score": 0.7,
    "highlights": [
      "model registry",
      "ollama library"
    ]
  },
  {
    "title": "Model: deepseek-v3.1DeepSeek-V3.1-Terminus is a hybrid model that supports both thinking mode and non-thinking mode.toolsthinkingcloud671b126.6KPulls8TagsUpdated1 month ago",
    "date": "2025-11-03T01:21:49.738273",
    "summary": "Ollama model available in library: deepseek-v3.1DeepSeek-V3.1-Terminus is a hybrid model that supports both thinking mode and non-thinking mode.toolsthinkingcloud671b126.6KPulls8TagsUpdated1 month ago",
    "url": "https://ollama.com/library/deepseek-v3.1",
    "source": "ollama_models",
    "turbo_score": 0.7,
    "highlights": [
      "model registry",
      "ollama library"
    ]
  },
  {
    "title": "Model: llama3.1Llama 3.1 is a new state-of-the-art model from Meta available in 8B, 70B and 405B parameter sizes.tools8b70b405b105.3MPulls93TagsUpdated11 months ago",
    "date": "2025-11-03T01:21:49.738295",
    "summary": "Ollama model available in library: llama3.1Llama 3.1 is a new state-of-the-art model from Meta available in 8B, 70B and 405B parameter sizes.tools8b70b405b105.3MPulls93TagsUpdated11 months ago",
    "url": "https://ollama.com/library/llama3.1",
    "source": "ollama_models",
    "turbo_score": 0.7,
    "highlights": [
      "model registry",
      "ollama library"
    ]
  },
  {
    "title": "Model: nomic-embed-textA high-performing open embedding model with a large token context window.embedding44.7MPulls3TagsUpdated1 year ago",
    "date": "2025-11-03T01:21:49.738314",
    "summary": "Ollama model available in library: nomic-embed-textA high-performing open embedding model with a large token context window.embedding44.7MPulls3TagsUpdated1 year ago",
    "url": "https://ollama.com/library/nomic-embed-text",
    "source": "ollama_models",
    "turbo_score": 0.7,
    "highlights": [
      "model registry",
      "ollama library"
    ]
  },
  {
    "title": "Model: llama3.2Meta's Llama 3.2 goes small with 1B and 3B models.tools1b3b43.3MPulls63TagsUpdated1 year ago",
    "date": "2025-11-03T01:21:49.738334",
    "summary": "Ollama model available in library: llama3.2Meta's Llama 3.2 goes small with 1B and 3B models.tools1b3b43.3MPulls63TagsUpdated1 year ago",
    "url": "https://ollama.com/library/llama3.2",
    "source": "ollama_models",
    "turbo_score": 0.7,
    "highlights": [
      "model registry",
      "ollama library"
    ]
  },
  {
    "title": "Model: mistralThe 7B model released by Mistral AI, updated to version 0.3.tools7b21.5MPulls84TagsUpdated3 months ago",
    "date": "2025-11-03T01:21:49.738353",
    "summary": "Ollama model available in library: mistralThe 7B model released by Mistral AI, updated to version 0.3.tools7b21.5MPulls84TagsUpdated3 months ago",
    "url": "https://ollama.com/library/mistral",
    "source": "ollama_models",
    "turbo_score": 0.7,
    "highlights": [
      "model registry",
      "ollama library"
    ]
  },
  {
    "title": "Model: qwen2.5Qwen2.5 models are pretrained on Alibaba's latest large-scale dataset, encompassing up to 18 trillion tokens. The model supports up to 128K tokens and has multilingual support.tools0.5b1.5b3b7b14b32b72b16MPulls133TagsUpdated1 year ago",
    "date": "2025-11-03T01:21:49.738375",
    "summary": "Ollama model available in library: qwen2.5Qwen2.5 models are pretrained on Alibaba's latest large-scale dataset, encompassing up to 18 trillion tokens. The model supports up to 128K tokens and has multilingual support.tools0.5b1.5b3b7b14b32b72b16MPulls133TagsUpdated1 year ago",
    "url": "https://ollama.com/library/qwen2.5",
    "source": "ollama_models",
    "turbo_score": 0.7,
    "highlights": [
      "model registry",
      "ollama library"
    ]
  },
  {
    "title": "Model: phi3Phi-3 is a family of lightweight 3B (Mini) and 14B (Medium) state-of-the-art open models by Microsoft.3.8b14b12.8MPulls72TagsUpdated1 year ago",
    "date": "2025-11-03T01:21:49.738393",
    "summary": "Ollama model available in library: phi3Phi-3 is a family of lightweight 3B (Mini) and 14B (Medium) state-of-the-art open models by Microsoft.3.8b14b12.8MPulls72TagsUpdated1 year ago",
    "url": "https://ollama.com/library/phi3",
    "source": "ollama_models",
    "turbo_score": 0.7,
    "highlights": [
      "model registry",
      "ollama library"
    ]
  },
  {
    "title": "Model: llama3Meta Llama 3: The most capable openly available LLM to date8b70b11.6MPulls68TagsUpdated1 year ago",
    "date": "2025-11-03T01:21:49.738414",
    "summary": "Ollama model available in library: llama3Meta Llama 3: The most capable openly available LLM to date8b70b11.6MPulls68TagsUpdated1 year ago",
    "url": "https://ollama.com/library/llama3",
    "source": "ollama_models",
    "turbo_score": 0.7,
    "highlights": [
      "model registry",
      "ollama library"
    ]
  },
  {
    "title": "Model: llavaüåã LLaVA is a novel end-to-end trained large multimodal model that combines a vision encoder and Vicuna for general-purpose visual and language understanding. Updated to version 1.6.vision7b13b34b11.2MPulls98TagsUpdated1 year ago",
    "date": "2025-11-03T01:21:49.738435",
    "summary": "Ollama model available in library: llavaüåã LLaVA is a novel end-to-end trained large multimodal model that combines a vision encoder and Vicuna for general-purpose visual and language understanding. Updated to version 1.6.vision7b13b34b11.2MPulls98TagsUpdated1 year ago",
    "url": "https://ollama.com/library/llava",
    "source": "ollama_models",
    "turbo_score": 0.7,
    "highlights": [
      "model registry",
      "ollama library"
    ]
  },
  {
    "title": "Model: gemma2Google Gemma 2 is a high-performing and efficient model available in three sizes: 2B, 9B, and 27B.2b9b27b8.7MPulls94TagsUpdated1 year ago",
    "date": "2025-11-03T01:21:49.738455",
    "summary": "Ollama model available in library: gemma2Google Gemma 2 is a high-performing and efficient model available in three sizes: 2B, 9B, and 27B.2b9b27b8.7MPulls94TagsUpdated1 year ago",
    "url": "https://ollama.com/library/gemma2",
    "source": "ollama_models",
    "turbo_score": 0.7,
    "highlights": [
      "model registry",
      "ollama library"
    ]
  },
  {
    "title": "Model: qwen2.5-coderThe latest series of Code-Specific Qwen models, with significant improvements in code generation, code reasoning, and code fixing.tools0.5b1.5b3b7b14b32b8MPulls199TagsUpdated5 months ago",
    "date": "2025-11-03T01:21:49.738477",
    "summary": "Ollama model available in library: qwen2.5-coderThe latest series of Code-Specific Qwen models, with significant improvements in code generation, code reasoning, and code fixing.tools0.5b1.5b3b7b14b32b8MPulls199TagsUpdated5 months ago",
    "url": "https://ollama.com/library/qwen2.5-coder",
    "source": "ollama_models",
    "turbo_score": 0.7,
    "highlights": [
      "model registry",
      "ollama library"
    ]
  },
  {
    "title": "Model: phi4Phi-4 is a 14B parameter, state-of-the-art open model from Microsoft.14b5.9MPulls5TagsUpdated9 months ago",
    "date": "2025-11-03T01:21:49.738494",
    "summary": "Ollama model available in library: phi4Phi-4 is a 14B parameter, state-of-the-art open model from Microsoft.14b5.9MPulls5TagsUpdated9 months ago",
    "url": "https://ollama.com/library/phi4",
    "source": "ollama_models",
    "turbo_score": 0.7,
    "highlights": [
      "model registry",
      "ollama library"
    ]
  },
  {
    "title": "Model: gemmaGemma is a family of lightweight, state-of-the-art open models built by Google DeepMind. Updated to version 1.12b7b5.4MPulls102TagsUpdated1 year ago",
    "date": "2025-11-03T01:21:49.738515",
    "summary": "Ollama model available in library: gemmaGemma is a family of lightweight, state-of-the-art open models built by Google DeepMind. Updated to version 1.12b7b5.4MPulls102TagsUpdated1 year ago",
    "url": "https://ollama.com/library/gemma",
    "source": "ollama_models",
    "turbo_score": 0.7,
    "highlights": [
      "model registry",
      "ollama library"
    ]
  },
  {
    "title": "Model: mxbai-embed-largeState-of-the-art large embedding model from mixedbread.aiembedding335m5.2MPulls4TagsUpdated1 year ago",
    "date": "2025-11-03T01:21:49.738533",
    "summary": "Ollama model available in library: mxbai-embed-largeState-of-the-art large embedding model from mixedbread.aiembedding335m5.2MPulls4TagsUpdated1 year ago",
    "url": "https://ollama.com/library/mxbai-embed-large",
    "source": "ollama_models",
    "turbo_score": 0.7,
    "highlights": [
      "model registry",
      "ollama library"
    ]
  },
  {
    "title": "Model: qwenQwen 1.5 is a series of large language models by Alibaba Cloud spanning from 0.5B to 110B parameters0.5b1.8b4b7b14b32b72b110b5MPulls379TagsUpdated1 year ago",
    "date": "2025-11-03T01:21:49.738556",
    "summary": "Ollama model available in library: qwenQwen 1.5 is a series of large language models by Alibaba Cloud spanning from 0.5B to 110B parameters0.5b1.8b4b7b14b32b72b110b5MPulls379TagsUpdated1 year ago",
    "url": "https://ollama.com/library/qwen",
    "source": "ollama_models",
    "turbo_score": 0.7,
    "highlights": [
      "model registry",
      "ollama library"
    ]
  },
  {
    "title": "Model: llama2Llama 2 is a collection of foundation language models ranging from 7B to 70B parameters.7b13b70b4.4MPulls102TagsUpdated1 year ago",
    "date": "2025-11-03T01:21:49.738575",
    "summary": "Ollama model available in library: llama2Llama 2 is a collection of foundation language models ranging from 7B to 70B parameters.7b13b70b4.4MPulls102TagsUpdated1 year ago",
    "url": "https://ollama.com/library/llama2",
    "source": "ollama_models",
    "turbo_score": 0.7,
    "highlights": [
      "model registry",
      "ollama library"
    ]
  },
  {
    "title": "Model: qwen2Qwen2 is a new series of large language models from Alibaba grouptools0.5b1.5b7b72b4.4MPulls97TagsUpdated1 year ago",
    "date": "2025-11-03T01:21:49.738595",
    "summary": "Ollama model available in library: qwen2Qwen2 is a new series of large language models from Alibaba grouptools0.5b1.5b7b72b4.4MPulls97TagsUpdated1 year ago",
    "url": "https://ollama.com/library/qwen2",
    "source": "ollama_models",
    "turbo_score": 0.7,
    "highlights": [
      "model registry",
      "ollama library"
    ]
  },
  {
    "title": "Model: minicpm-vA series of multimodal LLMs (MLLMs) designed for vision-language understanding.vision8b3.9MPulls17TagsUpdated11 months ago",
    "date": "2025-11-03T01:21:49.738613",
    "summary": "Ollama model available in library: minicpm-vA series of multimodal LLMs (MLLMs) designed for vision-language understanding.vision8b3.9MPulls17TagsUpdated11 months ago",
    "url": "https://ollama.com/library/minicpm-v",
    "source": "ollama_models",
    "turbo_score": 0.7,
    "highlights": [
      "model registry",
      "ollama library"
    ]
  },
  {
    "title": "Model: dolphin3Dolphin 3.0 Llama 3.1 8B üê¨ is the next generation of the Dolphin series of instruct-tuned models designed to be the ultimate general purpose local model, enabling coding, math, agentic, function calling, and general use cases.8b3.4MPulls5TagsUpdated10 months ago",
    "date": "2025-11-03T01:21:49.738631",
    "summary": "Ollama model available in library: dolphin3Dolphin 3.0 Llama 3.1 8B üê¨ is the next generation of the Dolphin series of instruct-tuned models designed to be the ultimate general purpose local model, enabling coding, math, agentic, function calling, and general use cases.8b3.4MPulls5TagsUpdated10 months ago",
    "url": "https://ollama.com/library/dolphin3",
    "source": "ollama_models",
    "turbo_score": 0.7,
    "highlights": [
      "model registry",
      "ollama library"
    ]
  },
  {
    "title": "Model: olmo2OLMo 2 is a new family of 7B and 13B models trained on up to 5T tokens. These models are on par with or better than equivalently sized fully open models, and competitive with open-weight models such as Llama 3.1 on English academic benchmarks.7b13b3.3MPulls9TagsUpdated9 months ago",
    "date": "2025-11-03T01:21:49.738650",
    "summary": "Ollama model available in library: olmo2OLMo 2 is a new family of 7B and 13B models trained on up to 5T tokens. These models are on par with or better than equivalently sized fully open models, and competitive with open-weight models such as Llama 3.1 on English academic benchmarks.7b13b3.3MPulls9TagsUpdated9 months ago",
    "url": "https://ollama.com/library/olmo2",
    "source": "ollama_models",
    "turbo_score": 0.7,
    "highlights": [
      "model registry",
      "ollama library"
    ]
  },
  {
    "title": "Model: codellamaA large language model that can use text prompts to generate and discuss code.7b13b34b70b3.3MPulls199TagsUpdated1 year ago",
    "date": "2025-11-03T01:21:49.738669",
    "summary": "Ollama model available in library: codellamaA large language model that can use text prompts to generate and discuss code.7b13b34b70b3.3MPulls199TagsUpdated1 year ago",
    "url": "https://ollama.com/library/codellama",
    "source": "ollama_models",
    "turbo_score": 0.7,
    "highlights": [
      "model registry",
      "ollama library"
    ]
  },
  {
    "title": "Model: tinyllamaThe TinyLlama project is an open endeavor to train a compact 1.1B Llama model on 3 trillion tokens.1.1b3.1MPulls36TagsUpdated1 year ago",
    "date": "2025-11-03T01:21:49.738687",
    "summary": "Ollama model available in library: tinyllamaThe TinyLlama project is an open endeavor to train a compact 1.1B Llama model on 3 trillion tokens.1.1b3.1MPulls36TagsUpdated1 year ago",
    "url": "https://ollama.com/library/tinyllama",
    "source": "ollama_models",
    "turbo_score": 0.7,
    "highlights": [
      "model registry",
      "ollama library"
    ]
  }
]