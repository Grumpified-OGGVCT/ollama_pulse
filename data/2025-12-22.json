[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Get up and running with Llama 3, Mistral, Gemma, and other large language models locally.",
    "source": "github",
    "date": "2024-05-20",
    "highlights": [
      "self-hosted LLM runtime",
      "bundles model weights",
      "simple CLI & REST API"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python SDK for Ollama. Install with pip install ollama.",
    "source": "github",
    "date": "2024-05-15",
    "highlights": [
      "official client",
      "async & sync APIs",
      "PyPI package"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript / TypeScript SDK for Ollama. npm install ollama.",
    "source": "github",
    "date": "2024-05-18",
    "highlights": [
      "npm package",
      "TypeScript support",
      "same API surface as Python"
    ]
  },
  {
    "title": "langchain-community/llms/ollama",
    "url": "https://python.langchain.com/docs/integrations/llms/ollama/",
    "summary": "LangChain integration to use any Ollama model as an LLM backend.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "LangChain LLM",
      "streaming support",
      "chat & embed endpoints"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "ChatGPT-style web UI for Ollama (now renamed Open WebUI).",
    "source": "github",
    "date": "2024-05-22",
    "highlights": [
      "full-featured UI",
      "RAG plugins",
      "multi-user support"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/llama-assistant/ollama-cli",
    "summary": "Terminal UI assistant powered by Ollama models.",
    "source": "github",
    "date": "2024-04-30",
    "highlights": [
      "rich TUI",
      "conversation history",
      "custom prompts"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java/Kotlin client library for Ollama.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "Java SDK",
      "Kotlin extensions",
      "Spring Boot starters"
    ]
  },
  {
    "title": "ollama-rag",
    "url": "https://github.com/tonykipkemboi/ollama-rag",
    "summary": "Minimal RAG template using Ollama + LangChain + Streamlit.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "PDF ingestion",
      "Chroma vector store",
      "Streamlit demo"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/danielgross/ollama-copilot",
    "summary": "GitHub Copilot-style VS Code extension backed by Ollama.",
    "source": "github",
    "date": "2024-05-19",
    "highlights": [
      "inline completions",
      "local model",
      "open-source copilot"
    ]
  },
  {
    "title": "ollama-nvidia-nim-bridge",
    "url": "https://github.com/NVIDIA/nim-anywhere/tree/main/ollama-bridge",
    "summary": "Bridge to expose Ollama models through NVIDIA NIM microservices.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "NIM compatibility",
      "GPU optimization",
      "enterprise ready"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/deepset-ai/haystack-integrations/tree/main/integrations/ollama",
    "summary": "Haystack integration to use Ollama models in pipelines.",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "Haystack nodes",
      "generator & embedder",
      "pipeline YAML"
    ]
  },
  {
    "title": "ollama-discord-bot",
    "url": "https://github.com/mxyng/ollama-discord",
    "summary": "Discord bot that chats via any Ollama model.",
    "source": "github",
    "date": "2024-05-16",
    "highlights": [
      "slash commands",
      "threading",
      "model switching"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/otwld/ollama-helm",
    "summary": "Community-maintained Helm chart to deploy Ollama on Kubernetes.",
    "source": "github",
    "date": "2024-05-21",
    "highlights": [
      "GPU node selector",
      "PVC for models",
      "autoscaling"
    ]
  },
  {
    "title": "ollama-macos-menu",
    "url": "https://github.com/szh/ollama-menubar",
    "summary": "macOS menu-bar app to start/stop Ollama and switch models.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "SwiftUI",
      "native launcher",
      "model dropdown"
    ]
  },
  {
    "title": "ollama-django",
    "url": "https://github.com/areski/ollama-django",
    "summary": "Django app + REST endpoints to serve Ollama models.",
    "source": "github",
    "date": "2024-05-13",
    "highlights": [
      "Django admin",
      "API keys",
      "async tasks"
    ]
  },
  {
    "title": "ollama-rust",
    "url": "https://github.com/pepperoni21/ollama-rust",
    "summary": "Unofficial Rust crate for Ollama\u2019s REST API.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "async client",
      "Serde models",
      "crates.io"
    ]
  },
  {
    "title": "ollama-obsidian",
    "url": "https://github.com/hintergrund/obsidian-ollama",
    "summary": "Obsidian plugin to run local LLM summaries & completions via Ollama.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "vault Q&A",
      "note summarization",
      "offline"
    ]
  },
  {
    "title": "ollama-slack-bot",
    "url": "https://github.com/UncleTallest/ollama-slack-bot",
    "summary": "Slack Bolt app that answers channel mentions using Ollama.",
    "source": "github",
    "date": "2024-05-17",
    "highlights": [
      "socket mode",
      "threaded replies",
      "app manifest"
    ]
  },
  {
    "title": "ollama-n8n-node",
    "url": "https://github.com/ebrian/n8n-nodes-ollama",
    "summary": "Custom n8n node to call Ollama models in no-code workflows.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "credentials manager",
      "workflow templates",
      "npm package"
    ]
  },
  {
    "title": "ollama-elixir",
    "url": "https://github.com/mmulli/ollama_elixir",
    "summary": "Elixir wrapper for Ollama with GenServer and Phoenix LiveView examples.",
    "source": "github",
    "date": "2024-05-04",
    "highlights": [
      "Hex package",
      "LiveView component",
      "GenServer client"
    ]
  }
]