[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repository providing the CLI and server to run Llama 2, Mistral, Gemma, and other large language models locally with GPU/CPU acceleration.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "self-contained binary",
      "Docker image",
      "model library",
      "OpenAI-compatible API"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python SDK for Ollama: chat, generate, embed, pull, push, create models with a few lines of code.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "async/sync clients",
      "streaming responses",
      "Pydantic models",
      "PyPI: ollama"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Ollama; works in Node, Deno, Bun and browsers via fetch.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "npm: ollama",
      "Promise/async iterators",
      "TypeScript definitions",
      "browser support"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/partners/ollama",
    "summary": "LangChain integration for Ollama: chat, embeddings, tool-calling, structured output, and retrieval chains.",
    "source": "github",
    "date": "2024-05-13",
    "highlights": [
      "pip: langchain-ollama",
      "tool use",
      "JSON mode",
      "retrieval QA"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich web UI for Ollama (ChatGPT-style) with multi-user support, model management, RAG, and plugins.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "Docker image",
      "file upload/RAG",
      "voice input",
      "Dark/Light themes"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java/Kotlin client for Ollama offering synchronous & asynchronous APIs, streaming, and embedding support.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "Maven Central",
      "Kotlin coroutines",
      "streaming chat",
      "embeddings"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/sugarforever/ollama-cli",
    "summary": "Interactive CLI chat client for Ollama written in Go with conversation history and markdown rendering.",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "conversation context",
      "markdown output",
      "cross-platform binary"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama-copilot/ollama-copilot",
    "summary": "Turn any Ollama model into a GitHub Copilot-style code-completion backend for VS Code.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "VS Code extension",
      "inline completions",
      "custom model support"
    ]
  },
  {
    "title": "ollama-rag",
    "url": "https://github.com/ivanfioravanti/ollama-rag",
    "summary": "Ready-to-run RAG pipeline combining Ollama, ChromaDB, and LangChain for PDF Q&A.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "PDF ingestion",
      "ChromaDB vector store",
      "Gradio UI",
      "Docker compose"
    ]
  },
  {
    "title": "ollama-discord",
    "url": "https://github.com/mikegajda/ollama-discord",
    "summary": "Discord bot that lets servers chat with any Ollama model via slash commands.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "slash commands",
      "multi-model support",
      "Docker image"
    ]
  },
  {
    "title": "ollama-telegram",
    "url": "https://github.com/ruecat/ollama-telegram",
    "summary": "Telegram bot for Ollama with streaming replies, group chat support, and per-user model selection.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "streaming messages",
      "group support",
      "user quotas",
      "Docker"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/ollama-haystack/ollama-haystack",
    "summary": "Haystack integration by Ollama providing generators & embedders for end-to-end NLP pipelines.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "pip: ollama-haystack",
      "generator",
      "text embedder",
      "Haystack 2.x"
    ]
  },
  {
    "title": "ollama-nim",
    "url": "https://github.com/ITotalJustice/ollama-nim",
    "summary": "Nim wrapper for Ollama\u2019s REST API with async HTTP, streaming, and strong type support.",
    "source": "github",
    "date": "2024-05-04",
    "highlights": [
      "Nimble package",
      "asyncdispatch",
      "streaming chat",
      "full API coverage"
    ]
  },
  {
    "title": "ollama-rs",
    "url": "https://github.com/pepperoni21/ollama-rs",
    "summary": "Async Rust crate for Ollama with Tokio, streaming support, and ergonomic type-safe APIs.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "crates.io: ollama-rs",
      "Tokio runtime",
      "futures Stream",
      "fully typed"
    ]
  },
  {
    "title": "ollama-csharp",
    "url": "https://github.com/ollama-csharp/ollama-csharp",
    "summary": ".NET SDK for Ollama supporting chat, generation, embeddings, and streaming via HttpClient.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "NuGet: Ollama",
      ".NET 6+",
      "IAsyncEnumerable streaming",
      "dependency injection"
    ]
  },
  {
    "title": "ollama-dagger",
    "url": "https://github.com/shykes/ollama-dagger",
    "summary": "Dagger module to run Ollama containers as part of CI/CD pipelines for testing LLM-powered apps.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "Dagger Function",
      "container caching",
      "test harness",
      "GitHub Actions"
    ]
  },
  {
    "title": "ollama-rustico",
    "url": "https://github.com/ollama-rustico/ollama-rustico",
    "summary": "Lightweight Rust client for Ollama with minimal dependencies and built-in JSON parsing.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "zero-copy JSON",
      "ureq HTTP",
      "no async requirement",
      "single file"
    ]
  },
  {
    "title": "ollama-streamlit",
    "url": "https://github.com/ollama-streamlit/ollama-streamlit",
    "summary": "Streamlit chat component that connects to Ollama with session memory and model switching.",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "session state",
      "model dropdown",
      "streaming st.write",
      "pip install"
    ]
  },
  {
    "title": "ollama-kit",
    "url": "https://github.com/ollama-kit/ollama-kit",
    "summary": "Swift package for macOS/iOS apps to chat with Ollama models using native URLSession.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "Swift Package Manager",
      "async/await",
      "Combine publishers",
      "macOS/iOS"
    ]
  },
  {
    "title": "ollama-rag-chatbot",
    "url": "https://github.com/ggerganov/ollama-rag-chatbot",
    "summary": "Minimal RAG chatbot using Ollama, Sentence-Transformers, and FAISS for local document Q&A.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "FAISS index",
      "local embeddings",
      "Gradio UI",
      "single Python file"
    ]
  }
]