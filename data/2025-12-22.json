[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repository: get up and running with Llama 3, Mistral, Gemma, and other large language models locally.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "self-hosted LLM inference",
      "Docker images",
      "REST & CLI APIs",
      "macOS/Linux/Windows"
    ]
  },
  {
    "title": "langchain-ai/langchain (Ollama integration)",
    "url": "https://python.langchain.com/docs/integrations/llms/ollama",
    "summary": "LangChain Python library provides a drop-in Ollama LLM wrapper for building chains, agents, RAG pipelines.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "ChatOllama",
      " embeddings",
      " Retrieval QA",
      "Tool calling"
    ]
  },
  {
    "title": "ollama-js on npm",
    "url": "https://www.npmjs.com/package/ollama",
    "summary": "Official JavaScript/TypeScript client for Ollama; chat, generate, pull models, stream responses in Node & browsers.",
    "source": "npm",
    "date": "2024-05-09",
    "highlights": [
      "Promise & stream APIs",
      "ESM & CJS bundles",
      "type definitions"
    ]
  },
  {
    "title": "ollama-python on PyPI",
    "url": "https://pypi.org/project/ollama/",
    "summary": "Official Python client for Ollama; chat, generate, embed, list models with sync/async support.",
    "source": "pypi",
    "date": "2024-05-09",
    "highlights": [
      "asyncio support",
      "embeddings endpoint",
      "model management"
    ]
  },
  {
    "title": "ollama-webui/ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Open-source ChatGPT-style web interface for Ollama; markdown, code highlighting, model switching, multi-user.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "Docker image",
      "dark/light themes",
      "PWA",
      "role-play presets"
    ]
  },
  {
    "title": "jmorganca/ollama-ai (Unofficial Node SDK)",
    "url": "https://github.com/jmorganca/ollama-ai",
    "summary": "Lightweight community Node SDK for Ollama with TypeScript support and streaming helpers.",
    "source": "github",
    "date": "2024-04-25",
    "highlights": [
      "Generator-based streaming",
      "retry logic",
      "custom host config"
    ]
  },
  {
    "title": "ollama4j \u2013 Java Client",
    "url": "https://github.com/ollama4j/ollama4j",
    "summary": "Native Java / Kotlin SDK for Ollama; chat, generate, pull models, callbacks, async executors.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "Zero deps beyond OkHttp",
      "Kotlin coroutines",
      "Spring Boot starters"
    ]
  },
  {
    "title": "ollama-rust on crates.io",
    "url": "https://github.com/pepperoni21/ollama-rust",
    "summary": "Async Rust client for Ollama using reqwest; supports chat, generate, embeddings, model ops.",
    "source": "github",
    "date": "2024-05-01",
    "highlights": [
      "Tokio runtime",
      "Serde models",
      "examples"
    ]
  },
  {
    "title": "ollama-copilot.nvim",
    "url": "https://github.com/yetone/ollama-copilot.nvim",
    "summary": "Neovim plugin that turns Ollama models into a GitHub Copilot-like inline code assistant.",
    "source": "github",
    "date": "2024-04-30",
    "highlights": [
      "Inline completions",
      "FIM templates",
      "multi-model"
    ]
  },
  {
    "title": "ollama-chatbot (Flutter desktop/mobile)",
    "url": "https://github.com/ollama-chatbot/ollama-chatbot",
    "summary": "Cross-platform Flutter app that chats with local Ollama instances; supports voice input, theming.",
    "source": "github",
    "date": "2024-04-28",
    "highlights": [
      "iOS/Android/macOS/Windows/Linux",
      "local storage",
      "voice typing"
    ]
  },
  {
    "title": "ollama-workflows (GitHub Actions)",
    "url": "https://github.com/marketplace/actions/ollama-workflows",
    "summary": "GitHub Action to spin up Ollama service in CI for testing LLM-powered features.",
    "source": "github",
    "date": "2024-05-02",
    "highlights": [
      "Service container",
      "model caching",
      "matrix strategies"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/otwld/ollama-helm",
    "summary": "Community Helm chart for deploying Ollama on Kubernetes with GPU & PVC support.",
    "source": "github",
    "date": "2024-05-03",
    "highlights": [
      "GPU node-selector",
      "model persistence",
      "autoscaling"
    ]
  },
  {
    "title": "ollama-terraform",
    "url": "https://github.com/ollama-terraform/ollama-terraform",
    "summary": "Terraform module to provision Ollama on AWS EC2 with NVIDIA GPU autoscaling.",
    "source": "github",
    "date": "2024-04-27",
    "highlights": [
      "Deep Learning AMI",
      "CloudWatch logs",
      "spot instances"
    ]
  },
  {
    "title": "ollama-discord-bot",
    "url": "https://github.com/ollama-discord/ollama-discord-bot",
    "summary": "Self-host Discord bot that streams Ollama responses in threads; slash commands, moderation filters.",
    "source": "github",
    "date": "2024-05-04",
    "highlights": [
      "Streaming replies",
      "role-based access",
      "model hot-swap"
    ]
  },
  {
    "title": "ollama-slackbot",
    "url": "https://github.com/ollama-slack/ollama-slackbot",
    "summary": "Slack Bolt app that brings local LLMs into channels with DM support and context threading.",
    "source": "github",
    "date": "2024-04-29",
    "highlights": [
      "Socket-Mode",
      "app mentions",
      "conversation memory"
    ]
  },
  {
    "title": "ollama-models (HuggingFace \u2192 Ollama converter)",
    "url": "https://github.com/ollama-models/ollama-models",
    "summary": "Scripts to convert HuggingFace transformers into Ollama Modelfile format with GGUF quantization.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "Auto-quantize",
      "tokenizer patching",
      "CI validation"
    ]
  },
  {
    "title": "ollama-rag (Weaviate + LangChain template)",
    "url": "https://github.com/ollama-rag/ollama-rag",
    "summary": "Starter repo for building private RAG pipelines using Ollama embeddings & chat with Weaviate vector store.",
    "source": "github",
    "date": "2024-05-01",
    "highlights": [
      "Docker Compose",
      "PDF ingestion",
      "Gradio UI"
    ]
  },
  {
    "title": "ollama-function-calling",
    "url": "https://github.com/ollama-experts/ollama-function-calling",
    "summary": "Experimental proof-of-concept adding OpenAI-style function calling to any Ollama model via prompt engineering.",
    "source": "github",
    "date": "2024-04-26",
    "highlights": [
      "JSON schema",
      "parallel calls",
      "retry parser"
    ]
  },
  {
    "title": "ollama-datasets (synthetic data generator)",
    "url": "https://github.com/ollama-datasets/ollama-datasets",
    "summary": "CLI tool that uses Ollama to generate synthetic instruction datasets for fine-tuning other models.",
    "source": "github",
    "date": "2024-04-24",
    "highlights": [
      "Parquet export",
      "configurable prompts",
      "multi-turn"
    ]
  },
  {
    "title": "ollama-on-termux",
    "url": "https://github.com/ollama-on-termux/ollama-on-termux",
    "summary": "Guide and scripts to compile and run Ollama on Android devices inside Termux with CPU inference.",
    "source": "github",
    "date": "2024-04-23",
    "highlights": [
      "No-root",
      "LLaVA 7b runnable",
      "proot-distro"
    ]
  }
]