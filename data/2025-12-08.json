[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official CLI and Python/JS bindings for downloading, running & chatting with GGUF models locally.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "self-contained binary",
      "REST API",
      "model library pull/push"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "First-party Python client library exposing sync/async APIs to chat, generate, embed and manage models.",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "async/await",
      "streaming responses",
      "PyPI package"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Node & browsers with fetch-based streaming support.",
    "source": "github",
    "date": "2024-05-13",
    "highlights": [
      "npm package",
      "TypeScript types",
      "streaming chat"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/partners/ollama",
    "summary": "LangChain integration providing Ollama LLM, embeddings and tool-calling components.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "LLM interface",
      "embeddings",
      "tool calling"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich web UI (formerly Ollama WebUI) that plugs into the Ollama REST API for chat, models & settings.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "dark/light themes",
      "code highlighting",
      "modelfile editor"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java SDK for Ollama offering fluent builder APIs, streaming, and custom modelfile creation.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "Maven Central",
      "async streaming",
      "modelfile DSL"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/nileshtrivedi/ollama-rb",
    "summary": "Lightweight Ruby gem wrapping the Ollama REST API with ActiveModel-style interfaces.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "Ruby gem",
      "streaming",
      "Rails ready"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/saltyorg/ollama-cli",
    "summary": "Community Rust CLI that adds progress bars, batch prompts and YAML config to the Ollama workflow.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "Rust binary",
      "progress bars",
      "batch prompts"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/hieunc229/ollama-copilot",
    "summary": "VS Code extension turning Ollama models into inline GitHub Copilot-style code suggestions.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "VS Code",
      "inline completions",
      "configurable model"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/ollama-haystack/ollama-haystack",
    "summary": "Haystack integration by the community to use Ollama models as generators or embedders in Haystack pipelines.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "Haystack nodes",
      "embeddings",
      "pipelines"
    ]
  },
  {
    "title": "ollama-camunda",
    "url": "https://github.com/camunda-community-hub/ollama-camunda",
    "summary": "Community Camunda Connectors that invoke Ollama models inside BPMN processes for tasks like summarisation.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "Camunda 8",
      "BPMN",
      "outbound connector"
    ]
  },
  {
    "title": "ollama-docker",
    "url": "https://github.com/ollama/ollama/tree/main/docker",
    "summary": "Official Docker images (CPU & GPU) with multi-arch support and example compose stacks.",
    "source": "github",
    "date": "2024-05-13",
    "highlights": [
      "official image",
      "CUDA",
      "docker-compose"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/ollama/ollama-helm",
    "summary": "Community-maintained Helm chart for deploying Ollama on Kubernetes with GPU node-selector options.",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "Helm chart",
      "GPU nodes",
      "HPA"
    ]
  },
  {
    "title": "ollama-nix",
    "url": "https://github.com/NixOS/nixpkgs/tree/master/pkgs/tools/misc/ollama",
    "summary": "Nix derivation for Ollama allowing reproducible installs and declarative service configuration.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "NixOS module",
      "reproducible",
      "declarative"
    ]
  },
  {
    "title": "ollama-on-bentoml",
    "url": "https://github.com/bentoml/BentoOllama",
    "summary": "BentoML example packaging Ollama as a containerised micro-service with autoscaling and monitoring.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "BentoML",
      "micro-service",
      "autoscaling"
    ]
  },
  {
    "title": "ollama-qt",
    "url": "https://github.com/ollama-ui/ollama-qt",
    "summary": "Cross-platform Qt6 desktop GUI for Ollama with conversation history and model switching.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "Qt6",
      "desktop",
      "conversation history"
    ]
  },
  {
    "title": "ollama-telegram",
    "url": "https://github.com/rainzee/ollama-telegram",
    "summary": "Telegram bot that forwards messages to a local Ollama instance and streams replies back to users.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "Telegram bot",
      "streaming",
      "group chats"
    ]
  },
  {
    "title": "ollama-express",
    "url": "https://github.com/ollama-express/ollama-express",
    "summary": "Express.js starter repo adding JWT auth, rate-limiting and OpenAI-compatible endpoints atop Ollama.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "Express",
      "JWT auth",
      "OpenAI format"
    ]
  },
  {
    "title": "ollama-rag",
    "url": "https://github.com/ollama-rag/ollama-rag",
    "summary": "Minimal RAG template using Ollama embeddings + Chroma to chat with local PDFs without cloud deps.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "RAG",
      "Chroma",
      "PDF ingestion"
    ]
  },
  {
    "title": "ollama-discord",
    "url": "https://github.com/ollama-discord/ollama-discord",
    "summary": "Discord.py bot bringing Ollama models into servers with slash commands, context windows and per-user quotas.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "Discord.py",
      "slash commands",
      "user quotas"
    ]
  }
]