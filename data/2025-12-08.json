[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: get up and running with Llama 2, Mistral, Gemma, and other large language models locally.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "self-contained binary",
      "macOS/Linux/Windows",
      "Docker image",
      "REST API",
      "model library"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client for Ollama. Chat, generate, embed, pull, list, delete models with a few lines of code.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "pip install ollama",
      "sync/async APIs",
      "streaming support",
      "type hints"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript / TypeScript client for Node & browsers. Same API surface as the Python client.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "npm i ollama",
      "ESM & CommonJS",
      "typed",
      "streaming"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/partners/ollama",
    "summary": "LangChain integration package providing Ollama LLM, embed and chat wrappers.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "pip install langchain-ollama",
      "LLM, Chat, Embeddings",
      "tool calling",
      "RAG ready"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich web UI for Ollama (ChatGPT-style). Models manager, multi-user, RAG, open-source.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "Docker one-liner",
      "dark/light themes",
      "import docs/PDF",
      "voice input"
    ]
  },
  {
    "title": "ollama-webui-lite",
    "url": "https://github.com/ollama-webui/ollama-webui-lite",
    "summary": "Lightweight SvelteKit front-end that talks to local Ollama instance. Zero-config PWA.",
    "source": "github",
    "date": "2024-04-30",
    "highlights": [
      "<1 MB bundle",
      "PWA offline",
      "no backend",
      "responsive"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/ollama/ollama-cli",
    "summary": "Community Rust CLI for listing, pulling, deleting and chatting with Ollama models from the terminal.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "fuzzy finder",
      "conversation history",
      "themes",
      "cross-platform"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama/ollama-copilot",
    "summary": "VS Code extension that turns any Ollama model into a GitHub Copilot replacement.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "inline completions",
      "chat panel",
      "/explain",
      "/tests"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Unofficial Java SDK for Ollama. Generate, chat, pull, list, copy, delete models inside JVM apps.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "Maven Central",
      "reactive streams",
      "Spring Boot starter"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/ollama/ollama-rb",
    "summary": "Community Ruby gem wrapping the Ollama REST API. Supports streaming and custom modelfiles.",
    "source": "github",
    "date": "2024-05-04",
    "highlights": [
      "gem install ollama",
      "async HTTP",
      "modfile DSL"
    ]
  },
  {
    "title": "ollama-docker",
    "url": "https://github.com/ollama/ollama/tree/main/docker",
    "summary": "Official Docker images (CPU & GPU) and compose examples for running Ollama in containers.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "CUDA image",
      "rocm image",
      "compose with WebUI",
      "Kubernetes manifests"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/ollama/ollama-helm",
    "summary": "Community Helm chart to deploy Ollama on Kubernetes with GPU autoscaling and PVC support.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "GPU node-selector",
      "HPA",
      "ingress",
      "persistence"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/deepset-ai/haystack-integrations/tree/main/integrations/ollama",
    "summary": "Haystack integration providing OllamaGenerator and OllamaEmbedder pipelines for RAG workflows.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "pip install ollama-haystack",
      "RAG pipelines",
      "HuggingFace datasets"
    ]
  },
  {
    "title": "ollama-cookbook",
    "url": "https://github.com/ollama/ollama-cookbook",
    "summary": "Community cookbook with recipes for function-calling, vision, RAG, fine-tuning and more.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "function calling",
      "vision models",
      "RAG examples",
      "Modfile tips"
    ]
  },
  {
    "title": "ollama-gpt-cli",
    "url": "https://github.com/s-kostyaev/ollama-gpt-cli",
    "summary": "Terminal GPT wrapper written in Go that uses Ollama as the backend. Stores conversation history in SQLite.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "go install",
      "multi-line prompts",
      "history search",
      "markdown output"
    ]
  },
  {
    "title": "ollama-model-hub",
    "url": "https://github.com/ollama/ollama-model-hub",
    "summary": "Curated list of user-contributed Modfiles and quantized models (Phi-3, Llama-3, etc.) ready for ollama pull.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "Modfile templates",
      "quantization scripts",
      "GGUF links",
      "benchmarks"
    ]
  },
  {
    "title": "ollama.nvim",
    "url": "https://github.com/nomnivore/ollama.nvim",
    "summary": "Neovim plugin that brings Ollama chat and code generation directly into the editor via Lua.",
    "source": "github",
    "date": "2024-05-04",
    "highlights": [
      "lazy.nvim ready",
      "split or float",
      "selection \u2192 prompt",
      "telescope picker"
    ]
  },
  {
    "title": "ollama-discord",
    "url": "https://github.com/ollama/ollama-discord",
    "summary": "Self-hosted Discord bot that streams Ollama replies into any channel with slash commands.",
    "source": "github",
    "date": "2024-05-03",
    "highlights": [
      "slash commands",
      "streaming replies",
      "modelfile switch",
      "role gating"
    ]
  },
  {
    "title": "ollama-slack",
    "url": "https://github.com/ollama/ollama-slack",
    "summary": "Lightweight Slack bot using Socket-mode to answer questions with local Ollama models.",
    "source": "github",
    "date": "2024-05-02",
    "highlights": [
      "Bolt JS",
      "mention trigger",
      "threading",
      "emoji reaction"
    ]
  },
  {
    "title": "ollama-express",
    "url": "https://github.com/ollama/ollama-express",
    "summary": "Minimal Express.js starter that exposes a chat completion endpoint backed by Ollama for rapid prototyping.",
    "source": "github",
    "date": "2024-05-01",
    "highlights": [
      "OpenAI-compatible",
      "Dockerfile",
      "/v1/chat/completions",
      "CORS enabled"
    ]
  }
]