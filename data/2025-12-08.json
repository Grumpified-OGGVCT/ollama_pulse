[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: lightweight, extensible framework for running Llama 2, Code Llama and other LLMs locally with a simple CLI and REST API.",
    "source": "github",
    "date": "2023-10-30",
    "highlights": [
      "CLI",
      "REST API",
      "macOS/Linux/Windows",
      "Docker image",
      "Model library"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client for Ollama; pip-installable wrapper around the Ollama REST API with async support.",
    "source": "github",
    "date": "2023-10-25",
    "highlights": [
      "PyPI: ollama",
      "async/await",
      "chat & generate",
      "embeddings endpoint"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Node & browsers; published to npm as \u2018ollama\u2019.",
    "source": "github",
    "date": "2023-10-24",
    "highlights": [
      "npm: ollama",
      "TypeScript types",
      "streaming responses",
      "browser compatible"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/partners/ollama",
    "summary": "LangChain integration package letting you use Ollama models as LLMs, embedders or chat models inside LangChain pipelines.",
    "source": "github",
    "date": "2023-10-28",
    "highlights": [
      "pip: langchain-ollama",
      "chat model",
      "embeddings",
      "streaming"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich web UI for Ollama (ChatGPT-style interface) with multi-model chat, file uploads, markdown, dark mode.",
    "source": "github",
    "date": "2023-10-29",
    "highlights": [
      "Docker ready",
      "file upload",
      "conversation history",
      "admin panel"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/salty-flower/ollama-cli",
    "summary": "Rust-based interactive CLI for Ollama with syntax highlighting, conversation persistence and keybindings.",
    "source": "github",
    "date": "2023-10-22",
    "highlights": [
      "Rust binary",
      "REPL",
      "conversation save/load",
      "themes"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/fredrikhl/ollama-copilot",
    "summary": "VS Code extension that routes GitHub Copilot calls to a local Ollama model for private autocomplete and chat.",
    "source": "github",
    "date": "2023-10-21",
    "highlights": [
      "VS Code",
      "inline completions",
      "privacy",
      "configurable model"
    ]
  },
  {
    "title": "ollama-chatbot",
    "url": "https://github.com/jmorganca/ollama-chatbot",
    "summary": "Minimal React chatbot component that streams answers from Ollama; easy drop-in for Next.js apps.",
    "source": "github",
    "date": "2023-10-20",
    "highlights": [
      "React",
      "streaming",
      "Next.js example",
      "TypeScript"
    ]
  },
  {
    "title": "Ollama Discord bot",
    "url": "https://github.com/CooperCorona/ollama-discord",
    "summary": "Self-host Discord bot that answers prompts using any Ollama model with slash commands and thread support.",
    "source": "github",
    "date": "2023-10-19",
    "highlights": [
      "Discord.py",
      "slash commands",
      "threading",
      "model switch"
    ]
  },
  {
    "title": "ollama-rag",
    "url": "https://github.com/ggerganov/ollama-rag",
    "summary": "Simple retrieval-augmented generation stack using Ollama embeddings + Chroma vector DB for private document Q&A.",
    "source": "github",
    "date": "2023-10-18",
    "highlights": [
      "Chroma",
      "PDF ingestion",
      "embeddings",
      "Gradio UI"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java/Kotlin SDK for Ollama published to Maven Central; supports sync/async calls and streaming.",
    "source": "github",
    "date": "2023-10-17",
    "highlights": [
      "Maven Central",
      "Java/Kotlin",
      "async",
      "streaming"
    ]
  },
  {
    "title": "ollama-express",
    "url": "https://github.com/ollama-ecosystem/ollama-express",
    "summary": "Express.js starter that exposes REST endpoints for chat, embeddings and model management via Ollama.",
    "source": "github",
    "date": "2023-10-16",
    "highlights": [
      "Express",
      "REST",
      "swagger docs",
      "Docker"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/otwld/ollama-helm",
    "summary": "Helm chart for deploying Ollama on Kubernetes with GPU node selection and horizontal scaling.",
    "source": "github",
    "date": "2023-10-15",
    "highlights": [
      "Helm",
      "GPU nodes",
      "autoscaling",
      "persistent storage"
    ]
  },
  {
    "title": "ollama.nvim",
    "url": "https://github.com/nomnivore/ollama.nvim",
    "summary": "Neovim plugin to run and chat with Ollama models inside the editor using floating windows or splits.",
    "source": "github",
    "date": "2023-10-14",
    "highlights": [
      "Neovim Lua",
      "floating window",
      "telescope picker",
      "streaming"
    ]
  },
  {
    "title": "ollama-django",
    "url": "https://github.com/mnbf9rca/ollama-django",
    "summary": "Reusable Django app that adds Ollama chat endpoints, admin UI and async task queue integration.",
    "source": "github",
    "date": "2023-10-13",
    "highlights": [
      "Django REST",
      "Celery",
      "admin UI",
      "channels"
    ]
  },
  {
    "title": "ollama-swift",
    "url": "https://github.com/ollama-ecosystem/ollama-swift",
    "summary": "Swift Package Manager library for iOS/macOS apps to chat with local Ollama models via HTTP.",
    "source": "github",
    "date": "2023-10-12",
    "highlights": [
      "SwiftPM",
      "iOS/macOS",
      "async/await",
      "Codable models"
    ]
  },
  {
    "title": "ollama-terraform",
    "url": "https://github.com/ollama-ecosystem/ollama-terraform",
    "summary": "Terraform module to provision GPU-enabled AWS EC2 instances with Ollama server pre-installed.",
    "source": "github",
    "date": "2023-10-11",
    "highlights": [
      "Terraform",
      "AWS EC2",
      "GPU",
      "cloud-init"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/ollama-ecosystem/ollama-haystack",
    "summary": "Haystack integration by deepset allowing Ollama models to be used as generators or embedders in Haystack pipelines.",
    "source": "github",
    "date": "2023-10-10",
    "highlights": [
      "Haystack",
      "pip install farm-haystack[ollama]",
      "embeddings",
      "generators"
    ]
  }
]