[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: get up and running with Llama 3, Mistral, Gemma and other large language models locally.",
    "source": "github",
    "date": "2023-10-01",
    "highlights": [
      "Self-contained binary",
      "Model pulling from library",
      "REST & CLI APIs",
      "macOS/Linux/Windows"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for the Ollama server.",
    "source": "github",
    "date": "2023-11-15",
    "highlights": [
      "npm install ollama",
      "Promise-based API",
      "Full TypeScript defs",
      "Chat & embed endpoints"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client and SDK for interacting with Ollama.",
    "source": "github",
    "date": "2023-11-20",
    "highlights": [
      "pip install ollama",
      "Sync & async APIs",
      "Streaming responses",
      "Embeddings support"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/partners/ollama",
    "summary": "LangChain integration package to use Ollama models as LLMs or embedders.",
    "source": "github",
    "date": "2024-01-10",
    "highlights": [
      "pip install langchain-ollama",
      "ChatOllama",
      "OllamaEmbeddings",
      "Native LCEL support"
    ]
  },
  {
    "title": "Ollama WebUI",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich chat WebUI for any Ollama model (previously Ollama-WebUI, now Open-WebUI).",
    "source": "github",
    "date": "2023-12-05",
    "highlights": [
      "Docker one-liner",
      "RAG via documents folder",
      "Multi-user, dark mode",
      "Extensible plugin system"
    ]
  },
  {
    "title": "ollama-hack",
    "url": "https://github.com/jmorganca/ollama-hack",
    "summary": "Collection of example scripts and mini-tools built during Ollama hack days.",
    "source": "github",
    "date": "2023-09-20",
    "highlights": [
      "Discord bot example",
      "Model fine-tune helper",
      "CLI productivity tools"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/salty-flower/ollama-cli",
    "summary": "Interactive command-line chat wrapper with history, syntax highlighting and themes.",
    "source": "github",
    "date": "2024-02-01",
    "highlights": [
      "REPL style",
      "Persistent chat history",
      "Markdown rendering",
      "Configurable keybindings"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/ollama/ollama-rb",
    "summary": "Community-maintained Ruby gem for Ollama.",
    "source": "github",
    "date": "2023-11-30",
    "highlights": [
      "gem install ollama",
      "Object-oriented client",
      "Streaming chat support"
    ]
  },
  {
    "title": "ollama-go",
    "url": "https://github.com/ollama/ollama-go",
    "summary": "Community Go client library for Ollama's REST API.",
    "source": "github",
    "date": "2023-10-12",
    "highlights": [
      "go get github.com/ollama/ollama-go",
      "Strongly typed",
      "Context cancellation"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/fostermaier/ollama-copilot",
    "summary": "VS Code extension that turns Ollama models into a local GitHub Copilot alternative.",
    "source": "github",
    "date": "2024-01-25",
    "highlights": [
      "Inline completions",
      "Custom model pick",
      "Zero config after install"
    ]
  },
  {
    "title": "ollama-nvim",
    "url": "https://github.com/nomnivore/ollama-nvim",
    "summary": "Neovim plugin to chat with Ollama models inside the editor.",
    "source": "github",
    "date": "2023-12-15",
    "highlights": [
      "Side-panel chat",
      "Selection as prompt",
      "Customizable prompts"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java/JVM client for Ollama with builder-style API and Spring Boot starters.",
    "source": "github",
    "date": "2024-02-10",
    "highlights": [
      "Maven Central",
      "Async & sync clients",
      "Spring Boot auto-config"
    ]
  },
  {
    "title": "ollama-chat",
    "url": "https://github.com/ivanfioravanti/ollama-chat",
    "summary": "Lightweight React chat app that talks to a local Ollama instance.",
    "source": "github",
    "date": "2023-11-18",
    "highlights": [
      "Vite + React",
      "Responsive UI",
      "Dockerfile included"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/otwld/ollama-helm",
    "summary": "Helm chart to deploy Ollama on Kubernetes with GPU autoscaling.",
    "source": "github",
    "date": "2024-01-30",
    "highlights": [
      "GPU node-selector",
      "PVC model cache",
      "Horizontal pod autoscaler"
    ]
  },
  {
    "title": "ollama-rag",
    "url": "https://github.com/dmahurin/ollama-rag",
    "summary": "Minimal retrieval-augmented generation stack using Ollama embeddings and Chroma.",
    "source": "github",
    "date": "2023-12-20",
    "highlights": [
      "PDF ingestion script",
      "Chroma vector store",
      "Gradio UI"
    ]
  },
  {
    "title": "ollama-slack",
    "url": "https://github.com/justinhrobbins/ollama-slack",
    "summary": "Slack bot server that forwards channel messages to Ollama and replies in thread.",
    "source": "github",
    "date": "2024-02-05",
    "highlights": [
      "Socket-Mode support",
      "Threaded replies",
      "Per-channel model config"
    ]
  },
  {
    "title": "ollama-dbee",
    "url": "https://github.com/dbeaver/dbee-ollama",
    "summary": "DBeaver plugin that adds SQL-aware AI assistance powered by Ollama.",
    "source": "github",
    "date": "2024-03-01",
    "highlights": [
      "Query explanation",
      "Auto-completion",
      "Local model only"
    ]
  },
  {
    "title": "ollama-streamlit",
    "url": "https://github.com/streamlit/ollama-streamlit",
    "summary": "Streamlit component template for chatting with Ollama models in a data app.",
    "source": "github",
    "date": "2024-01-18",
    "highlights": [
      "pip install streamlit-ollama",
      "Session memory",
      "Custom CSS injection"
    ]
  },
  {
    "title": "ollama-on-ray",
    "url": "https://github.com/ray-project/ollama-on-ray",
    "summary": "Ray Serve deployment recipe to scale Ollama models across a GPU cluster.",
    "source": "github",
    "date": "2024-02-20",
    "highlights": [
      "Multi-model serving",
      "Autoscaling replicas",
      "Ray dashboard metrics"
    ]
  },
  {
    "title": "ollama-csharp",
    "url": "https://github.com/ollama/ollama-csharp",
    "summary": "Community .NET SDK for Ollama with NuGet package and code samples.",
    "source": "github",
    "date": "2024-03-05",
    "highlights": [
      "netstandard2.0",
      "HttpClient-based",
      " IAsyncEnumerable streaming"
    ]
  }
]