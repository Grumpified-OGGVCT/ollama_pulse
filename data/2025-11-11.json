[
  {
    "title": "Ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Get up and running with Llama 3.3, Mistral, Gemma 2, and other large language models locally.",
    "source": "github",
    "date": "2024-12-19",
    "highlights": [
      "Local LLM inference",
      "REST API",
      "Model library",
      "macOS/Linux/Windows"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Ollama.",
    "source": "github",
    "date": "2024-12-19",
    "highlights": [
      "npm package",
      "TypeScript support",
      "Promise-based API",
      "Chat & generate endpoints"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client for Ollama.",
    "source": "github",
    "date": "2024-12-19",
    "highlights": [
      "PyPI package",
      "Sync & async APIs",
      "Streaming support",
      "Embeddings endpoint"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/partners/ollama",
    "summary": "LangChain integration for Ollama models.",
    "source": "github",
    "date": "2024-12-19",
    "highlights": [
      "LangChain adapter",
      "Chat & LLM classes",
      "Tool calling",
      "Streaming"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "ChatGPT-style web UI client for Ollama.",
    "source": "github",
    "date": "2024-12-19",
    "highlights": [
      "React frontend",
      "Docker image",
      "Model management",
      "Multi-user support"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/ollama4j/ollama4j",
    "summary": "Java client library for Ollama.",
    "source": "github",
    "date": "2024-12-19",
    "highlights": [
      "Maven Central",
      "Java 8+",
      "Async support",
      "Chat & embeddings"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/ollama/ollama-rb",
    "summary": "Official Ruby gem for Ollama.",
    "source": "github",
    "date": "2024-12-19",
    "highlights": [
      "Ruby gem",
      "Streaming responses",
      "Chat & generate",
      "Embeddings"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/ollama/ollama-cli",
    "summary": "Feature-rich TUI client for Ollama written in Rust.",
    "source": "github",
    "date": "2024-12-19",
    "highlights": [
      "Rust TUI",
      "Keyboard shortcuts",
      "Model browser",
      "Chat history"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama/ollama-copilot",
    "summary": "VS Code extension bringing Ollama models into the editor.",
    "source": "github",
    "date": "2024-12-19",
    "highlights": [
      "VS Code extension",
      "Inline completions",
      "Custom prompts",
      "Multi-model"
    ]
  },
  {
    "title": "ollama-discord",
    "url": "https://github.com/ollama/ollama-discord",
    "summary": "Discord bot that serves Ollama models in chat.",
    "source": "github",
    "date": "2024-12-19",
    "highlights": [
      "Discord.py",
      "Slash commands",
      "Thread support",
      "Model switching"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/deepset-ai/haystack-core-integrations/tree/main/integrations/ollama",
    "summary": "Haystack integration for Ollama generators and chatters.",
    "source": "github",
    "date": "2024-12-19",
    "highlights": [
      "Haystack 2.x",
      "Generator & Chat",
      "Streaming",
      "Component library"
    ]
  },
  {
    "title": "ollama-csharp",
    "url": "https://github.com/ollama/ollama-csharp",
    "summary": "Official .NET client for Ollama.",
    "source": "github",
    "date": "2024-12-19",
    "highlights": [
      "NuGet package",
      ".NET 6+",
      "Chat & generate",
      "Embeddings"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/ollama/ollama-helm",
    "summary": "Helm chart to deploy Ollama on Kubernetes.",
    "source": "github",
    "date": "2024-12-19",
    "highlights": [
      "Kubernetes",
      "GPU support",
      "PVC storage",
      "Ingress ready"
    ]
  },
  {
    "title": "ollama-dagger",
    "url": "https://github.com/ollama/ollama-dagger",
    "summary": "Dagger module for running Ollama pipelines.",
    "source": "github",
    "date": "2024-12-19",
    "highlights": [
      "Dagger CI",
      "Containerized",
      "Model caching",
      "Pipeline functions"
    ]
  },
  {
    "title": "ollama-spring-boot-starter",
    "url": "https://github.com/ollama/ollama-spring-boot-starter",
    "summary": "Spring Boot starter auto-configuring Ollama client beans.",
    "source": "github",
    "date": "2024-12-19",
    "highlights": [
      "Spring Boot",
      "Auto-configuration",
      "Properties binding",
      "Chat templates"
    ]
  },
  {
    "title": "ollama-n8n-node",
    "url": "https://github.com/n8n-io/n8n/tree/master/packages/nodes-base/nodes/Ollama",
    "summary": "n8n community node for chatting with Ollama models.",
    "source": "github",
    "date": "2024-12-19",
    "highlights": [
      "n8n node",
      "Workflow automation",
      "Credentials",
      "Chat operation"
    ]
  },
  {
    "title": "ollama-go",
    "url": "https://github.com/ollama/ollama-go",
    "summary": "Official Go client library for Ollama.",
    "source": "github",
    "date": "2024-12-19",
    "highlights": [
      "Go module",
      "Streaming",
      "Chat & generate",
      "Embeddings"
    ]
  },
  {
    "title": "ollama-docker",
    "url": "https://github.com/ollama/ollama/tree/main/docker",
    "summary": "Official Docker images and compose examples for Ollama.",
    "source": "github",
    "date": "2024-12-19",
    "highlights": [
      "Official images",
      "GPU support",
      "Compose examples",
      "AMD/NVIDIA"
    ]
  },
  {
    "title": "ollama-logseq",
    "url": "https://github.com/ollama/ollama-logseq",
    "summary": "Logseq plugin that adds Ollama AI commands to your notes.",
    "source": "github",
    "date": "2024-12-19",
    "highlights": [
      "Logseq plugin",
      "Slash commands",
      "Custom prompts",
      "Block selection"
    ]
  },
  {
    "title": "ollama-rust",
    "url": "https://github.com/ollama/ollama-rust",
    "summary": "Community Rust crate for interacting with Ollama.",
    "source": "github",
    "date": "2024-12-19",
    "highlights": [
      "Async client",
      "Serde models",
      "Chat & generate",
      "Embeddings"
    ]
  }
]