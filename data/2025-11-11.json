[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: get up and running with Llama 2, Mistral, Gemma, and other large language models locally.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "self-contained binary",
      "Docker image",
      "macOS/Linux/Windows",
      "REST & CLI APIs"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python SDK for Ollama; chat, generate, embed, pull, and manage models with a few lines of code.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "pip install ollama",
      "async support",
      "streaming responses",
      "type hints"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Node and browsers; same generate/chat/embed API surface as Python.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "npm i ollama",
      "Promise & stream interfaces",
      "ESM/CJS bundles",
      "zero deps"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/partners/ollama",
    "summary": "LangChain adapter to use any Ollama model as an LLM or embedding provider in chains, agents, RAG pipelines.",
    "source": "github",
    "date": "2024-05-13",
    "highlights": [
      "pip langchain-ollama",
      "chat & embedding wrappers",
      "tool calling beta"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich web UI (formerly Ollama-WebUI) that feels like ChatGPT but runs entirely local via Ollama.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "Docker one-liner",
      "multi-user, themes",
      "RAG uploads, PDF, CSV",
      "voice input"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java/Kotlin client for Ollama; synchronous & async APIs, streaming, model management, Android compatible.",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "Maven Central",
      "non-blocking",
      "Kotlin coroutines",
      "Spring Boot starters"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/ollama/ollama-rb",
    "summary": "Official Ruby gem wrapping the Ollama REST API; generate, chat, pull, delete, copy, list models.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "gem install ollama",
      "streaming blocks",
      "Faraday backend",
      "RSpec tested"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/sugarforever/ollama-cli",
    "summary": "Rust-based interactive CLI that adds conversation history, markdown rendering, and prompt templates to Ollama.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "cargo install ollama-cli",
      "readline, syntax highlight",
      "config profiles"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama/ollama-copilot",
    "summary": "VS Code extension that brings local Ollama models into the editor as inline Copilot-style suggestions.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "FIM templates",
      "multi-model switch",
      "privacy first, no cloud"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/deepset-ai/haystack-integrations/tree/main/integrations/ollama",
    "summary": "Haystack integration: use Ollama models as generators or embedders in production-ready NLP pipelines.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "pip farm-haystack[ollama]",
      "YAML pipelines",
      "RAG eval benchmarks"
    ]
  },
  {
    "title": "ollama-csharp",
    "url": "https://github.com/ollama/ollama-csharp",
    "summary": "Community-maintained C#/.NET client with strongly-typed models and IAsyncEnumerable streaming.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "NuGet Ollama",
      ".NET 6+",
      "dependency injection friendly"
    ]
  },
  {
    "title": "ollama-docker-compose",
    "url": "https://github.com/ollama/ollama/tree/main/docker",
    "summary": "Official Docker image and compose stacks (CPU & GPU) for easy server deployment with persistent volumes.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "rocm & cuda tags",
      "rootless",
      "healthcheck endpoint"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/ollama/helm",
    "summary": "Community Helm chart to deploy Ollama on Kubernetes with GPU node-selector, autoscaling, and ingress.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "Helm repo",
      "HPA support",
      "PVC model cache",
      "configmaps"
    ]
  },
  {
    "title": "ollama-gpt4all-importer",
    "url": "https://github.com/jmorganca/ollama-gpt4all-importer",
    "summary": "Tool to convert GPT4All quantized models into Ollama\u2019s Modelfile format for local usage.",
    "source": "github",
    "date": "2024-04-25",
    "highlights": [
      "one-script conversion",
      "keeps quant savings",
      "example Modelfiles"
    ]
  },
  {
    "title": "ollama-rag-chatbot",
    "url": "https://github.com/suvam14/ollama-rag-chatbot",
    "summary": "Streamlit app demonstrating RAG with Ollama embeddings, Chroma vector store, and Llama-3 chat.",
    "source": "github",
    "date": "2024-05-13",
    "highlights": [
      "drag-drop PDFs",
      "chunk tuning UI",
      "citations in reply"
    ]
  },
  {
    "title": "ollama-logseq",
    "url": "https://github.com/ollama-logseq/plugin",
    "summary": "Logseq plugin that summons local Ollama models to summarize notes, brainstorm ideas, or rewrite text blocks.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "slash commands",
      "custom prompts",
      "offline privacy"
    ]
  },
  {
    "title": "ollama-npm",
    "url": "https://www.npmjs.com/package/ollama",
    "summary": "npm landing page for the official ollama JavaScript package: weekly downloads, version history, quick samples.",
    "source": "npm",
    "date": "2024-05-14",
    "highlights": [
      ">80k weekly downloads",
      "0 dependencies",
      "browser & node"
    ]
  },
  {
    "title": "ollama PyPI",
    "url": "https://pypi.org/project/ollama/",
    "summary": "PyPI page for official ollama Python package: installation, usage snippet, release notes.",
    "source": "pypi",
    "date": "2024-05-14",
    "highlights": [
      "~70k monthly downloads",
      "Python \u22653.8",
      "wheel distributions"
    ]
  },
  {
    "title": "r/ollama - Reddit community",
    "url": "https://www.reddit.com/r/ollama/",
    "summary": "Subreddit for sharing models, troubleshooting, integrations, and feature requests around Ollama.",
    "source": "reddit",
    "date": "2024-05-14",
    "highlights": [
      ">20k members",
      "weekly model threads",
      "showcase flair"
    ]
  },
  {
    "title": "Ollama on Hacker News",
    "url": "https://news.ycombinator.com/item?id=38820178",
    "summary": "Discussion thread announcing Ollama v0.1.33 with new Gemma support and concurrent model loading.",
    "source": "hackernews",
    "date": "2024-05-08",
    "highlights": [
      "performance benchmarks",
      "M-series GPU notes",
      "feature roadmap"
    ]
  }
]