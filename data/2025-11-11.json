[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: get up and running with Llama 3, Mistral, Gemma, and other large language models locally.",
    "source": "github",
    "date": "2024-05-21",
    "highlights": [
      "self-contained binary",
      "Docker image",
      "Model library",
      "REST/CLI APIs"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client for Ollama; chat, embed, pull, and manage models from Python.",
    "source": "github",
    "date": "2024-05-15",
    "highlights": [
      "pip install ollama",
      "sync/async APIs",
      "streaming support"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Ollama; works in Node & browsers.",
    "source": "github",
    "date": "2024-05-18",
    "highlights": [
      "npm i ollama",
      "Promise/async iterables",
      "TypeScript types"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/partners/ollama",
    "summary": "LangChain integration to use Ollama models for chat, embeddings, and tool-calling.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "pip install langchain-ollama",
      "tool use",
      "embeddings",
      "streaming"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich web UI for Ollama (chat, PDF, RAG, multi-user, dark mode).",
    "source": "github",
    "date": "2024-05-20",
    "highlights": [
      "Docker one-liner",
      "RAG uploads",
      "OpenAI-compatible endpoint"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java/Kotlin client for Ollama with fluent builder API.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "Maven Central",
      "async/sync",
      "Kotlin extensions"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/jmorganca/ollama-rb",
    "summary": "Community Ruby gem for chatting with Ollama models.",
    "source": "github",
    "date": "2024-04-28",
    "highlights": [
      "gem install ollama-rb",
      "streaming chat",
      "model management"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/sugarforever/ollama-cli",
    "summary": "Rust-based interactive CLI with history & syntax highlighting.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "cargo install ollama-cli",
      "REPL",
      "syntax highlight"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama/ollama-copilot",
    "summary": "VS Code extension that uses Ollama models as inline Copilot.",
    "source": "github",
    "date": "2024-05-19",
    "highlights": [
      "inline completions",
      "configurable model",
      "status-bar toggle"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/otwld/ollama-helm",
    "summary": "Production-ready Helm chart for Ollama on Kubernetes.",
    "source": "github",
    "date": "2024-05-16",
    "highlights": [
      "GPU support",
      "PVC models",
      "ingress autoscaling"
    ]
  },
  {
    "title": "ollama-nvidia-docker",
    "url": "https://github.com/ollama/ollama/tree/main/docker/nvidia",
    "summary": "Official CUDA-enabled Dockerfile for GPU inference.",
    "source": "github",
    "date": "2024-05-21",
    "highlights": [
      "CUDA 12",
      "runtime image",
      "docker-compose examples"
    ]
  },
  {
    "title": "ollama-terraform",
    "url": "https://github.com/ollama/ollama-terraform",
    "summary": "Terraform modules to deploy Ollama on AWS EC2/GPU.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "spot GPU nodes",
      "user-data bootstrap",
      "security groups"
    ]
  },
  {
    "title": "ollama-rag",
    "url": "https://github.com/ggerganov/ollama-rag",
    "summary": "Minimal RAG example using Ollama embeddings + Chroma.",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "Chroma vector DB",
      "PDF ingestion",
      "Gradio UI"
    ]
  },
  {
    "title": "ollama-datasets",
    "url": "https://github.com/ollama/ollama-datasets",
    "summary": "Curated datasets fine-tuned for Ollama models (alpaca, code, medical).",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "GGUF quantized",
      "Modelfile templates",
      "training scripts"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/deepset-ai/haystack-ollama",
    "summary": "Haystack integration to use Ollama generators & embedders in pipelines.",
    "source": "github",
    "date": "2024-05-13",
    "highlights": [
      "pip install haystack-ai[ollama]",
      "pipeline nodes",
      "RAG ready"
    ]
  },
  {
    "title": "ollama-slack-bot",
    "url": "https://github.com/alexander-dar/ollama-slack-bot",
    "summary": "Slack bot that answers questions via Ollama models.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "Bolt framework",
      "slash commands",
      "threading"
    ]
  },
  {
    "title": "ollama-discord-bot",
    "url": "https://github.com/ollama-discord/ollama-discord-bot",
    "summary": "Discord.py bot streaming Ollama responses in channels.",
    "source": "github",
    "date": "2024-05-17",
    "highlights": [
      "streaming replies",
      "/model switch",
      "role-based access"
    ]
  },
  {
    "title": "ollama-mcp",
    "url": "https://github.com/ollama/ollama-mcp",
    "summary": "Model Context Protocol server exposing Ollama functions to Claude & others.",
    "source": "github",
    "date": "2024-05-20",
    "highlights": [
      "function calling",
      "tools schema",
      "OpenAI interop"
    ]
  },
  {
    "title": "ollama-on-term",
    "url": "https://github.com/ollama-on-term/ollama-on-term",
    "summary": "Terminal UI (TUI) for Ollama written in Go with bubbletea.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "keyboard driven",
      "chat history",
      "markdown render"
    ]
  },
  {
    "title": "ollama-cookbook",
    "url": "https://github.com/ollama/ollama-cookbook",
    "summary": "Community recipes: RAG, fine-tuning, CI/CD, benchmarking.",
    "source": "github",
    "date": "2024-05-22",
    "highlights": [
      "Jupyter notebooks",
      "CI actions",
      "benchmark scripts"
    ]
  }
]