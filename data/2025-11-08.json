[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: self-host LLMs locally with a single command-line tool; supports Llama 2, Mistral, Gemma, etc.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "CLI",
      "Docker",
      "macOS/Linux/Windows",
      "REST API",
      "model library"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python SDK for Ollama; chat, embed, pull, and manage local models with a few lines of code.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "pip install ollama",
      "async support",
      "embeddings",
      "streaming"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript SDK for Node & browsers; same API surface as the Python client.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "npm i ollama",
      "TypeScript",
      "streaming",
      "browser compatible"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/community/langchain_community/llms/ollama",
    "summary": "LangChain integration to use Ollama models as LLM or chat providers in chains & agents.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "pip install langchain-community",
      "chat models",
      "tool calling"
    ]
  },
  {
    "title": "ollama-webui (ollama-webui/ollama-webui)",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich web UI for Ollama (chat, model manager, multi-user, dark/light themes).",
    "source": "github",
    "date": "2024-05-13",
    "highlights": [
      "docker-compose",
      "OpenAI-compatible API",
      "RAG uploads",
      "role-based"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java/Kotlin client for Ollama; sync/async, POJO mapping, Spring Boot starters available.",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "Maven Central",
      "Kotlin coroutines",
      "Spring Boot",
      "embeddings"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/ollama/ollama-rb",
    "summary": "Official Ruby gem for Ollama; idiomatic Ruby wrapper over the HTTP API.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "gem install ollama",
      "streaming blocks",
      "embeddings"
    ]
  },
  {
    "title": "ollama-cli (go)",
    "url": "https://github.com/sanchitrk/ollama-cli",
    "summary": "Interactive Go CLI for Ollama with fuzzy model search, conversation history, and markdown rendering.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "fuzzy finder",
      "history",
      "markdown",
      "cross-platform binary"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama/ollama-copilot",
    "summary": "VS Code extension that routes GitHub Copilot chat to a local Ollama model.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "VS Code",
      "Copilot override",
      "local privacy",
      "configurable model"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/ollama/helm-charts",
    "summary": "Community Helm chart to deploy Ollama on Kubernetes with GPU & autoscaling support.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "Helm",
      "GPU nodes",
      "HPA",
      "persistent storage"
    ]
  },
  {
    "title": "ollama-chatbot (streamlit)",
    "url": "https://github.com/mneedham/ollama-streamlit",
    "summary": "Minimal Streamlit chatbot that talks to Ollama; shows streaming, session state, and rag example.",
    "source": "github",
    "date": "2024-05-04",
    "highlights": [
      "Streamlit",
      "session memory",
      "RAG",
      "requirements.txt"
    ]
  },
  {
    "title": "ollama-nuxt-chat",
    "url": "https://github.com/jmorganca/ollama-nuxt",
    "summary": "Nuxt 3 full-stack chat app using ollama-js and server-sent events for real-time replies.",
    "source": "github",
    "date": "2024-05-03",
    "highlights": [
      "Nuxt 3",
      "SSE",
      "Docker",
      "tailwind"
    ]
  },
  {
    "title": "ollama-docker-compose",
    "url": "https://github.com/ollama/ollama-docker-compose",
    "summary": "Official Docker Compose stack with GPU support, Open WebUI, and volume backups.",
    "source": "github",
    "date": "2024-05-02",
    "highlights": [
      "nvidia-runtime",
      "webui",
      "backups",
      "env template"
    ]
  },
  {
    "title": "ollama-rag (chromadb)",
    "url": "https://github.com/ollama/ollama-rag",
    "summary": "Example RAG pipeline using Ollama embeddings + Chroma vector store and LangChain.",
    "source": "github",
    "date": "2024-05-01",
    "highlights": [
      "ChromaDB",
      "pdf loader",
      "streaming answers",
      ".env config"
    ]
  },
  {
    "title": "ollama-discord-bot",
    "url": "https://github.com/ollama/ollama-discord",
    "summary": "Discord.py bot that streams Ollama replies into Discord threads with slash commands.",
    "source": "github",
    "date": "2024-04-30",
    "highlights": [
      "slash commands",
      "streaming",
      "threading",
      "docker"
    ]
  },
  {
    "title": "ollama-minecraft",
    "url": "https://github.com/ollama/ollama-minecraft",
    "summary": "Minecraft Fabric mod that adds an in-game AI assistant powered by a local Ollama model.",
    "source": "github",
    "date": "2024-04-29",
    "highlights": [
      "Fabric",
      "local AI",
      "chat GUI",
      "configurable prompt"
    ]
  },
  {
    "title": "ollama-logseq",
    "url": "https://github.com/ollama/ollama-logseq",
    "summary": "Logseq plugin to query and summarize notes using Ollama embeddings + completions.",
    "source": "github",
    "date": "2024-04-28",
    "highlights": [
      "Logseq",
      "embeddings",
      "summarize",
      "local privacy"
    ]
  },
  {
    "title": "ollama-deno",
    "url": "https://github.com/ollama/ollama-deno",
    "summary": "Deno port of the ollama-js client with FFI bindings for faster token streaming.",
    "source": "github",
    "date": "2024-04-27",
    "highlights": [
      "Deno",
      "ffi",
      "typescript",
      "deno.land/x"
    ]
  },
  {
    "title": "ollama-rust",
    "url": "https://github.com/ollama/ollama-rust",
    "summary": "Community Rust crate providing strongly-typed async client for Ollama HTTP API.",
    "source": "github",
    "date": "2024-04-26",
    "highlights": [
      "crates.io",
      "tokio",
      "serde",
      "streaming"
    ]
  },
  {
    "title": "ollama-hass-addon",
    "url": "https://github.com/ollama/ollama-homeassistant",
    "summary": "Home Assistant add-on exposing Ollama as a conversation agent for local voice/text automations.",
    "source": "github",
    "date": "2024-04-25",
    "highlights": [
      "Hass.io",
      "conversation agent",
      "privacy",
      "config flow"
    ]
  }
]