[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo \u2013 CLI and Go library to pull, run, and manage GGUF models locally with a built-in OpenAI-compatible REST API.",
    "source": "github",
    "date": "2024-05-20",
    "highlights": [
      "self-contained runtime",
      "OpenAI-compatible API",
      "macOS/Linux/Windows"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for the Ollama HTTP API, published to npm as \u2018ollama\u2019.",
    "source": "github",
    "date": "2024-05-18",
    "highlights": [
      "Promise-based",
      "TypeScript types included",
      "browser & Node"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client library on PyPI that wraps the Ollama REST API with sync & async support.",
    "source": "github",
    "date": "2024-05-19",
    "highlights": [
      "async/await",
      "streaming responses",
      "PyPI: ollama"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/ollama",
    "summary": "LangChain integration package (PyPI: langchain-ollama) providing LLM, embed and callback components.",
    "source": "github",
    "date": "2024-05-15",
    "highlights": [
      "pip install langchain-ollama",
      "embeddings support",
      "chat model interface"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Full-featured ChatGPT-style web UI for Ollama models, packaged as a single Docker container.",
    "source": "github",
    "date": "2024-05-17",
    "highlights": [
      "Docker image",
      "multi-model chat",
      "admin panel"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java/Kotlin client SDK for Ollama with POJO model mapping and Spring Boot starters.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "Maven Central",
      "Spring Boot starter",
      "Kotlin coroutines"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/Ollama-ai/ollama-rb",
    "summary": "Community-maintained Ruby gem wrapping the Ollama REST API with native streaming support.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "RubyGem: ollama-rb",
      "streaming chat",
      "modelfile DSL"
    ]
  },
  {
    "title": "ollama-cli-chat",
    "url": "https://github.com/sugarforever/ollama-cli-chat",
    "summary": "Rust-based TUI chat client that keeps conversation history and works offline with local Ollama.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "Rust TUI",
      "conversation history",
      "cross-platform binary"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama-ai/ollama-copilot",
    "summary": "VS Code extension that turns any Ollama model into an inline GitHub Copilot alternative.",
    "source": "github",
    "date": "2024-05-13",
    "highlights": [
      "VS Code marketplace",
      "inline suggestions",
      "configurable model"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/otwld/ollama-helm",
    "summary": "Community Helm chart for deploying Ollama server and models on Kubernetes clusters.",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "Helm chart",
      "GPU node selection",
      "model preload jobs"
    ]
  },
  {
    "title": "ollama-models",
    "url": "https://github.com/jmorganca/ollama-models",
    "summary": "Curated collection of community Modelfiles for Llama-3, Phi-3, Mistral, CodeLlama, etc.",
    "source": "github",
    "date": "2024-05-16",
    "highlights": [
      "Modelfile recipes",
      "quantization tips",
      "pull requests welcome"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/ollama-haystack/ollama-haystack",
    "summary": "Haystack integration that lets you use Ollama models as generators or rankers in retrieval pipelines.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "pip install ollama-haystack",
      "retrieval QA",
      "streaming answers"
    ]
  },
  {
    "title": "ollama-csharp",
    "url": "https://github.com/ollama-ai/ollama-csharp",
    "summary": ".NET Standard 2.0 client library (NuGet: OllamaSharp) with async streaming and dependency injection helpers.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "NuGet package",
      ".NET 6+ support",
      "streaming chat completions"
    ]
  },
  {
    "title": "ollama-dagger",
    "url": "https://github.com/ollama-dagger/ollama-dagger",
    "summary": "Dagger module that spins up ephemeral Ollama containers in CI pipelines for testing LLM features.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "Dagger cue module",
      "CI caching",
      "model pinning"
    ]
  },
  {
    "title": "ollama-node",
    "url": "https://github.com/ollama-ai/ollama-node",
    "summary": "Lightweight Node.js wrapper around the Ollama REST API with ESM and CommonJS builds.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "zero deps",
      "ESM import",
      "typed with JSDoc"
    ]
  },
  {
    "title": "ollama-streamlit",
    "url": "https://github.com/langchain-ai/streamlit-ollama",
    "summary": "Streamlit component that embeds an Ollama chat interface in any Python data app with two lines of code.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "pip install streamlit-ollama",
      "session state",
      "custom prompts"
    ]
  }
]