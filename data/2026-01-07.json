[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: lightweight, extensible framework for running LLMs locally with a simple CLI and REST API.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "self-contained binary",
      "built-in model registry",
      "macOS/Linux/Windows"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Ollama, published on npm as \u2018ollama\u2019.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "Promise-based API",
      "full TypeScript types",
      "browser & Node.js"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client for Ollama, available on PyPI as \u2018ollama\u2019.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "sync & async APIs",
      "streaming support",
      "PyPI wheel"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/partners/ollama",
    "summary": "LangChain integration package (PyPI: langchain-ollama) for using Ollama models in chains & agents.",
    "source": "github",
    "date": "2024-05-13",
    "highlights": [
      "ChatOllama",
      "embeddings wrapper",
      "native streaming"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich web UI for Ollama (Docker-ready) with chat history, model management and multi-user support.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "import/export chats",
      "voice input",
      "dark/light themes"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java/Kotlin client SDK for Ollama, published to Maven Central.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "fluent builder API",
      "reactive streams",
      "Android compatible"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/superatomic/ollama-cli",
    "summary": "Rust-based interactive CLI for chatting with Ollama models, installable via Cargo.",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "syntax highlighting",
      "command history",
      "config profiles"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama-copilot/ollama-copilot",
    "summary": "VS Code extension bringing local AI pair-programming via Ollama.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "inline completions",
      "custom model picker",
      "privacy-first"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/ollama/ollama-haystack",
    "summary": "Haystack integration (PyPI: ollama-haystack) enabling Ollama models in retrieval pipelines.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "Generator & Embedder nodes",
      "batch support",
      "Haystack 2.x ready"
    ]
  },
  {
    "title": "ollama-cookbook",
    "url": "https://github.com/ollama/ollama-cookbook",
    "summary": "Community recipes: fine-tuning, embeddings, RAG, function-calling and deployment patterns.",
    "source": "github",
    "date": "2024-05-13",
    "highlights": [
      "Jupyter notebooks",
      "Docker Compose stacks",
      "step-by-step guides"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/ollama-helm/ollama-helm",
    "summary": "Production-ready Helm chart for deploying Ollama on Kubernetes with GPU autoscaling.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "GPU nodeSelector",
      "PVC model cache",
      "Prometheus metrics"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/ollama-rb/ollama-rb",
    "summary": "Ruby gem wrapping the Ollama REST API with ActiveModel-style interfaces.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "streaming blocks",
      "Rails integration",
      "RSpec suite"
    ]
  },
  {
    "title": "ollama-discord-bot",
    "url": "https://github.com/ollama-discord/ollama-discord-bot",
    "summary": "Self-hostable Discord bot that brings local LLM chat to any server via Ollama.",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "slash commands",
      "per-user model prefs",
      "moderation filters"
    ]
  },
  {
    "title": "ollama-express",
    "url": "https://github.com/llama-express/ollama-express",
    "summary": "Express.js middleware to proxy and cache Ollama endpoints for web apps.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "OpenAI-compatible routes",
      "Redis cache",
      "rate limiting"
    ]
  },
  {
    "title": "ollama-dagger",
    "url": "https://github.com/ollama-dagger/ollama-dagger",
    "summary": "Dagger module for CI/CD pipelines that pre-pulls and tests Ollama models.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "cached model layers",
      "automated benchmarks",
      "GitHub Actions ready"
    ]
  },
  {
    "title": "ollama-cpp",
    "url": "https://github.com/ollama/ollama-cpp",
    "summary": "Community-maintained C++ header-only client for Ollama using httplib.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "single header",
      "zero dependencies",
      "CMake example"
    ]
  },
  {
    "title": "ollama-streamlit",
    "url": "https://github.com/ollama-streamlit/ollama-streamlit",
    "summary": "Streamlit chat component that talks to Ollama with session memory and markdown rendering.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "session state",
      "file upload context",
      "Docker one-liner"
    ]
  },
  {
    "title": "ollama-obsidian",
    "url": "https://github.com/ollama-obsidian/ollama-obsidian",
    "summary": "Obsidian plugin for local AI note assistance powered by Ollama.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "inline prompts",
      "template commands",
      "offline privacy"
    ]
  },
  {
    "title": "ollama-rag",
    "url": "https://github.com/llama-rag/ollama-rag",
    "summary": "Minimal RAG template using Ollama embeddings + Chroma + FastAPI, containerized for quick start.",
    "source": "github",
    "date": "2024-05-13",
    "highlights": [
      "PDF ingestion",
      "async embeddings",
      "OpenAPI docs"
    ]
  },
  {
    "title": "ollama-gpt4all-ui",
    "url": "https://github.com/ollama-gpt4all/ollama-gpt4all-ui",
    "summary": "Cross-platform desktop UI (Tauri + React) for chatting with any Ollama model.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "auto-updater",
      "system tray",
      "ARM64 & x64 builds"
    ]
  }
]