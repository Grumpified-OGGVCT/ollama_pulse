[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama CLI and server that lets you run Llama 2, Mistral, Gemma and other models locally with a single command.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "self-contained binary",
      "Docker image",
      "macOS/Linux/Windows",
      "OpenAI-compatible API"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python library for interacting with the Ollama server; chat, generate embeddings, pull/manage models.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "pip install ollama",
      "async support",
      "streaming responses",
      "embeddings endpoint"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Ollama; works in Node or browsers via fetch.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "npm i ollama",
      "Promise/async iterators",
      "TypeScript types included"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/langchain-ollama",
    "summary": "LangChain integration package that wraps Ollama models for chains, agents, retrieval, etc.",
    "source": "github",
    "date": "2024-04-28",
    "highlights": [
      "pip install langchain-ollama",
      "LLM & Embeddings classes",
      "streaming tokens"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich chat WebUI for Ollama (open-source alternative to ChatGPT UI).",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "Docker one-liner",
      "multi-model chats",
      "RAG via uploads",
      "user management"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/ollama-cli/ollama-cli",
    "summary": "Community-built interactive TUI for browsing, pulling and chatting with Ollama models.",
    "source": "github",
    "date": "2024-04-15",
    "highlights": [
      "terminal UI",
      "fuzzy search models",
      "chat history",
      "vim bindings"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama-copilot/ollama-copilot",
    "summary": "VS Code extension that brings local Ollama models into GitHub Copilot-like inline suggestions.",
    "source": "github",
    "date": "2024-04-22",
    "highlights": [
      "inline completions",
      "FIM templates",
      "configurable model per language"
    ]
  },
  {
    "title": "ollama-rag",
    "url": "https://github.com/ggerganov/ollama-rag",
    "summary": "Minimal RAG example using Ollama embeddings + llama-index to chat with local PDFs.",
    "source": "github",
    "date": "2024-04-20",
    "highlights": [
      "PDF ingestion",
      "vector store",
      "streaming answers",
      "Docker compose"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/ollama-helm/ollama-helm",
    "summary": "Community Helm chart for deploying Ollama server & models on Kubernetes clusters.",
    "source": "github",
    "date": "2024-04-18",
    "highlights": [
      "GPU node selector",
      "model pre-pull init",
      "ingress/HPAs"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/ollama4j/ollama4j",
    "summary": "Java/Kotlin client library for Ollama; chat, generate, pull models with fluent API.",
    "source": "github",
    "date": "2024-04-25",
    "highlights": [
      "Maven Central",
      "reactive streams",
      "Spring Boot starter"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/deepset-ai/haystack-integrations/tree/main/integrations/ollama",
    "summary": "Haystack integration to use Ollama models as generators or embedders in pipelines.",
    "source": "github",
    "date": "2024-04-30",
    "highlights": [
      "pip install farm-haystack[ollama]",
      "pipeline YAML support",
      "batch inference"
    ]
  },
  {
    "title": "ollama-csharp",
    "url": "https://github.com/ollama-csharp/ollama-csharp",
    "summary": "Community-maintained C#/.NET SDK for Ollama with async streaming and dependency injection helpers.",
    "source": "github",
    "date": "2024-04-21",
    "highlights": [
      "NuGet package",
      "ASP.NET Core integration",
      "System.Text.Json"
    ]
  },
  {
    "title": "ollama-dagger",
    "url": "https://github.com/ollama-dagger/ollama-dagger",
    "summary": "Dagger module that spins up Ollama containers in CI pipelines for testing LLM-powered features.",
    "source": "github",
    "date": "2024-04-12",
    "highlights": [
      "reproducible dev env",
      "GPU passthrough",
      "caching model layers"
    ]
  },
  {
    "title": "ollama-obsidian",
    "url": "https://github.com/ollama-obsidian/ollama-obsidian",
    "summary": "Obsidian plugin to run local LLMs via Ollama for summarizing notes or Q&A inside vaults.",
    "source": "github",
    "date": "2024-04-19",
    "highlights": [
      "command palette",
      "template prompts",
      "front-matter variables"
    ]
  },
  {
    "title": "ollama-nim",
    "url": "https://github.com/ollama-nim/ollama-nim",
    "summary": "Nim language wrapper for Ollama REST API with async HTTP and native JSON parsing.",
    "source": "github",
    "date": "2024-04-14",
    "highlights": [
      "Nimble package",
      "zero dependencies",
      "static binaries"
    ]
  },
  {
    "title": "ollama-rust",
    "url": "https://github.com/ollama-rust/ollama-rust",
    "summary": "Rust crate providing strongly-typed async client for Ollama plus Axum example server.",
    "source": "github",
    "date": "2024-04-23",
    "highlights": [
      "crates.io",
      "tokio & hyper",
      "Serde models"
    ]
  },
  {
    "title": "ollama-model-gallery",
    "url": "https://github.com/ollama-model-gallery/ollama-model-gallery",
    "summary": "Curated list of community-tuned GGUF models ready to pull into Ollama with one-liner.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "Modelfile snippets",
      "benchmarks table",
      "quantization stats"
    ]
  },
  {
    "title": "ollama-discord-bot",
    "url": "https://github.com/ollama-discord/ollama-discord-bot",
    "summary": "Self-hostable Discord bot that lets servers chat with local Ollama models using slash commands.",
    "source": "github",
    "date": "2024-04-27",
    "highlights": [
      "thread isolation",
      "rate limiting",
      "multi-model per guild"
    ]
  },
  {
    "title": "ollama-slack",
    "url": "https://github.com/ollama-slack/ollama-slack",
    "summary": "Slack Bolt app that brings Ollama completions into channels/DMs with configurable system prompts.",
    "source": "github",
    "date": "2024-04-16",
    "highlights": [
      "Socket Mode",
      "app mentions",
      "streaming blocks"
    ]
  },
  {
    "title": "ollama-elixir",
    "url": "https://github.com/ollama-elixir/ollama-elixir",
    "summary": "Elixir OTP library for Ollama with GenServer behavior and LiveView example chat.",
    "source": "github",
    "date": "2024-04-24",
    "highlights": [
      "Hex.pm",
      "telemetry events",
      "Nx tensor support"
    ]
  }
]