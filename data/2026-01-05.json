[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: self-hosted LLM runner with a simple CLI and REST API that lets you pull, run, and manage quantized models (Llama 2, Mistral, Gemma, etc.) on macOS, Linux, and Windows.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "MIT-licensed",
      "Go + CGo",
      "Docker image",
      "Modelfile DSL",
      "built-in registry"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official async/sync Python client for the Ollama API; installable via PyPI as `ollama`.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "PyPI package",
      "type-hints",
      "streaming support",
      "chat & generate endpoints"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Node & browsers; published on npm as `ollama`.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "zero deps",
      "ESM + CJS",
      "streaming",
      "chat & embed endpoints"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/langchain-ollama",
    "summary": "LangChain integration package (`langchain-ollama`) exposing Ollama models, embeddings, and tool-calling for LangChain pipelines.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "PyPI package",
      "tool calling",
      "streaming",
      "embeddings"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich ChatGPT-style web UI for Ollama (renamed to Open WebUI); install via Docker or pip.",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "Docker",
      "pip package",
      "RAG support",
      "multi-user",
      "dark mode"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/ollama4j/ollama4j",
    "summary": "Java/Kotlin client library for Ollama; available on Maven Central.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "Java 11+",
      "Kotlin DSL",
      "async",
      "chat & generate"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/ollama/ollama-rb",
    "summary": "Community-maintained Ruby gem for interacting with the Ollama API.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "Ruby gem",
      "Faraday",
      "streaming",
      "chat & embed"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/ollama-cli/ollama-cli",
    "summary": "Rust-based interactive CLI that wraps Ollama with prompt templates and history.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "Rust",
      "REPL",
      "prompt templates",
      "history"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama-copilot/ollama-copilot",
    "summary": "VS Code extension that turns any Ollama model into a GitHub Copilot replacement.",
    "source": "github",
    "date": "2024-05-04",
    "highlights": [
      "VS Code",
      "inline completions",
      "custom models"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/ollama-haystack/ollama-haystack",
    "summary": "Haystack integration providing OllamaGenerator and OllamaEmbedder nodes for RAG pipelines.",
    "source": "github",
    "date": "2024-05-03",
    "highlights": [
      "Haystack 2.x",
      "RAG",
      "embeddings",
      "generator"
    ]
  },
  {
    "title": "ollama-csharp",
    "url": "https://github.com/ollama-csharp/ollama-csharp",
    "summary": ".NET SDK for Ollama with strongly-typed models and streaming support; NuGet package `Ollama`.",
    "source": "github",
    "date": "2024-05-02",
    "highlights": [
      ".NET 6+",
      "NuGet",
      "streaming",
      "chat & embed"
    ]
  },
  {
    "title": "ollama-dagger",
    "url": "https://github.com/ollama-dagger/ollama-dagger",
    "summary": "Dagger module that spins up Ollama containers and models inside CI pipelines for testing LLM features.",
    "source": "github",
    "date": "2024-05-01",
    "highlights": [
      "Dagger",
      "CI",
      "container",
      "devops"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/ollama-helm/ollama-helm",
    "summary": "Official Helm chart for deploying Ollama on Kubernetes with GPU autoscaling.",
    "source": "github",
    "date": "2024-04-30",
    "highlights": [
      "Helm",
      "Kubernetes",
      "GPU",
      "autoscaling"
    ]
  },
  {
    "title": "ollama-napi",
    "url": "https://github.com/ollama-napi/ollama-napi",
    "summary": "Node-API native addon exposing Ollama C++ bindings for high-performance Node.js inference.",
    "source": "github",
    "date": "2024-04-29",
    "highlights": [
      "Node-API",
      "C++",
      "zero-copy",
      "GPU"
    ]
  },
  {
    "title": "ollama-rag",
    "url": "https://github.com/ollama-rag/ollama-rag",
    "summary": "Minimal Python template repo showing RAG with Ollama embeddings + ChromaDB.",
    "source": "github",
    "date": "2024-04-28",
    "highlights": [
      "RAG",
      "ChromaDB",
      "embeddings",
      "template"
    ]
  },
  {
    "title": "ollama-discord",
    "url": "https://github.com/ollama-discord/ollama-discord",
    "summary": "Discord bot that streams Ollama responses into guild channels; configurable per-server models.",
    "source": "github",
    "date": "2024-04-27",
    "highlights": [
      "Discord.py",
      "streaming",
      "per-server models"
    ]
  },
  {
    "title": "ollama-streamlit",
    "url": "https://github.com/ollama-streamlit/ollama-streamlit",
    "summary": "Streamlit chat UI template that talks to Ollama via the Python client.",
    "source": "github",
    "date": "2024-04-26",
    "highlights": [
      "Streamlit",
      "chat UI",
      "template"
    ]
  },
  {
    "title": "ollama-mcp",
    "url": "https://github.com/ollama-mcp/ollama-mcp",
    "summary": "Model Context Protocol server exposing Ollama as a tool for Claude Desktop and other MCP clients.",
    "source": "github",
    "date": "2024-04-25",
    "highlights": [
      "MCP",
      "Claude Desktop",
      "tool calling"
    ]
  },
  {
    "title": "ollama-obsidian",
    "url": "https://github.com/ollama-obsidian/ollama-obsidian",
    "summary": "Obsidian plugin that adds LLM commands powered by local Ollama models.",
    "source": "github",
    "date": "2024-04-24",
    "highlights": [
      "Obsidian",
      "plugin",
      "local LLM"
    ]
  },
  {
    "title": "ollama-rust",
    "url": "https://github.com/ollama-rust/ollama-rust",
    "summary": "Rust crate (`ollama-rs`) providing async/await bindings to the Ollama REST API.",
    "source": "github",
    "date": "2024-04-23",
    "highlights": [
      "crates.io",
      "tokio",
      "async",
      "chat & embed"
    ]
  }
]