[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: self-hosted LLM runner with a built-in model library and simple REST/CLI APIs.",
    "source": "github",
    "date": "2023-10-01",
    "highlights": [
      "run Llama-2, Mistral, CodeLlama locally",
      "one-line install",
      "OpenAI-compatible endpoints"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Ollama; works in Node or browsers via fetch.",
    "source": "github",
    "date": "2023-09-15",
    "highlights": [
      "npm install ollama",
      "Promise-based API",
      "chat & embed helpers"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client for Ollama; pip install ollama.",
    "source": "github",
    "date": "2023-09-20",
    "highlights": [
      "sync & async clients",
      "streaming responses",
      "embeddings support"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/community/langchain_community/llms/ollama",
    "summary": "LangChain integration to use Ollama models as LLM or chat backend.",
    "source": "github",
    "date": "2023-10-05",
    "highlights": [
      "drop-in replacement for OpenAI",
      "streaming",
      "callback support"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich web UI for Ollama (chat, model manager, multi-user).",
    "source": "github",
    "date": "2023-10-12",
    "highlights": [
      "responsive UI",
      "markdown & code highlight",
      "import/export chats"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/ollama/ollama-cli",
    "summary": "Community-enhanced CLI with REPL, prompt templates, and conversation history.",
    "source": "github",
    "date": "2023-09-28",
    "highlights": [
      "interactive mode",
      "prompt snippets",
      "shell completions"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama/ollama-copilot",
    "summary": "VS Code extension that turns Ollama models into a local GitHub Copilot.",
    "source": "github",
    "date": "2023-10-08",
    "highlights": [
      "inline suggestions",
      "custom model picker",
      "no API key needed"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/ollama/helm-charts/tree/main/charts/ollama",
    "summary": "Helm chart for deploying Ollama on Kubernetes with GPU support.",
    "source": "github",
    "date": "2023-10-02",
    "highlights": [
      "auto-scaling",
      "persistent storage",
      "GPU node-selector"
    ]
  },
  {
    "title": "ollama-docker",
    "url": "https://github.com/ollama/ollama/tree/main/docker",
    "summary": "Official container images (CPU & CUDA) with docker-compose examples.",
    "source": "github",
    "date": "2023-09-30",
    "highlights": [
      "single-line docker run",
      "CUDA 11/12 tags",
      "compose with webui"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/ollama/ollama-rb",
    "summary": "Community Ruby gem for chatting with Ollama models.",
    "source": "github",
    "date": "2023-10-03",
    "highlights": [
      "bundler install",
      "ActiveRecord-like syntax",
      "streaming blocks"
    ]
  },
  {
    "title": "ollama-go",
    "url": "https://github.com/ollama/ollama-go",
    "summary": "Idiomatic Go client generated from Ollama\u2019s OpenAPI spec.",
    "source": "github",
    "date": "2023-09-25",
    "highlights": [
      "context cancellation",
      "concurrent chats",
      "modelfile helpers"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/deepset-ai/haystack-core-integrations/tree/main/integrations/ollama",
    "summary": "Haystack integration to use Ollama generators & embedders in pipelines.",
    "source": "github",
    "date": "2023-10-11",
    "highlights": [
      "pipeline nodes",
      "embedding retrieval",
      "batch inference"
    ]
  },
  {
    "title": "ollama-csharp",
    "url": "https://github.com/ollama/ollama-csharp",
    "summary": "Community .NET SDK for Ollama with async/await and streaming support.",
    "source": "github",
    "date": "2023-10-06",
    "highlights": [
      "NuGet package",
      "strong typing",
      "cancellation tokens"
    ]
  },
  {
    "title": "ollama-rust",
    "url": "https://github.com/ollama/ollama-rust",
    "summary": "Rust crate providing ergonomic wrappers over Ollama\u2019s REST API.",
    "source": "github",
    "date": "2023-09-27",
    "highlights": [
      "tokio client",
      "serde models",
      "examples folder"
    ]
  },
  {
    "title": "ollama-logseq",
    "url": "https://github.com/ollama-logseq/plugin",
    "summary": "Logseq plugin that lets you query local Ollama models from your notes.",
    "source": "github",
    "date": "2023-10-09",
    "highlights": [
      "slash command",
      "template prompts",
      "block insertion"
    ]
  },
  {
    "title": "ollama-obsidian",
    "url": "https://github.com/ollama-obsidian/ollama-obsidian",
    "summary": "Obsidian community plugin for AI-assisted writing with Ollama.",
    "source": "github",
    "date": "2023-10-10",
    "highlights": [
      "highlight-to-ask",
      "custom front-matter prompts",
      "offline"
    ]
  },
  {
    "title": "ollama-npm",
    "url": "https://www.npmjs.com/package/ollama",
    "summary": "Official npm package for JavaScript/TypeScript developers.",
    "source": "github",
    "date": "2023-09-15",
    "highlights": [
      "zero dependencies",
      "ESM & CJS",
      "typedoc docs"
    ]
  },
  {
    "title": "ollama-pypi",
    "url": "https://pypi.org/project/ollama/",
    "summary": "Official PyPI package \u2013 pip install ollama.",
    "source": "github",
    "date": "2023-09-20",
    "highlights": [
      ">=3.8 support",
      "asyncio integration",
      "PEP-561 typing"
    ]
  },
  {
    "title": "ollama-reddit",
    "url": "https://www.reddit.com/r/ollama/",
    "summary": "Active subreddit for model announcements, troubleshooting, and showcases.",
    "source": "reddit",
    "date": "2023-10-13",
    "highlights": [
      "model requests",
      "performance tips",
      "community Dockerfiles"
    ]
  },
  {
    "title": "ollama-hackernews-discussion",
    "url": "https://news.ycombinator.com/item?id=37812345",
    "summary": "Hacker News thread discussing Ollama\u2019s release and local LLM trends.",
    "source": "hackernews",
    "date": "2023-09-29",
    "highlights": [
      "benchmarks vs llama.cpp",
      "M1 GPU numbers",
      "security notes"
    ]
  }
]