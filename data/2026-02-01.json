[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: the CLI tool that downloads, builds and serves GGUF models with a built-in OpenAI-compatible API.",
    "source": "github",
    "date": "2024-04-24",
    "highlights": [
      "self-contained",
      "OpenAI-compatible API",
      "GGUF support",
      "macOS/Linux/Windows"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "First-party Python client library (PyPI: ollama) for chatting, embedding, pulling and managing models.",
    "source": "github",
    "date": "2024-04-24",
    "highlights": [
      "sync & async",
      "embedding helpers",
      "streaming responses"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client (npm: ollama) that works in Node, Bun, Deno and browsers via fetch.",
    "source": "github",
    "date": "2024-04-24",
    "highlights": [
      "zero deps",
      "ESM",
      "browser support",
      "TypeScript"
    ]
  },
  {
    "title": "langchain-ollama (PyPI)",
    "url": "https://pypi.org/project/langchain-ollama/",
    "summary": "LangChain adapter providing Ollama LLM & embedding components.",
    "source": "github",
    "date": "2024-04-24",
    "highlights": [
      "ChatOllama",
      "OllamaEmbeddings",
      "standard LangChain interface"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Open-source ChatGPT-style web UI that connects to any local Ollama instance.",
    "source": "github",
    "date": "2024-04-24",
    "highlights": [
      "markdown support",
      "multi-model chat",
      "modelfile editor",
      "Docker image"
    ]
  },
  {
    "title": "ollama4j \u2013 Java Client",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Lightweight Java/Android/Kotlin library for the Ollama API (Maven Central).",
    "source": "github",
    "date": "2024-04-24",
    "highlights": [
      "fluent API",
      "streaming",
      "Android compatible"
    ]
  },
  {
    "title": "ollama-cli \u2013 Rust TUI",
    "url": "https://github.com/spearow/juice/tree/main/ollama-cli",
    "summary": "Fast Rust CLI/TUI for interactive chatting with Ollama models.",
    "source": "github",
    "date": "2024-04-24",
    "highlights": [
      "keyboard shortcuts",
      "conversation history",
      "Rust binary"
    ]
  },
  {
    "title": "ollama-copilot.nvim",
    "url": "https://github.com/yetone/ollama-copilot.nvim",
    "summary": "Neovim plugin that turns Ollama models into a GitHub-Copilot-like code assistant.",
    "source": "github",
    "date": "2024-04-24",
    "highlights": [
      "inline suggestions",
      "Lua config",
      "streaming completion"
    ]
  },
  {
    "title": "ollama-vscode",
    "url": "https://github.com/mshd/ollama-vscode",
    "summary": "VS Code extension for chatting and code generation with local Ollama models.",
    "source": "github",
    "date": "2024-04-24",
    "highlights": [
      "sidebar panel",
      "quick commands",
      "no cloud required"
    ]
  },
  {
    "title": "ollama-rag \u2013 Python RAG starter",
    "url": "https://github.com/ivanfioravivi/ollama-rag",
    "summary": "Minimal repo showing how to build a RAG pipeline combining Ollama embeddings + Llama-3 for Q&A.",
    "source": "github",
    "date": "2024-04-24",
    "highlights": [
      "ChromaDB",
      "sentence splitting",
      "Gradio UI"
    ]
  },
  {
    "title": "ollama-slack-bot",
    "url": "https://github.com/justinleewells/ollama-slack-bot",
    "summary": "Slack Bolt bot that answers channel mentions using any Ollama model.",
    "source": "github",
    "date": "2024-04-24",
    "highlights": [
      "Socket-Mode",
      "threaded replies",
      "Dockerfile"
    ]
  },
  {
    "title": "ollama-telegram",
    "url": "https://github.com/rainchen/ollama-telegram",
    "summary": "Telegram bot with group & private chat support, streaming answers from Ollama.",
    "source": "github",
    "date": "2024-04-24",
    "highlights": [
      "typing indicator",
      "markdown rendering",
      "env-file config"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/ollama/ollama-haystack",
    "summary": "Haystack integration letting you use Ollama models as generators & embedders in pipelines.",
    "source": "github",
    "date": "2024-04-24",
    "highlights": [
      "prompt node",
      "embedder node",
      "Haystack 2.x ready"
    ]
  },
  {
    "title": "ollama-csharp SDK",
    "url": "https://github.com/ollama/ollama-csharp",
    "summary": "Community-maintained C#/.NET SDK (NuGet: Ollama) with async streaming support.",
    "source": "github",
    "date": "2024-04-24",
    "highlights": [
      "NET 6+",
      "System.Text.Json",
      "streaming chat"
    ]
  },
  {
    "title": "ollama-dagger",
    "url": "https://github.com/shykes/ollama-dagger",
    "summary": "Dagger module that spins up an Ollama service containerized for CI pipelines.",
    "source": "github",
    "date": "2024-04-24",
    "highlights": [
      "Dagger 0.9",
      "caching",
      "GitHub Actions example"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/otwld/ollama-helm",
    "summary": "Production-ready Helm chart to deploy Ollama on Kubernetes with GPU & PVC support.",
    "source": "github",
    "date": "2024-04-24",
    "highlights": [
      "GPU node-selector",
      "PVC cache",
      "autoscaling"
    ]
  },
  {
    "title": "reddit/r/ollama \u2013 model discussion",
    "url": "https://www.reddit.com/r/ollama/top/?sort=top&t=week",
    "summary": "Active subreddit sharing custom Modelfiles, benchmarks and troubleshooting tips.",
    "source": "reddit",
    "date": "2024-04-24",
    "highlights": [
      "Modelfile recipes",
      "GPU performance",
      "community support"
    ]
  },
  {
    "title": "Hacker News \u2013 Show HN: Ollama",
    "url": "https://news.ycombinator.com/item?id=38612345",
    "summary": "Recent Show-HN thread comparing Ollama to llama.cpp, text-generation-webui and discussing roadmap.",
    "source": "hackernews",
    "date": "2024-04-24",
    "highlights": [
      "performance numbers",
      "roadmap hints",
      "M-series Mac benchmarks"
    ]
  },
  {
    "title": "ollama-go \u2013 idiomatic Go client",
    "url": "https://github.com/ollama/ollama-go",
    "summary": "Official lightweight Go package exposing chat, embed and pull endpoints.",
    "source": "github",
    "date": "2024-04-24",
    "highlights": [
      "context support",
      "io.Reader streaming",
      "go mod tidy"
    ]
  },
  {
    "title": "Ollama Models Library",
    "url": "https://ollama.com/library",
    "summary": "Official registry of 150+ pre-converted GGUF models (Llama-3, Phi-3, Mistral, CodeLlama, etc.).",
    "source": "blog",
    "date": "2024-04-24",
    "highlights": [
      "one-line pull",
      "quantization options",
      "model cards"
    ]
  }
]