[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official CLI and Python/JS libraries for downloading and running Llama-2, Mistral, Gemma, CodeLlama and 30+ other GGUF models locally with GPU/CPU acceleration.",
    "source": "github",
    "date": "2024-05-15",
    "highlights": [
      "self-hosted inference",
      "Modelfile DSL",
      "REST API",
      "macOS/Linux/Windows"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://pypi.org/project/ollama/",
    "summary": "Official PyPI package providing synchronous and async Python clients for the Ollama REST API; chat, embed, pull, create and delete models with 3 lines of code.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "async/await",
      "streaming responses",
      "Pydantic models",
      "embeddings endpoint"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://www.npmjs.com/package/ollama",
    "summary": "Official npm library that wraps the Ollama HTTP API for Node/Bun/Deno; identical surface to the Python client so front-end and back-end code stay in sync.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "TypeScript definitions",
      "ESM & CommonJS",
      "readable streams",
      "browser fetch polyfill"
    ]
  },
  {
    "title": "langchain-community/llms/ollama",
    "url": "https://python.langchain.com/docs/integrations/llms/ollama",
    "summary": "First-party LangChain integration exposing chat, completion, embed and tool-calling interfaces so any LangChain chain or agent can run against local Ollama models.",
    "source": "blog",
    "date": "2024-04-22",
    "highlights": [
      "tool calling",
      "function embeddings",
      "batch runnable",
      "streaming tokens"
    ]
  },
  {
    "title": "LlamaIndex Ollama Integration",
    "url": "https://docs.llamaindex.ai/en/stable/examples/llm/ollama/",
    "summary": "Native LlamaIndex reader and LLM classes for building RAG pipelines on top of local Ollama instances; supports response synthesizers, embeddings and node parsers.",
    "source": "blog",
    "date": "2024-04-18",
    "highlights": [
      "RAG",
      "vector store",
      "response modes",
      "custom prompts",
      "streaming"
    ]
  },
  {
    "title": "ollama-webui/ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich ChatGPT-style web frontend (React + FastAPI) that talks to any Ollama server; offers multi-model chats, code highlighting, PDF upload, RAG and user auth.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "dark/light themes",
      "role-based auth",
      "openai-compatible endpoint",
      "docker image"
    ]
  },
  {
    "title": "ollama4j \u2013 Java / Kotlin Client",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Community Java/Kotlin SDK wrapping the Ollama REST API with builder-style requests, streaming callbacks and model management utilities; published to Maven Central.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "reactive streams",
      "Kotlin coroutines",
      "Maven Central",
      "custom Modelfile creator"
    ]
  },
  {
    "title": "ollama-rb \u2013 Ruby Gem",
    "url": "https://github.com/oelna/ollama-rb",
    "summary": "Lightweight Ruby client for Ollama supporting chat, completion, embeddings and model CRUD; includes CLI wrapper and Rails generator for quick prototyping.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "CLI",
      "Rails integration",
      "streaming",
      "Faraday backend"
    ]
  },
  {
    "title": "OllamaSharp \u2013 .NET Client",
    "url": "https://github.com/awaescher/OllamaSharp",
    "summary": "C# library providing async chat, completion, model listing and pulling; exposes IAsyncEnumerable streams and ships as NuGet package for .NET 6+.",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "IAsyncEnumerable",
      "NuGet",
      ".NET 6",
      "dependency injection friendly"
    ]
  },
  {
    "title": "ollama-cli \u2013 Rust TUI",
    "url": "https://github.com/jakobhellermann/ollama-cli",
    "summary": "Fast Rust terminal UI for chatting, switching and downloading models; uses skim fuzzy finder and supports markdown rendering in the terminal.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "TUI",
      "fuzzy finder",
      "markdown render",
      "cross-platform"
    ]
  },
  {
    "title": "ollama-copilot \u2013 VS Code Extension",
    "url": "https://github.com/mshd/ollama-copilot",
    "summary": "VS Code plugin that turns any Ollama model into an inline coding assistant; supports explain, refactor, test-generation and custom prompts via keyboard shortcuts.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "inline refactor",
      "custom prompts",
      "status bar indicator",
      "open-source"
    ]
  },
  {
    "title": "ollama-helm \u2013 Kubernetes Helm Charts",
    "url": "https://github.com/otwld/ollama-helm",
    "summary": "Production-ready Helm chart deploying Ollama server and WebUI to Kubernetes with GPU node-selector, PVC and autoscaling support; published to ArtifactHub.",
    "source": "github",
    "date": "2024-05-13",
    "highlights": [
      "GPU scheduling",
      "PVC",
      "autoscaling",
      "ArtifactHub"
    ]
  },
  {
    "title": "ollama-docker \u2013 Official Container Images",
    "url": "https://hub.docker.com/r/ollama/ollama",
    "summary": "Official multi-arch Docker images (AMD64, ARM64, CUDA, ROCm) updated nightly; one-liner docker run spins up GPU-accelerated Llama-2 on any host.",
    "source": "blog",
    "date": "2024-05-01",
    "highlights": [
      "CUDA",
      "ROCm",
      "multi-arch",
      "nightly builds",
      "rootless"
    ]
  },
  {
    "title": "ollama-model-hub \u2013 Community Model Registry",
    "url": "https://github.com/ollama-hub/ollama-model-hub",
    "summary": "Curated list of 150+ user-contributed Modelfiles for specialized models (Code, Chinese, Medical, SQL, etc.) with one-click pull scripts and performance notes.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "Modelfile recipes",
      "community curated",
      "pull scripts",
      "benchmarks"
    ]
  },
  {
    "title": "reddit/r/ollama \u2013 Discussion Subreddit",
    "url": "https://www.reddit.com/r/ollama/",
    "summary": "Active 8 k-member subreddit for sharing tips, troubleshooting GPU issues, showcasing integrations and requesting new model conversions.",
    "source": "reddit",
    "date": "2024-05-15",
    "highlights": [
      "community support",
      "model requests",
      "benchmarks",
      "show-and-tell"
    ]
  },
  {
    "title": "Ollama Discord Bot \u2013 TypeScript",
    "url": "https://github.com/Coen-Schuijt/ollama-discord-bot",
    "summary": "Discord.js bot that exposes slash commands to chat with any local Ollama model; supports thread isolation, moderation filter and configurable rate limits.",
    "source": "github",
    "date": "2024-05-04",
    "highlights": [
      "slash commands",
      "thread isolation",
      "rate limiting",
      "docker"
    ]
  },
  {
    "title": "ollama-dagger \u2013 CI/CD Module",
    "url": "https://github.com/sagikazarmark/daggerverse/tree/main/ollama",
    "summary": "Dagger module for spinning up ephemeral Ollama services inside CI pipelines; useful for integration-testing LLM features without cloud credits.",
    "source": "github",
    "date": "2024-05-03",
    "highlights": [
      "ephemeral containers",
      "CI testing",
      "caching",
      "Dagger"
    ]
  },
  {
    "title": "ollama-elixir \u2013 Elixir OTP Client",
    "url": "https://github.com/curiosum-dev/ollama-elixir",
    "summary": "GenServer-based Elixir client with supervised connections, streaming via WebSockets and telemetry instrumentation; published to Hex.pm.",
    "source": "github",
    "date": "2024-05-02",
    "highlights": [
      "OTP",
      "WebSocket stream",
      "telemetry",
      "Hex package"
    ]
  },
  {
    "title": "ollama-ui \u2013 Minimal Flutter Desktop App",
    "url": "https://github.com/pasha-zaig/ollama-ui",
    "summary": "Cross-platform Flutter desktop client for macOS/Linux/Windows with markdown chat view, model switcher and local settings persistence.",
    "source": "github",
    "date": "2024-05-01",
    "highlights": [
      "Flutter",
      "desktop",
      "markdown",
      "cross-platform"
    ]
  },
  {
    "title": "Hacker News \u2013 Show HN: Ollama",
    "url": "https://news.ycombinator.com/item?id=38820178",
    "summary": "Original 2023 launch thread discussing design decisions (Go + GGML, static binary, no CUDA runtime deps) and roadmap toward OpenAI-compatible endpoints.",
    "source": "hackernews",
    "date": "2023-12-01",
    "highlights": [
      "static binary",
      "no CUDA deps",
      "open-source",
      "roadmap"
    ]
  }
]