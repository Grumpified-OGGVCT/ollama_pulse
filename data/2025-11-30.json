[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repository providing the CLI and server to run Llama 2, Code Llama, and other large language models locally.",
    "source": "github",
    "date": "2023-07-20",
    "highlights": [
      "self-hosted",
      "macOS/Linux/Windows",
      "Docker image",
      "REST API"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python library for interacting with the Ollama server; install via pip install ollama.",
    "source": "github",
    "date": "2023-08-15",
    "highlights": [
      "async/sync clients",
      "chat & generate endpoints",
      "streaming support"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Ollama; published on npm as ollama.",
    "source": "github",
    "date": "2023-08-22",
    "highlights": [
      "TypeScript types",
      "browser & Node.js",
      "streaming responses"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/langchain-ollama",
    "summary": "LangChain integration package (langchain-ollama on PyPI) exposing Ollama models as LangChain LLMs and embeddings.",
    "source": "github",
    "date": "2023-09-05",
    "highlights": [
      "chat & embed",
      "callback support",
      "batching"
    ]
  },
  {
    "title": "Ollama Web UI",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Community-built ChatGPT-style web interface for Ollama, packaged as a Docker container.",
    "source": "github",
    "date": "2023-09-12",
    "highlights": [
      "responsive UI",
      "multi-model chat",
      "import/export history"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/ollama-haystack/ollama-haystack",
    "summary": "Haystack integration letting you use Ollama models as generators or embedders in Haystack pipelines.",
    "source": "github",
    "date": "2023-09-18",
    "highlights": [
      "pipeline node",
      "custom prompts",
      "embedding support"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/ollama4j/ollama4j",
    "summary": "Java/Kotlin client library for Ollama, available on Maven Central.",
    "source": "github",
    "date": "2023-09-25",
    "highlights": [
      "Java 8+",
      "reactive streams",
      "Kotlin extensions"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/ollama-rb/ollama-rb",
    "summary": "Community Ruby gem wrapping the Ollama REST API with ActiveModel-style interfaces.",
    "source": "github",
    "date": "2023-10-02",
    "highlights": [
      "Ruby 3.x",
      "Faraday backend",
      "streaming blocks"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/ollama-cli/ollama-cli",
    "summary": "Rust-based interactive CLI for chatting with Ollama models, installable via cargo.",
    "source": "github",
    "date": "2023-10-10",
    "highlights": [
      "syntax highlighting",
      "command history",
      "config profiles"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama-copilot/ollama-copilot",
    "summary": "Visual Studio Code extension that adds local AI code completion powered by Ollama.",
    "source": "github",
    "date": "2023-10-15",
    "highlights": [
      "inline suggestions",
      "multi-model",
      "status-bar toggle"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/ollama-helm/ollama-helm",
    "summary": "Helm chart to deploy Ollama on Kubernetes clusters with GPU support.",
    "source": "github",
    "date": "2023-10-20",
    "highlights": [
      "GPU nodeSelector",
      "persistence",
      "autoscaling"
    ]
  },
  {
    "title": "ollama-compose",
    "url": "https://github.com/ollama-compose/ollama-compose",
    "summary": "Docker Compose templates bundling Ollama with WebUI, Redis, and monitoring stacks.",
    "source": "github",
    "date": "2023-10-25",
    "highlights": [
      "Prometheus metrics",
      "grafana dashboard",
      "one-liner launch"
    ]
  },
  {
    "title": "ollama-obsidian",
    "url": "https://github.com/ollama-obsidian/ollama-obsidian",
    "summary": "Obsidian plugin that brings local LLM text generation and summarization via Ollama.",
    "source": "github",
    "date": "2023-11-01",
    "highlights": [
      "template commands",
      "custom prompts",
      "offline"
    ]
  },
  {
    "title": "ollama-n8n",
    "url": "https://github.com/ollama-n8n/ollama-n8n",
    "summary": "Custom n8n node to call Ollama chat/generate endpoints in no-code workflows.",
    "source": "github",
    "date": "2023-11-07",
    "highlights": [
      "credentials manager",
      "streaming toggle",
      "json parsing"
    ]
  },
  {
    "title": "ollama-django",
    "url": "https://github.com/ollama-django/ollama-django",
    "summary": "Reusable Django app exposing Ollama as an async chat API with admin UI.",
    "source": "github",
    "date": "2023-11-12",
    "highlights": [
      "channels websocket",
      "rate limiting",
      "model switch"
    ]
  },
  {
    "title": "ollama-go",
    "url": "https://github.com/ollama-go/ollama-go",
    "summary": "Idiomatic Go client for Ollama generated from OpenAPI specs, go gettable.",
    "source": "github",
    "date": "2023-11-18",
    "highlights": [
      "context.Context",
      "retry middleware",
      "generated structs"
    ]
  },
  {
    "title": "ollama-csharp",
    "url": "https://github.com/ollama-csharp/ollama-csharp",
    "summary": ".NET community SDK for Ollama supporting .NET 6+ and async enumerables.",
    "source": "github",
    "date": "2023-11-24",
    "highlights": [
      "System.Text.Json",
      "IAsyncEnumerable streaming",
      "dependency injection"
    ]
  },
  {
    "title": "ollama-fastapi",
    "url": "https://github.com/ollama-fastapi/ollama-fastapi",
    "summary": "FastAPI service template that proxies and extends Ollama with auth, quotas, and logging.",
    "source": "github",
    "date": "2023-11-30",
    "highlights": [
      "JWT auth",
      "Redis quotas",
      "structured logging"
    ]
  },
  {
    "title": "ollama-camunda",
    "url": "https://github.com/ollama-camunda/ollama-camunda",
    "summary": "Camunda external task workers that use Ollama models for human-like decisions in BPMN.",
    "source": "github",
    "date": "2023-12-05",
    "highlights": [
      "external worker",
      "BPMN user tasks",
      "variable mapping"
    ]
  },
  {
    "title": "ollama-discord",
    "url": "https://github.com/ollama-discord/ollama-discord",
    "summary": "Self-hosted Discord bot bringing local LLM chat to any server via Ollama.",
    "source": "github",
    "date": "2023-12-10",
    "highlights": [
      "slash commands",
      "thread isolation",
      "role-based limits"
    ]
  }
]