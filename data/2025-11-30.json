[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: lightweight, extensible framework for running Llama 2, Mistral, Gemma and other models locally with a single command.",
    "source": "github",
    "date": "2023-10-01",
    "highlights": [
      "CLI",
      "Docker",
      "macOS/Linux/Windows",
      "REST API",
      "model library"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for the Ollama server.",
    "source": "github",
    "date": "2023-11-15",
    "highlights": [
      "npm",
      "TypeScript",
      "Promise-based",
      "chat & generate endpoints"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client and asyncio bindings for Ollama.",
    "source": "github",
    "date": "2023-11-20",
    "highlights": [
      "PyPI",
      "async/await",
      "streaming",
      "embeddings"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/community/langchain_community/llms/ollama",
    "summary": "LangChain integration to use Ollama models as LLM or chat components.",
    "source": "github",
    "date": "2023-12-05",
    "highlights": [
      "pip install langchain-community",
      "chat models",
      "streaming",
      "callbacks"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich web UI for Ollama (chat UI, model management, multi-user).",
    "source": "github",
    "date": "2023-12-10",
    "highlights": [
      "Docker",
      "Dark/light mode",
      "code highlighting",
      "multi-model chat"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/ollama-cli/ollama-cli",
    "summary": "Interactive terminal UI for chatting with Ollama models (Rust-based).",
    "source": "github",
    "date": "2023-12-12",
    "highlights": [
      "Rust",
      "REPL",
      "syntax highlighting",
      "keyboard shortcuts"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/fostermaier/ollama-copilot",
    "summary": "VS Code extension that turns Ollama models into a GitHub Copilot replacement.",
    "source": "github",
    "date": "2023-12-18",
    "highlights": [
      "VS Code marketplace",
      "inline completions",
      "custom prompts"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java/Kotlin client for Ollama with fluent API and Spring Boot starter.",
    "source": "github",
    "date": "2023-12-20",
    "highlights": [
      "Maven Central",
      "Spring Boot",
      "reactive streams",
      "Kotlin extensions"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/ollama-rb/ollama-rb",
    "summary": "Ruby gem for integrating Ollama models into Rails or plain Ruby apps.",
    "source": "github",
    "date": "2023-12-22",
    "highlights": [
      "RubyGems",
      "Faraday",
      "streaming chat",
      "embeddings"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/deepset-ai/haystack-core-integrations/tree/main/integrations/ollama",
    "summary": "Haystack 2.0 integration to use Ollama models in RAG pipelines.",
    "source": "github",
    "date": "2024-01-10",
    "highlights": [
      "pip install haystack-ai[ollama]",
      "generator & embedder",
      "RAG"
    ]
  },
  {
    "title": "ollama-csharp",
    "url": "https://github.com/ollama-csharp/ollama-csharp",
    "summary": ".NET client for Ollama with async streaming and dependency injection support.",
    "source": "github",
    "date": "2024-01-12",
    "highlights": [
      "NuGet",
      ".NET 8",
      "System.Text.Json",
      "streaming"
    ]
  },
  {
    "title": "ollama-discord",
    "url": "https://github.com/ollama-discord/ollama-discord",
    "summary": "Self-host Discord bot that brings Ollama models into any server.",
    "source": "github",
    "date": "2024-01-15",
    "highlights": [
      "Slash commands",
      "threaded chats",
      "model switching",
      "Docker"
    ]
  },
  {
    "title": "ollama-slack",
    "url": "https://github.com/ollama-slack/ollama-slack",
    "summary": "Slack Bolt app to chat with local Ollama models directly in Slack.",
    "source": "github",
    "date": "2024-01-18",
    "highlights": [
      "Bolt JS",
      "socket mode",
      "threading",
      "app home"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/ollama-helm/ollama-helm",
    "summary": "Official Helm chart for deploying Ollama on Kubernetes clusters.",
    "source": "github",
    "date": "2024-01-20",
    "highlights": [
      "Helm",
      "GPU support",
      "PVC",
      "autoscaling"
    ]
  },
  {
    "title": "ollama-dagger",
    "url": "https://github.com/ollama-dagger/ollama-dagger",
    "summary": "Dagger module to spin up Ollama sidecars in CI pipelines for testing.",
    "source": "github",
    "date": "2024-01-22",
    "highlights": [
      "Daggerverse",
      "CI caching",
      "model pre-pull",
      "Go SDK"
    ]
  },
  {
    "title": "ollama-obsidian",
    "url": "https://github.com/ollama-obsidian/ollama-obsidian",
    "summary": "Obsidian plugin that adds local AI completions & summarization via Ollama.",
    "source": "github",
    "date": "2024-01-25",
    "highlights": [
      "Community plugin",
      "command palette",
      "template variables"
    ]
  },
  {
    "title": "ollama-nix",
    "url": "https://github.com/NixOS/nixpkgs/tree/master/pkgs/tools/misc/ollama",
    "summary": "Nix flake for reproducible Ollama installations across macOS/Linux.",
    "source": "github",
    "date": "2024-02-01",
    "highlights": [
      "nixpkgs",
      "CUDA/rocm",
      "declarative models",
      "module"
    ]
  },
  {
    "title": "ollama-rust",
    "url": "https://github.com/ollama-rust/ollama-rs",
    "summary": "Async Rust client for Ollama with tokio and serde support.",
    "source": "github",
    "date": "2024-02-05",
    "highlights": [
      "crates.io",
      "tokio",
      "Serde",
      "streaming"
    ]
  },
  {
    "title": "ollama-elixir",
    "url": "https://github.com/ollama-elixir/ollama_ex",
    "summary": "Elixir wrapper that brings Ollama models into Phoenix LiveView apps.",
    "source": "github",
    "date": "2024-02-08",
    "highlights": [
      "Hex.pm",
      "GenServer",
      "LiveView",
      "telemetry"
    ]
  },
  {
    "title": "ollama-zig",
    "url": "https://github.com/ollama-zig/ollama-zig",
    "summary": "Zig client library for Ollama with cross-compilation and static binary output.",
    "source": "github",
    "date": "2024-02-10",
    "highlights": [
      "Zig package manager",
      "static linking",
      "no libc"
    ]
  }
]