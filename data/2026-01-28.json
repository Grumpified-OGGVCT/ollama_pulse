[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "The official Ollama project that lets you run large language models locally with a simple CLI and REST API.",
    "source": "github",
    "date": "2024-04-15",
    "highlights": [
      "CLI",
      "REST API",
      "local LLM",
      "macOS/Linux/Windows",
      "Docker"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client library for Ollama.",
    "source": "github",
    "date": "2024-04-01",
    "highlights": [
      "npm",
      "TypeScript",
      "chat",
      "embeddings",
      "pull/push models"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client library for Ollama.",
    "source": "github",
    "date": "2024-04-10",
    "highlights": [
      "PyPI",
      "chat",
      "embeddings",
      "model management",
      "streaming"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/partners/ollama",
    "summary": "LangChain integration for Ollama models.",
    "source": "github",
    "date": "2024-03-20",
    "highlights": [
      "LangChain",
      "RAG",
      "agents",
      "streaming",
      "chat"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich web UI for Ollama with chat, model management, and RAG support.",
    "source": "github",
    "date": "2024-04-12",
    "highlights": [
      "React",
      "chat UI",
      "RAG",
      "Docker",
      "multi-user"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java/Kotlin client library for Ollama.",
    "source": "github",
    "date": "2024-03-28",
    "highlights": [
      "Java",
      "Kotlin",
      "Maven",
      "async",
      "streaming"
    ]
  },
  {
    "title": "ollama-rs",
    "url": "https://github.com/pepperoni21/ollama-rs",
    "summary": "Rust client library for Ollama.",
    "source": "github",
    "date": "2024-04-05",
    "highlights": [
      "Rust",
      "async",
      "tokio",
      "chat",
      "embeddings"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama/ollama-copilot",
    "summary": "VS Code extension bringing Ollama models into GitHub Copilot-like experience.",
    "source": "github",
    "date": "2024-04-08",
    "highlights": [
      "VS Code",
      "code completion",
      "inline chat",
      "FIM templates"
    ]
  },
  {
    "title": "ollama-discord",
    "url": "https://github.com/mxyng/discord-ollama",
    "summary": "Discord bot that integrates Ollama models into Discord servers.",
    "source": "github",
    "date": "2024-03-15",
    "highlights": [
      "Discord bot",
      "slash commands",
      "streaming",
      "multi-model"
    ]
  },
  {
    "title": "ollama-cli-chat",
    "url": "https://github.com/sugarforever/ollama-cli-chat",
    "summary": "Enhanced interactive CLI chat interface for Ollama with conversation history.",
    "source": "github",
    "date": "2024-04-02",
    "highlights": [
      "interactive chat",
      "history",
      "markdown",
      "syntax highlighting"
    ]
  },
  {
    "title": "ollama-streamlit",
    "url": "https://github.com/ivanfioravanti/chatbot-ollama",
    "summary": "Streamlit chatbot UI for Ollama with session memory.",
    "source": "github",
    "date": "2024-03-30",
    "highlights": [
      "Streamlit",
      "session memory",
      "Docker",
      "chat UI"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/deepset-ai/haystack-core-integrations/tree/main/integrations/ollama",
    "summary": "Haystack integration for Ollama models in NLP pipelines.",
    "source": "github",
    "date": "2024-04-09",
    "highlights": [
      "Haystack",
      "pipelines",
      "RAG",
      "generators",
      "embedders"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/otwld/ollama-helm",
    "summary": "Helm chart for deploying Ollama on Kubernetes.",
    "source": "github",
    "date": "2024-04-11",
    "highlights": [
      "Kubernetes",
      "Helm",
      "persistent storage",
      "GPU support"
    ]
  },
  {
    "title": "ollama-nix",
    "url": "https://github.com/ollama/ollama/tree/main/nix",
    "summary": "Nix flake for reproducible Ollama builds and deployments.",
    "source": "github",
    "date": "2024-03-25",
    "highlights": [
      "Nix",
      "flake",
      "reproducible",
      "declarative"
    ]
  },
  {
    "title": "ollama-rag",
    "url": "https://github.com/ivanfioravanti/ollama-rag",
    "summary": "Ready-to-use RAG pipeline combining Ollama with ChromaDB and LangChain.",
    "source": "github",
    "date": "2024-04-06",
    "highlights": [
      "RAG",
      "ChromaDB",
      "PDF ingestion",
      "Docker Compose"
    ]
  },
  {
    "title": "ollama-obsidian",
    "url": "https://github.com/hinterdupfinger/obsidian-ollama",
    "summary": "Obsidian plugin for local AI assistance using Ollama.",
    "source": "github",
    "date": "2024-03-18",
    "highlights": [
      "Obsidian",
      "note assistant",
      "local AI",
      "custom prompts"
    ]
  },
  {
    "title": "ollama-dagger",
    "url": "https://github.com/dagger/dagger/tree/main/sdk/python/src/dagger/client/gen_ollama.py",
    "summary": "Dagger SDK module for spinning up Ollama services in CI pipelines.",
    "source": "github",
    "date": "2024-04-04",
    "highlights": [
      "Dagger",
      "CI/CD",
      "containerized",
      "testing"
    ]
  },
  {
    "title": "ollama-mistral-finetune",
    "url": "https://github.com/ollama/ollama/tree/main/examples/finetune",
    "summary": "Example scripts for fine-tuning Mistral models and importing into Ollama.",
    "source": "github",
    "date": "2024-03-22",
    "highlights": [
      "fine-tune",
      "Mistral",
      "Modelfile",
      "LoRA"
    ]
  }
]