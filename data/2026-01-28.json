[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: self-hosted LLM runner with a REST API and CLI to pull, run, and chat with open-source models (Llama 2, Mistral, Gemma, etc.) on macOS, Linux, Windows.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "one-line install",
      "built-in model library",
      "OpenAI-compatible /chat endpoint",
      "GPU & CPU fallback"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client for Ollama; pip install ollama gives synchronous & async wrappers for generate, chat, embeddings, pull, list, etc.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "asyncio support",
      "streaming responses",
      "fully typed"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Node & browsers; npm install ollama provides chat, generate, pull, list, embeddings.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "ESM & CommonJS",
      "streaming fetch",
      "zero deps"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/langchain-ollama",
    "summary": "LangChain integration package; pip install langchain-ollama adds OllamaChatModel, OllamaEmbeddings, OllamaLLM with callback & tool-calling support.",
    "source": "github",
    "date": "2024-05-13",
    "highlights": [
      "tool calling beta",
      "streaming",
      "batch embeddings"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich web UI (formerly Ollama WebUI) that plugs into the local Ollama API; offers chat, workspace, RAG, multimodal, admin panel.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "Docker one-liner",
      "OpenAI drop-in",
      "PDF & web RAG",
      "role management"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/ollama4j/ollama4j",
    "summary": "Java/JVM client library for Ollama; Maven Central artifact provides sync/async APIs, streaming, POJO model mapping.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "Java 8+",
      "Spring Boot starter",
      "reactive streams"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/ollama/ollama-rb",
    "summary": "Official Ruby gem for Ollama; gem install ollama exposes generate, chat, pull, list, embeddings, streaming.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "Fiber-based streaming",
      "zero dependencies"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/technosophos/ollama-cli",
    "summary": "Rust CLI that wraps Ollama REST endpoints with ergonomic commands, config profiles, and shell completions.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "cross-platform binary",
      "config profiles",
      "fuzzy model finder"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama-copilot/ollama-copilot",
    "summary": "VS Code extension that turns local Ollama models into inline code copilots with autocomplete, explain, refactor, and unit-test actions.",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "inline completions",
      "custom prompts",
      "multi-model switch"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/ollama-haystack/ollama-haystack",
    "summary": "Haystack integration by community; provides OllamaGenerator, OllamaChatGenerator, and OllamaTextEmbedder nodes for RAG pipelines.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "pipeline YAML support",
      "streaming",
      "batch embed"
    ]
  },
  {
    "title": "ollama-cookbook",
    "url": "https://github.com/ollama/ollama-cookbook",
    "summary": "Community recipes: FastAPI chatbot, Next.js copilot, Discord bot, Obsidian plugin, Raspberry Pi deployment, GPU benchmarking scripts.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "FastAPI SSE",
      "Next.js Vercel template",
      "multi-arch Docker"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/ollama-helm/ollama-helm",
    "summary": "Helm chart for deploying Ollama on Kubernetes with autoscaling, PVC model cache, and optional GPU node-selector.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "GPU & CPU modes",
      "HPA ready",
      "model pre-load list"
    ]
  },
  {
    "title": "ollama-nim",
    "url": "https://github.com/ollama-nim/ollama-nim",
    "summary": "Nim client library for Ollama; nimble install ollama provides async HTTP, streaming JSON, and native model listing.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "asyncdispatch",
      "zero-copy streams",
      "Nim 1.6+"
    ]
  },
  {
    "title": "ollama-rust",
    "url": "https://github.com/ollama-rust/ollama-rs",
    "summary": "Community Rust crate offering strongly-typed async client for Ollama with Tokio, streaming, and serde models.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "Tokio runtime",
      "fully typed",
      "cargo install"
    ]
  },
  {
    "title": "ollama-dart",
    "url": "https://github.com/ollama-dart/ollama-dart",
    "summary": "Dart/Flutter package; pub.dev package adds Ollama client for chat, generate, embeddings with SSE streaming.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "Flutter ready",
      "SSE parser",
      "null-safe"
    ]
  },
  {
    "title": "ollama-csharp",
    "url": "https://github.com/ollama-csharp/ollama-csharp",
    "summary": ".NET community SDK for Ollama; NuGet package provides async chat, generate, embeddings, and tool-calling beta support.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "NET 6+",
      "System.Text.Json",
      "tool calling"
    ]
  },
  {
    "title": "ollama-gpt4all-ui",
    "url": "https://github.com/nomic-ai/gpt4all-ui",
    "summary": "Nomic\u2019s GPT4All UI now supports Ollama backend\u2014download any GGUF into Ollama and chat via a polished Qt desktop interface.",
    "source": "github",
    "date": "2024-05-13",
    "highlights": [
      "Qt GUI",
      "model manager",
      "local RAG folder"
    ]
  },
  {
    "title": "ollama-discord",
    "url": "https://github.com/ollama-discord/ollama-discord",
    "summary": "Self-hosted Discord bot that exposes Ollama models as slash commands with per-guild model selection and moderation filters.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "slash commands",
      "guild configs",
      "rate limiting"
    ]
  },
  {
    "title": "ollama-slack",
    "url": "https://github.com/ollama-slack/ollama-slack",
    "summary": "Slack Bolt app that brings local Ollama models into channels/DMs with thread support and file snippet RAG.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "threading",
      "file RAG",
      "socket mode"
    ]
  },
  {
    "title": "ollama-obsidian",
    "url": "https://github.com/ollama-obsidian/ollama-obsidian",
    "summary": "Obsidian community plugin to run local LLMs via Ollama for note summarization, Q&A, and inline text generation.",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "command palette",
      "template prompts",
      "offline"
    ]
  }
]