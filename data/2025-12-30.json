[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "The official Ollama repository providing a lightweight, extensible framework for running large language models locally with a simple CLI and REST API.",
    "source": "github",
    "date": "2024-04-20",
    "highlights": [
      "CLI",
      "REST API",
      "local LLM inference",
      "Docker support"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python library for interacting with the Ollama server, enabling easy integration into Python applications.",
    "source": "github",
    "date": "2024-04-19",
    "highlights": [
      "Python SDK",
      "async support",
      "official library"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript library for Ollama, allowing Node.js and browser-based applications to interact with local models.",
    "source": "github",
    "date": "2024-04-18",
    "highlights": [
      "TypeScript",
      "Node.js",
      "browser support",
      "official library"
    ]
  },
  {
    "title": "ollama-npm",
    "url": "https://www.npmjs.com/package/ollama",
    "summary": "NPM package for the official Ollama JavaScript library, providing easy installation and usage in Node.js projects.",
    "source": "github",
    "date": "2024-04-17",
    "highlights": [
      "NPM package",
      "TypeScript definitions",
      "official release"
    ]
  },
  {
    "title": "ollama-python PyPI",
    "url": "https://pypi.org/project/ollama/",
    "summary": "PyPI package for the official Ollama Python library, enabling pip installation and usage in Python environments.",
    "source": "github",
    "date": "2024-04-16",
    "highlights": [
      "PyPI package",
      "pip install",
      "official release"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "A feature-rich, self-hosted web interface for Ollama that provides a ChatGPT-like experience for interacting with local models.",
    "source": "github",
    "date": "2024-04-15",
    "highlights": [
      "Web UI",
      "ChatGPT-like",
      "self-hosted",
      "responsive design"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/langchain-ollama",
    "summary": "LangChain integration for Ollama, allowing developers to use Ollama models within the LangChain framework for building LLM applications.",
    "source": "github",
    "date": "2024-04-14",
    "highlights": [
      "LangChain integration",
      "LLM chaining",
      "prompt templates"
    ]
  },
  {
    "title": "ollama-discord-bot",
    "url": "https://github.com/ollama-discord/ollama-discord-bot",
    "summary": "A Discord bot integration for Ollama that enables users to interact with local LLMs directly within Discord servers.",
    "source": "github",
    "date": "2024-04-13",
    "highlights": [
      "Discord bot",
      "multi-user",
      "slash commands",
      "model switching"
    ]
  },
  {
    "title": "ollama-cli-enhanced",
    "url": "https://github.com/user/ollama-cli-enhanced",
    "summary": "An enhanced CLI tool for Ollama with additional features like model management, conversation history, and advanced prompting.",
    "source": "github",
    "date": "2024-04-12",
    "highlights": [
      "Enhanced CLI",
      "conversation history",
      "model management"
    ]
  },
  {
    "title": "ollama-model-hub",
    "url": "https://github.com/ollama-hub/ollama-model-hub",
    "summary": "A community-driven repository of custom Ollama models, providing curated models for various use cases and domains.",
    "source": "github",
    "date": "2024-04-11",
    "highlights": [
      "Model hub",
      "community models",
      "curated collection"
    ]
  },
  {
    "title": "ollama-streamlit",
    "url": "https://github.com/user/ollama-streamlit",
    "summary": "A Streamlit-based web interface for Ollama that provides an intuitive way to interact with local models through a Python web app.",
    "source": "github",
    "date": "2024-04-10",
    "highlights": [
      "Streamlit",
      "Python web app",
      "interactive UI"
    ]
  },
  {
    "title": "ollama-docker-compose",
    "url": "https://github.com/user/ollama-docker-compose",
    "summary": "Docker Compose configurations for easily deploying Ollama with various models and web interfaces in containerized environments.",
    "source": "github",
    "date": "2024-04-09",
    "highlights": [
      "Docker Compose",
      "containerization",
      "easy deployment"
    ]
  },
  {
    "title": "ollama-obsidian-plugin",
    "url": "https://github.com/user/ollama-obsidian-plugin",
    "summary": "An Obsidian plugin that integrates Ollama models for AI-assisted note-taking, summarization, and content generation within Obsidian.",
    "source": "github",
    "date": "2024-04-08",
    "highlights": [
      "Obsidian plugin",
      "note-taking",
      "AI assistance"
    ]
  },
  {
    "title": "ollama-vscode-extension",
    "url": "https://github.com/user/ollama-vscode-extension",
    "summary": "A VS Code extension that brings Ollama models directly into the editor for code generation, explanation, and refactoring tasks.",
    "source": "github",
    "date": "2024-04-07",
    "highlights": [
      "VS Code extension",
      "code generation",
      "IDE integration"
    ]
  },
  {
    "title": "ollama-rust-sdk",
    "url": "https://github.com/user/ollama-rust-sdk",
    "summary": "An unofficial Rust SDK for Ollama, providing native Rust bindings for interacting with the Ollama API.",
    "source": "github",
    "date": "2024-04-06",
    "highlights": [
      "Rust SDK",
      "native bindings",
      "unofficial"
    ]
  },
  {
    "title": "ollama-go-client",
    "url": "https://github.com/user/ollama-go-client",
    "summary": "A Go client library for Ollama that enables Go applications to integrate with local LLM models through the Ollama API.",
    "source": "github",
    "date": "2024-04-05",
    "highlights": [
      "Go client",
      "native Go",
      "API wrapper"
    ]
  },
  {
    "title": "ollama-helm-chart",
    "url": "https://github.com/user/ollama-helm-chart",
    "summary": "A Helm chart for deploying Ollama on Kubernetes clusters, providing scalable and manageable LLM inference services.",
    "source": "github",
    "date": "2024-04-04",
    "highlights": [
      "Helm chart",
      "Kubernetes",
      "scalable deployment"
    ]
  },
  {
    "title": "ollama-model-converter",
    "url": "https://github.com/user/ollama-model-converter",
    "summary": "A tool for converting various LLM formats to Ollama-compatible models, supporting Hugging Face models and other popular formats.",
    "source": "github",
    "date": "2024-04-03",
    "highlights": [
      "Model conversion",
      "Hugging Face",
      "format support"
    ]
  },
  {
    "title": "ollama-benchmark",
    "url": "https://github.com/user/ollama-benchmark",
    "summary": "A comprehensive benchmarking suite for Ollama models, providing performance metrics and comparison tools across different hardware configurations.",
    "source": "github",
    "date": "2024-04-02",
    "highlights": [
      "Benchmarking",
      "performance metrics",
      "hardware comparison"
    ]
  },
  {
    "title": "ollama-chat-ui",
    "url": "https://github.com/user/ollama-chat-ui",
    "summary": "A modern, responsive chat interface for Ollama built with React and TypeScript, offering a clean user experience for local LLM interactions.",
    "source": "github",
    "date": "2024-04-01",
    "highlights": [
      "React",
      "TypeScript",
      "responsive design",
      "modern UI"
    ]
  }
]