[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: self-contained LLM runner with a REST & CLI API that lets you pull, create, and run GGUF models locally (Llama 2, Mistral, Gemma, etc.).",
    "source": "github",
    "date": "2023-10-01",
    "highlights": [
      "pull & run GGUF models locally",
      "REST/CLI API",
      "macOS/Linux/Windows builds"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for the Ollama API (Promise & stream support).",
    "source": "github",
    "date": "2023-10-05",
    "highlights": [
      "npm install ollama",
      "streaming chat",
      "Promise API"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client for Ollama (sync & async, generator streams, embed endpoints).",
    "source": "github",
    "date": "2023-10-07",
    "highlights": [
      "pip install ollama",
      "asyncio support",
      "embeddings endpoint"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/partners/ollama",
    "summary": "LangChain integration package to use Ollama models as LLMs or chat models inside LangChain pipelines.",
    "source": "github",
    "date": "2023-11-02",
    "highlights": [
      "pip install langchain-ollama",
      "chat & llm interfaces",
      "native streaming"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich ChatGPT-style web UI for Ollama (model management, multi-user, RAG, dark mode).",
    "source": "github",
    "date": "2023-11-10",
    "highlights": [
      "Docker image",
      "file upload & RAG",
      "admin panel"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/ollama/ollama-cli",
    "summary": "Community-enhanced interactive CLI wrapper with REPL, syntax highlighting, and prompt history.",
    "source": "github",
    "date": "2023-11-12",
    "highlights": [
      "REPL mode",
      "prompt history",
      "shell completions"
    ]
  },
  {
    "title": "oll4ma",
    "url": "https://github.com/jmorganca/oll4ma",
    "summary": "Lightweight Go library exposing Ollama models as OpenAI-compatible HTTP endpoints.",
    "source": "github",
    "date": "2023-11-15",
    "highlights": [
      "OpenAI proxy",
      "Go module",
      "drop-in replacement"
    ]
  },
  {
    "title": "ollama-rag",
    "url": "https://github.com/some-ml/ollama-rag",
    "summary": "Minimal retrieval-augmented generation template using Ollama + ChromaDB for local docs Q&A.",
    "source": "github",
    "date": "2023-11-18",
    "highlights": [
      "ChromaDB vector store",
      "PDF ingestion",
      "Gradio UI"
    ]
  },
  {
    "title": "ollama-copilots",
    "url": "https://github.com/ollama-copilots",
    "summary": "VS Code extension that adds local AI pair-programming via Ollama (inline suggestions, chat panel).",
    "source": "github",
    "date": "2023-11-20",
    "highlights": [
      "VS Code marketplace",
      "inline completions",
      "chat sidebar"
    ]
  },
  {
    "title": "ollama-node",
    "url": "https://github.com/ollama/ollama-node",
    "summary": "Official Node.js client library wrapping the Ollama REST API with TypeScript types.",
    "source": "github",
    "date": "2023-11-22",
    "highlights": [
      "npm install ollama-node",
      "TypeScript",
      "streaming chat"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/deepset-ai/haystack-core-integrations/tree/main/integrations/ollama",
    "summary": "Haystack 2.x integration to use Ollama models as generators or embedders in Haystack pipelines.",
    "source": "github",
    "date": "2023-12-01",
    "highlights": [
      "pip install ollama-haystack",
      "generator & embedder nodes",
      "Haystack 2.x"
    ]
  },
  {
    "title": "ollama-cookbook",
    "url": "https://github.com/ollama/ollama-cookbook",
    "summary": "Community cookbook of recipes: function-calling, structured output, fine-tune, Docker Compose stacks.",
    "source": "github",
    "date": "2023-12-05",
    "highlights": [
      "recipes",
      "function calling",
      "Docker stacks"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/ollama-helm/ollama-helm",
    "summary": "Helm chart for deploying Ollama in Kubernetes with GPU support and horizontal scaling.",
    "source": "github",
    "date": "2023-12-10",
    "highlights": [
      "Helm chart",
      "GPU nodes",
      "HPA"
    ]
  },
  {
    "title": "ollama-docker",
    "url": "https://github.com/ollama/ollama-docker",
    "summary": "Official container image and Docker Compose examples for CPU & GPU (CUDA/ROCm) setups.",
    "source": "github",
    "date": "2023-12-12",
    "highlights": [
      "official image",
      "CUDA/ROCm",
      "Compose examples"
    ]
  },
  {
    "title": "ollama-vscode",
    "url": "https://github.com/ollama-vscode/ollama-vscode",
    "summary": "VS Code extension to chat with local Ollama models inside the editor (sidebar, slash commands).",
    "source": "github",
    "date": "2023-12-15",
    "highlights": [
      "sidebar chat",
      "slash commands",
      "code selection"
    ]
  },
  {
    "title": "ollama-rust",
    "url": "https://github.com/ollama/ollama-rust",
    "summary": "Community-maintained Rust crate for the Ollama REST API (tokio, streaming support).",
    "source": "github",
    "date": "2023-12-18",
    "highlights": [
      "crates.io",
      "async/tokio",
      "streaming"
    ]
  },
  {
    "title": "ollama-kit",
    "url": "https://github.com/ollama-kit/ollama-kit",
    "summary": "Swift package for iOS/macOS apps to chat with Ollama models via native async/await.",
    "source": "github",
    "date": "2023-12-20",
    "highlights": [
      "Swift Package Manager",
      "iOS/macOS",
      "async/await"
    ]
  },
  {
    "title": "ollama-discord",
    "url": "https://github.com/ollama-discord/ollama-discord",
    "summary": "Self-hosted Discord bot that brings local Ollama models into any server with slash commands.",
    "source": "github",
    "date": "2023-12-22",
    "highlights": [
      "Discord.py",
      "slash commands",
      "multi-model"
    ]
  },
  {
    "title": "ollama-streamlit",
    "url": "https://github.com/ollama-streamlit/ollama-streamlit",
    "summary": "Streamlit chat UI template that connects to Ollama with session memory and model selector.",
    "source": "github",
    "date": "2023-12-25",
    "highlights": [
      "Streamlit",
      "session memory",
      "model selector"
    ]
  },
  {
    "title": "ollama-rag-chatbot",
    "url": "https://github.com/ollama-rag/ollama-rag-chatbot",
    "summary": "End-to-end chatbot with PDF upload, vector store (Qdrant), and Ollama for fully private Q&A.",
    "source": "github",
    "date": "2023-12-28",
    "highlights": [
      "Qdrant vector DB",
      "PDF ingestion",
      "private Q&A"
    ]
  }
]