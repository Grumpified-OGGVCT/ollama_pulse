[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: get up and running with Llama 2, Mistral, Gemma, and other large language models locally.",
    "source": "github",
    "date": "2024-04-20",
    "highlights": [
      "self-hosted LLM inference",
      "Docker/CLI tooling",
      "model library"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Ollama, published on npm as \u2018ollama\u2019.",
    "source": "github",
    "date": "2024-04-18",
    "highlights": [
      "Promise-based API",
      "browser & Node",
      "chat & embed endpoints"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client for Ollama, available on PyPI.",
    "source": "github",
    "date": "2024-04-19",
    "highlights": [
      "sync/async APIs",
      "streaming responses",
      "built-in embeddings"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/partners/ollama",
    "summary": "LangChain integration package to use Ollama models as LLMs or embedders.",
    "source": "github",
    "date": "2024-04-15",
    "highlights": [
      "pip install langchain-ollama",
      "chat & embed bindings",
      "chain compatibility"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich web UI for Ollama (chat, model management, multi-user).",
    "source": "github",
    "date": "2024-04-20",
    "highlights": [
      "Docker one-liner",
      "dark/light themes",
      "code highlighting"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java/Kotlin client for Ollama with Spring Boot starters on Maven Central.",
    "source": "github",
    "date": "2024-04-17",
    "highlights": [
      "fluent API",
      "reactive streams",
      "Spring auto-config"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/ollama/ollama-rb",
    "summary": "Community-maintained Ruby gem for chatting with Ollama models.",
    "source": "github",
    "date": "2024-04-14",
    "highlights": [
      "Ruby >= 3",
      "Faraday backend",
      "streaming support"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/salty-flower/ollama-cli",
    "summary": "Cross-platform TUI client written in Rust for interactive Ollama chats.",
    "source": "github",
    "date": "2024-04-16",
    "highlights": [
      "keyboard shortcuts",
      "conversation history",
      "cargo install"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama/ollama-copilot",
    "summary": "VS Code extension that turns any Ollama model into a GitHub Copilot replacement.",
    "source": "github",
    "date": "2024-04-19",
    "highlights": [
      "inline completions",
      "custom prompts",
      "local only"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/deepset-ai/haystack-integrations/tree/main/integrations/ollama",
    "summary": "Haystack integration to use Ollama models in retrieval pipelines.",
    "source": "github",
    "date": "2024-04-12",
    "highlights": [
      "Generator & Embedder nodes",
      "pip install farm-haystack[ollama]"
    ]
  },
  {
    "title": "ollama-cookbook",
    "url": "https://github.com/ollama/ollama-cookbook",
    "summary": "Community recipes: FastAPI backend, NextChat UI, model fine-tune tips.",
    "source": "github",
    "date": "2024-04-20",
    "highlights": [
      "docker-compose stacks",
      "OpenAI-compatible proxy",
      "GPU notes"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/otwld/ollama-helm",
    "summary": "Production-ready Helm chart for deploying Ollama on Kubernetes.",
    "source": "github",
    "date": "2024-04-18",
    "highlights": [
      "GPU nodeSelector",
      "PVC model cache",
      "autoscaling"
    ]
  },
  {
    "title": "ollama.nvim",
    "url": "https://github.com/nomnivore/ollama.nvim",
    "summary": "Neovim plugin to chat with Ollama models inside the editor.",
    "source": "github",
    "date": "2024-04-17",
    "highlights": [
      "Lua config",
      "keymap actions",
      "split or float layouts"
    ]
  },
  {
    "title": "ollama-dagger",
    "url": "https://github.com/shykes/ollama-dagger",
    "summary": "Dagger module that spins up Ollama as a CI service for testing LLM features.",
    "source": "github",
    "date": "2024-04-15",
    "highlights": [
      "GitHub Actions example",
      "caching models",
      "parallel tests"
    ]
  },
  {
    "title": "reddit/r/ollama \u2013 weekly discussion",
    "url": "https://www.reddit.com/r/ollama/comments/1c8xyrj/weekly_discussion_thread/",
    "summary": "Active community thread sharing model files, GPU tweaks, and integrations.",
    "source": "reddit",
    "date": "2024-04-21",
    "highlights": [
      "user Modfile recipes",
      "M-series Mac performance",
      "Windows WSL tips"
    ]
  },
  {
    "title": "ollama-ui-streamlit",
    "url": "https://github.com/mneedham/ollama-ui-streamlit",
    "summary": "Minimal Streamlit chat app that proxies to Ollama, runnable in one command.",
    "source": "github",
    "date": "2024-04-13",
    "highlights": [
      "pip install streamlit-ollama",
      "session memory",
      "Dockerfile"
    ]
  },
  {
    "title": "ollama-swift",
    "url": "https://github.com/kyle-carlson/ollama-swift",
    "summary": "Swift Package Manager client for iOS/macOS apps to talk to Ollama.",
    "source": "github",
    "date": "2024-04-14",
    "highlights": [
      "async/await",
      "SwiftUI example",
      "codable models"
    ]
  },
  {
    "title": "ollama-obsidian",
    "url": "https://github.com/hintergrund/ollama-obsidian",
    "summary": "Obsidian plugin that lets you summarize notes or brainstorm with local models.",
    "source": "github",
    "date": "2024-04-16",
    "highlights": [
      "command palette",
      "template prompts",
      "offline only"
    ]
  },
  {
    "title": "ollama-telegram",
    "url": "https://github.com/rueedlinger/ollama-telegram",
    "summary": "Telegram bot server (Go) that answers users via your self-hosted Ollama.",
    "source": "github",
    "date": "2024-04-19",
    "highlights": [
      "multi-chat isolation",
      "rate limiting",
      "docker image"
    ]
  },
  {
    "title": "ollama-huggingface-hub",
    "url": "https://github.com/ollama-hub/ollama-huggingface",
    "summary": "Community registry pushing Hugging Face models into Ollama Modfile format.",
    "source": "github",
    "date": "2024-04-20",
    "highlights": [
      "automated PRs",
      "GGUF conversions",
      "version tags"
    ]
  }
]