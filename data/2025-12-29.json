[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: self-hosted LLM runner with a REST/CLI API, macOS/Linux binaries, and built-in model library.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "REST API",
      "CLI",
      "built-in model hub",
      "macOS/Linux support"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "First-party Python client and async helpers for the Ollama API.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "pip install ollama",
      "async/await",
      "streaming responses"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for browsers & Node.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "npm i ollama",
      "TypeScript types",
      "browser & Node"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/partners/ollama",
    "summary": "LangChain adapter that adds Ollama models to chains, agents, and retrieval pipelines.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "pip install langchain-ollama",
      "ChatOllama",
      "embeddings"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich web UI (chat, file upload, multi-user) that talks to local Ollama.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "Docker image",
      "file upload",
      "multi-model chats"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/ollama-cli/ollama-cli",
    "summary": "Community Rust CLI with interactive chat, prompt templates, and shell completion.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "Rust binary",
      "interactive REPL",
      "prompt templates"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama-copilot/ollama-copilot",
    "summary": "VS Code extension that turns any Ollama model into a GitHub-Copilot-like pair programmer.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "VS Code",
      "inline completions",
      "custom models"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/ollama-helm/ollama-helm",
    "summary": "Helm chart for deploying Ollama on Kubernetes with GPU node selection and PVC support.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "Helm",
      "GPU nodes",
      "PVC"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/ollama-rb/ollama-rb",
    "summary": "Community-maintained Ruby gem wrapping the Ollama REST API.",
    "source": "github",
    "date": "2024-05-04",
    "highlights": [
      "gem install ollama",
      "Ruby DSL",
      "streaming"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/ollama4j/ollama4j",
    "summary": "Lightweight Java client for Ollama with Spring Boot starters and Kotlin extensions.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "Maven Central",
      "Spring Boot",
      "Kotlin"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/ollama-haystack/ollama-haystack",
    "summary": "Haystack integration to use Ollama models as generators or embedders in pipelines.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "pip install ollama-haystack",
      "RAG pipelines",
      "embeddings"
    ]
  },
  {
    "title": "ollama-csharp",
    "url": "https://github.com/ollama-csharp/ollama-csharp",
    "summary": ".NET SDK for Ollama with IAsyncEnumerable streaming and dependency-injection helpers.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "NuGet",
      "IAsyncEnumerable",
      "DI helpers"
    ]
  },
  {
    "title": "ollama-dagger",
    "url": "https://github.com/ollama-dagger/ollama-dagger",
    "summary": "Dagger (CI) module that spins up Ollama containers for reproducible LLM tests in pipelines.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "Dagger module",
      "CI tests",
      "containers"
    ]
  },
  {
    "title": "ollama-obsidian",
    "url": "https://github.com/ollama-obsidian/ollama-obsidian",
    "summary": "Obsidian plugin to summarize notes, generate flashcards, or answer questions via local Ollama.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "Obsidian",
      "summarize",
      "flashcards"
    ]
  },
  {
    "title": "ollama-n8n",
    "url": "https://github.com/ollama-n8n/ollama-n8n",
    "summary": "n8n community node that adds Ollama chat, completion, and embedding actions to workflows.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "n8n node",
      "workflows",
      "embeddings"
    ]
  },
  {
    "title": "ollama-ray",
    "url": "https://github.com/ollama-ray/ollama-ray",
    "summary": "Ray Serve deployment example for scaling Ollama models across GPU workers.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "Ray Serve",
      "GPU scaling",
      "batching"
    ]
  },
  {
    "title": "ollama-fastapi",
    "url": "https://github.com/ollama-fastapi/ollama-fastapi",
    "summary": "FastAPI wrapper adding OpenAI-compatible endpoints on top of local Ollama for drop-in replacement.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "OpenAI-compatible",
      "FastAPI",
      "drop-in"
    ]
  },
  {
    "title": "ollama-go",
    "url": "https://github.com/ollama-go/ollama-go",
    "summary": "Idiomatic Go client with context cancellation and streaming support.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "Go module",
      "context",
      "streaming"
    ]
  },
  {
    "title": "ollama-docker-compose",
    "url": "https://github.com/ollama-docker-compose/ollama-docker-compose",
    "summary": "Ready-to-run Docker Compose stacks bundling Ollama with WebUI, Postgres vector DB, and nginx.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "Compose",
      "WebUI",
      "Postgres pgvector"
    ]
  },
  {
    "title": "ollama-rust",
    "url": "https://github.com/ollama-rust/ollama-rust",
    "summary": "Rust crate providing strongly-typed async bindings to the Ollama REST API.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "crates.io",
      "tokio",
      "serde"
    ]
  }
]