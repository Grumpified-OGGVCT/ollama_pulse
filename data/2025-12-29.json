[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official CLI and Python/JS libraries to pull, build, run GGML/GGUF models locally with an OpenAI-style HTTP API.",
    "source": "github",
    "date": "2024-05-20",
    "highlights": [
      "self-contained binary",
      "model library",
      "REST API",
      "macOS/Linux/Windows"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client that wraps the Ollama REST API for chat, generate, embed, pull, push, create, delete.",
    "source": "github",
    "date": "2024-05-18",
    "highlights": [
      "sync & async",
      "streaming",
      "embeddings",
      "PyPI: ollama"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official TypeScript/JavaScript client for Node, Deno & browsers; same chat/generate/embed methods as Python.",
    "source": "github",
    "date": "2024-05-19",
    "highlights": [
      "npm: ollama",
      "streaming",
      "browser support",
      "ESM"
    ]
  },
  {
    "title": "langchain-ollama (PyPI)",
    "url": "https://pypi.org/project/langchain-ollama/",
    "summary": "LangChain adapter providing Ollama LLM & embeddings components with standard LangChain interface.",
    "source": "github",
    "date": "2024-05-15",
    "highlights": [
      "pip install langchain-ollama",
      "chat",
      "embeddings",
      "tool calling"
    ]
  },
  {
    "title": "ollama-webui (ollama-webui/ollama-webui)",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Full-featured ChatGPT-style web UI for Ollama with multi-model chats, code highlighting, RAG, user auth.",
    "source": "github",
    "date": "2024-05-20",
    "highlights": [
      "Docker image",
      "file upload & RAG",
      "admin panel",
      "dark mode"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java/Kotlin client for Ollama offering sync/async APIs and Spring Boot starter.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "Maven Central",
      "Spring starter",
      "Kotlin coroutines"
    ]
  },
  {
    "title": "ollama-cli (npm)",
    "url": "https://www.npmjs.com/package/ollama-cli",
    "summary": "Interactive CLI menu to list, pull, run, and chat with any Ollama model from the terminal.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "interactive prompts",
      "auto-pull",
      "chat history"
    ]
  },
  {
    "title": "ollama-copilot (JetBrains plugin)",
    "url": "https://github.com/continuum-industries/ollama-copilot",
    "summary": "JetBrains IDE plugin that adds an Ollama-powered copilot pane with chat and inline completions.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "IDE integration",
      "inline completion",
      "custom prompts"
    ]
  },
  {
    "title": "ollama-rag (langchain sample)",
    "url": "https://github.com/omarsar/ollama-rag",
    "summary": "Minimal repo showing how to build a RAG pipeline with Ollama, LangChain & Chroma.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "PDF ingestion",
      "ChromaDB",
      "streaming answers"
    ]
  },
  {
    "title": "ollama-discord-bot",
    "url": "https://github.com/rajtilak-2020/ollama-discord-bot",
    "summary": "Discord.py bot that lets servers chat with local Ollama models via slash commands.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "slash commands",
      "model switching",
      "typing indicator"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/otwld/ollama-helm",
    "summary": "Community-maintained Helm chart to deploy Ollama on Kubernetes with GPU support.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "GPU node selector",
      "PVC for models",
      "autoscaling"
    ]
  },
  {
    "title": "ollama-models (Hugging Face)",
    "url": "https://huggingface.co/ollama",
    "summary": "Official Hugging Face org hosting GGUF versions of popular models ready for ollama pull.",
    "source": "github",
    "date": "2024-05-19",
    "highlights": [
      "Llama-3",
      "Phi-3",
      "Mistral",
      " quantized GGUF"
    ]
  },
  {
    "title": "ollama-codellama-vscode",
    "url": "https://github.com/jmorganca/ollama-codellama-vscode",
    "summary": "VS Code extension that adds CodeLlama code completion powered by local Ollama instance.",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "inline suggestions",
      "multi-language",
      "configurable endpoint"
    ]
  },
  {
    "title": "ollama-express-api",
    "url": "https://github.com/ryanhex53/ollama-express-api",
    "summary": "Lightweight Express.js wrapper exposing extra endpoints for batch generate, whisper, and TTS.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "batch generate",
      "OpenAI-compatible",
      "Docker"
    ]
  },
  {
    "title": "ollama-grpc",
    "url": "https://github.com/songquanpeng/ollama-grpc",
    "summary": "gRPC server/proto definitions for Ollama enabling high-performance streaming from non-HTTP clients.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "protobuf",
      "streaming",
      "Go client example"
    ]
  },
  {
    "title": "ollama-rust",
    "url": "https://github.com/pepperoni21/ollama-rust",
    "summary": "Community Rust crate providing async wrappers for the Ollama REST API with Tokio.",
    "source": "github",
    "date": "2024-05-13",
    "highlights": [
      "crates.io: ollama-rs",
      "async/await",
      "streaming"
    ]
  },
  {
    "title": "ollama-csharp",
    "url": "https://github.com/awaescher/ollama-csharp",
    "summary": ".NET client for Ollama with chat & generate methods, built-in streaming IAsyncEnumerable support.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "NuGet: Ollama",
      "IAsyncEnumerable",
      "ASP.NET sample"
    ]
  },
  {
    "title": "ollama-obsidian",
    "url": "https://github.com/hinterlandsupply/ollama-obsidian",
    "summary": "Obsidian plugin to summarize notes, brainstorm ideas, and answer questions using local Ollama models.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "command palette",
      "template prompts",
      "offline"
    ]
  },
  {
    "title": "ollama-slack-bot",
    "url": "https://github.com/andrewyager/ollama-slack-bot",
    "summary": "Slack Bolt app that adds /ollama slash command to query local models with per-channel history.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "Bolt framework",
      "threading",
      "permissions"
    ]
  },
  {
    "title": "ollama-qt-client",
    "url": "https://github.com/sandro-h/ollama-qt-client",
    "summary": "Cross-platform Qt6 desktop GUI for Ollama with conversation management and model switching.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "Qt6",
      "Windows/Linux/macOS",
      "chat history"
    ]
  }
]