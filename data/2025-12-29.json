[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Get up and running with Llama 3, Mistral, Gemma 2, and other large language models locally.",
    "source": "github",
    "date": "2024-06-15",
    "highlights": [
      "self-contained CLI",
      "model management",
      "Docker images"
    ]
  },
  {
    "title": "langchain-ai/langchain",
    "url": "https://github.com/langchain-ai/langchain",
    "summary": "LangChain\u2019s Ollama integration lets you call any model served by your local Ollama instance as a standard LangChain LLM or chat model.",
    "source": "github",
    "date": "2024-06-10",
    "highlights": [
      "langchain-community.llms.Ollama",
      "streaming support",
      "chat model wrapper"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python library for Ollama; chat, generate, embed, pull, list, delete models via Python.",
    "source": "github",
    "date": "2024-06-12",
    "highlights": [
      "pip install ollama",
      "asyncio support",
      "embedding endpoint"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript / TypeScript client for Ollama; works in Node and browsers (via proxy).",
    "source": "github",
    "date": "2024-06-11",
    "highlights": [
      "npm install ollama",
      "Promise-based",
      "TypeScript types"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich web UI for Ollama (ChatGPT-style interface, model manager, multi-user).",
    "source": "github",
    "date": "2024-06-13",
    "highlights": [
      "Docker one-liner",
      "dark/light themes",
      "code highlighting"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/sugarforever/ollama-cli",
    "summary": "Interactive CLI wrapper around Ollama with chat history, prompt templates, and markdown rendering.",
    "source": "github",
    "date": "2024-05-30",
    "highlights": [
      "history file",
      "prompt templates",
      "syntax highlighting"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama/ollama-copilot",
    "summary": "VS Code extension that turns any Ollama model into a GitHub Copilot replacement.",
    "source": "github",
    "date": "2024-06-01",
    "highlights": [
      "inline completions",
      "custom model pick",
      "status-bar toggle"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/otwld/ollama-helm",
    "summary": "Production-ready Helm chart for deploying Ollama on Kubernetes with GPU support.",
    "source": "github",
    "date": "2024-06-05",
    "highlights": [
      "GPU node-selector",
      "PVC model cache",
      "autoscaling"
    ]
  },
  {
    "title": "ollama-unified",
    "url": "https://github.com/jmorganca/ollama-unified",
    "summary": "Experimental repo showing how to bundle multiple GGUF models into one Ollama Modelfile.",
    "source": "github",
    "date": "2024-05-28",
    "highlights": [
      "multi-model file",
      "quantization mix",
      "size optimization"
    ]
  },
  {
    "title": "ollama-gui",
    "url": "https://github.com/ollama/ollama-gui",
    "summary": "Cross-platform desktop GUI for Ollama built with Tauri and React.",
    "source": "github",
    "date": "2024-06-03",
    "highlights": [
      "native binaries",
      "auto-updater",
      "system tray"
    ]
  },
  {
    "title": "ollama-chatbot",
    "url": "https://github.com/sanchit-gandhi/ollama-chatbot",
    "summary": "Minimal Streamlit chatbot that connects to local Ollama for RAG-style Q&A over PDFs.",
    "source": "github",
    "date": "2024-05-25",
    "highlights": [
      "PDF ingestion",
      "Chroma vector store",
      "streaming chat"
    ]
  },
  {
    "title": "ollama-nvim",
    "url": "https://github.com/nomnivore/ollama-nvim",
    "summary": "Neovim plugin to query Ollama models inside the editor for code explanation or generation.",
    "source": "github",
    "date": "2024-06-07",
    "highlights": [
      "Lua config",
      "selection prompt",
      "split window output"
    ]
  },
  {
    "title": "ollama-rag",
    "url": "https://github.com/ggerganov/ollama-rag",
    "summary": "Reference implementation of retrieval-augmented generation using Ollama and Sentence-Transformers.",
    "source": "github",
    "date": "2024-05-29",
    "highlights": [
      "FAISS index",
      "embed endpoint",
      "Gradio UI"
    ]
  },
  {
    "title": "ollama-dagger",
    "url": "https://github.com/shykes/ollama-dagger",
    "summary": "Dagger module that spins up Ollama as a service for CI pipelines to run LLM-based tests.",
    "source": "github",
    "date": "2024-06-02",
    "highlights": [
      "CI caching",
      "GPU passthrough",
      "modular tests"
    ]
  },
  {
    "title": "ollama-obsidian",
    "url": "https://github.com/ollama-obsidian/ollama-obsidian",
    "summary": "Obsidian community plugin that adds a \u201cAsk Ollama\u201d command to summarize or rewrite notes.",
    "source": "github",
    "date": "2024-05-31",
    "highlights": [
      "command palette",
      "template variables",
      "offline operation"
    ]
  }
]