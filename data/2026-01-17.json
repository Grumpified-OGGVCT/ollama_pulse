[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Ollama\u2019s official CLI and server to pull, run, and manage large language models locally with minimal setup.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "self-hosted LLM runner",
      "Modelfile system",
      "REST & stream APIs"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client library for Ollama, exposing sync/async APIs to chat, generate, embed, and pull models.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "async/await support",
      "pip install ollama",
      "full API coverage"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Node & browsers; chat, generate, embeddings, and model management.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "npm install ollama",
      "TypeScript types",
      "streaming responses"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://pypi.org/project/langchain-ollama/",
    "summary": "PyPI package integrating Ollama models into LangChain LLM, embeddings, and chat interfaces.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "pip install langchain-ollama",
      "drop-in LLM replacement",
      "embeddings support"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Open-source ChatGPT-style web interface for Ollama models with multi-model chats, code highlighting, and RAG.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "Docker one-liner",
      "document upload/RAG",
      "role-based users"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java/Kotlin client for Ollama providing sync/async APIs, streaming, and embedding support.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "Maven Central",
      "Kotlin coroutines",
      "Spring Boot starters"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/ollama/ollama-rb",
    "summary": "Community-maintained Ruby gem wrapping Ollama\u2019s REST API for chat, generate, and model operations.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "gem install ollama-rb",
      "streaming blocks",
      "Rails integration"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/salty-flower/ollama-cli",
    "summary": "Rust-based interactive CLI frontend for Ollama with syntax highlighting, history, and prompt templates.",
    "source": "github",
    "date": "2024-05-04",
    "highlights": [
      "cross-platform binary",
      "fuzzy model finder",
      "configurable themes"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama-copilot/ollama-copilot",
    "summary": "VS Code extension turning Ollama models into inline code copilots with autocomplete and explanations.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "inline suggestions",
      "custom prompts",
      "multi-model switch"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/ollama/ollama-haystack",
    "summary": "Haystack integration letting you use Ollama models as generators or embedders in RAG pipelines.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "pip install ollama-haystack",
      "Haystack 2.x ready",
      "streaming support"
    ]
  },
  {
    "title": "ollama-cookbook",
    "url": "https://github.com/ollama/ollama-cookbook",
    "summary": "Community recipes showing how to fine-tune, quantize, and deploy custom GGUF models with Ollama.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "Modelfile examples",
      "GPU offloading",
      "multi-arch images"
    ]
  },
  {
    "title": "ollama-docker",
    "url": "https://github.com/ollama/ollama-docker",
    "summary": "Official container images and compose stacks for CPU/GPU inference with NVIDIA runtime support.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "official image",
      "CUDA flags",
      "docker-compose examples"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/ollama/ollama-helm",
    "summary": "Helm chart deploying Ollama server and WebUI onto Kubernetes with autoscaling and PVC model cache.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "Helm repo",
      "GPU node selector",
      "HPA support"
    ]
  },
  {
    "title": "ollama-rag",
    "url": "https://github.com/ollama-rag/ollama-rag",
    "summary": "Minimal RAG starter using Ollama embeddings + Chroma + LangChain to chat over your documents locally.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "one-command setup",
      "PDF ingestion",
      "Gradio UI"
    ]
  },
  {
    "title": "ollama-discord",
    "url": "https://github.com/ollama-discord/ollama-discord",
    "summary": "Self-host Discord bot that lets servers chat with Ollama models using slash commands and thread contexts.",
    "source": "github",
    "date": "2024-05-04",
    "highlights": [
      "slash commands",
      "per-guild model config",
      "thread memory"
    ]
  },
  {
    "title": "ollama-slack",
    "url": "https://github.com/ollama-slack/ollama-slack",
    "summary": "Slack Bolt app integrating Ollama completions into channels/DMs with rate limiting and admin scopes.",
    "source": "github",
    "date": "2024-05-03",
    "highlights": [
      "Socket Mode",
      "app home",
      "audit logs"
    ]
  },
  {
    "title": "ollama-logseq",
    "url": "https://github.com/ollama-logseq/ollama-logseq",
    "summary": "Logseq plugin that brings local LLM assistance for summarizing notes and answering queries inside your graph.",
    "source": "github",
    "date": "2024-05-02",
    "highlights": [
      "block actions",
      "template prompts",
      "offline first"
    ]
  },
  {
    "title": "ollama-obsidian",
    "url": "https://github.com/ollama-obsidian/ollama-obsidian",
    "summary": "Obsidian community plugin to run Ollama models for note Q&A, summarization, and brainstorming.",
    "source": "github",
    "date": "2024-05-03",
    "highlights": [
      "command palette",
      "custom hotkeys",
      "front-matter templates"
    ]
  },
  {
    "title": "ollama-npm",
    "url": "https://www.npmjs.com/package/ollama",
    "summary": "Official npm package providing TypeScript-first client for Node and browsers to interact with Ollama.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "zero deps",
      "ESM & CJS",
      "typed streams"
    ]
  },
  {
    "title": "ollama-pypi",
    "url": "https://pypi.org/project/ollama/",
    "summary": "Official PyPI package for Python developers to chat, generate, embed, and manage Ollama models.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "PEP-561 typed",
      "asyncio support",
      "model pulling API"
    ]
  }
]