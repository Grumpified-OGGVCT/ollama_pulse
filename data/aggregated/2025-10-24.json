[
  {
    "title": "davidsly4954/I101-Web-Profile: Cyber-Protector-Chat-Bot.htm",
    "date": "2025-10-24T18:29:25.645Z",
    "summary": "Code mention in images/Cyber-Protector-Chat-Bot.htm",
    "url": "https://github.com/davidsly4954/I101-Web-Profile/blob/7e92d68b6bb9674e07691fa63afd8b4c1c7829a5/images/Cyber-Protector-Chat-Bot.htm",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.75
  },
  {
    "title": "Ollama Turbo (Cloud) Compatibility",
    "date": "2025-09-02T00:25:15Z",
    "summary": "# Ollama Turbo Compatibility Fix Plan\n\n## Issue\nUsers cannot use Ollama Turbo (cloud service) with BrowserOS because:\n- `ollama` type forces localhost and lacks cloud API key support\n- `openai_compatible` and `custom` types force `/v1` path and use wrong client\n- No existing provider handles Ollama ",
    "url": "https://github.com/browseros-ai/BrowserOS-agent/issues/80",
    "source": "github_issues",
    "highlights": [
      "comments: 1",
      "state: open",
      "repo: BrowserOS-agent"
    ],
    "turbo_score": 0.7
  },
  {
    "title": "mattmerrick/llmlogs: ollama-mcp.html",
    "date": "2025-10-24T18:29:25.645Z",
    "summary": "Code mention in mcp/ollama-mcp.html",
    "url": "https://github.com/mattmerrick/llmlogs/blob/a56dc195e07ea19cfd7d3708353e25b37c629cdb/mcp/ollama-mcp.html",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "bosterptr/nthwse: 1158.html",
    "date": "2025-10-24T18:29:25.645Z",
    "summary": "Code mention in scraper/raw/1158.html",
    "url": "https://github.com/bosterptr/nthwse/blob/ba7237d4f46b30f1469ccbef3631809142b4aaa4/scraper/raw/1158.html",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "Avatar2001/Text-To-Sql: testdb.sqlite",
    "date": "2025-10-24T18:29:25.645Z",
    "summary": "Code mention in testdb.sqlite",
    "url": "https://github.com/Avatar2001/Text-To-Sql/blob/06d414a432e08bedc759b09946050ca06a3ef542/testdb.sqlite",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "Akshay120703/Project_Audio: Script2.py",
    "date": "2025-10-24T18:29:25.645Z",
    "summary": "Code mention in Uday_Sahu/Script2.py",
    "url": "https://github.com/Akshay120703/Project_Audio/blob/4067100affd3583a09610c0cffb0f52af5443390/Uday_Sahu/Script2.py",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "pranshu-raj-211/score_profiles: mock_github.html",
    "date": "2025-10-24T18:29:25.645Z",
    "summary": "Code mention in mock_github.html",
    "url": "https://github.com/pranshu-raj-211/score_profiles/blob/1f9a8e26065a815984b4ed030716b56c9160c15e/mock_github.html",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "MichielBontenbal/AI_advanced: 11878674-indian-elephant.jpg",
    "date": "2025-10-24T18:29:25.645Z",
    "summary": "Code mention in 11878674-indian-elephant.jpg",
    "url": "https://github.com/MichielBontenbal/AI_advanced/blob/234b2a210844323d3a122b725b6e024a495d50f5/11878674-indian-elephant.jpg",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "ursa-mikail/git_all_repo_static: index.html",
    "date": "2025-10-24T18:29:25.645Z",
    "summary": "Code mention in index.html",
    "url": "https://github.com/ursa-mikail/git_all_repo_static/blob/46ac1cb3e9125b60e4e59d117ec468ab150ce342/index.html",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "Otlhomame/llm-zoomcamp: huggingface-phi3.ipynb",
    "date": "2025-10-24T18:29:25.645Z",
    "summary": "Code mention in 02-open-source/huggingface-phi3.ipynb",
    "url": "https://github.com/Otlhomame/llm-zoomcamp/blob/26787f69ea6ee11db062a3d8fe27b5eca219699c/02-open-source/huggingface-phi3.ipynb",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "bosterptr/nthwse: 267.html",
    "date": "2025-10-24T18:29:25.645Z",
    "summary": "Code mention in scraper/raw/267.html",
    "url": "https://github.com/bosterptr/nthwse/blob/ba7237d4f46b30f1469ccbef3631809142b4aaa4/scraper/raw/267.html",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "mattmerrick/llmlogs: ollama-mcp-bridge.html",
    "date": "2025-10-24T18:29:25.645Z",
    "summary": "Code mention in mcp/ollama-mcp-bridge.html",
    "url": "https://github.com/mattmerrick/llmlogs/blob/a56dc195e07ea19cfd7d3708353e25b37c629cdb/mcp/ollama-mcp-bridge.html",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "Akshay120703/Project_Audio: Script1.py",
    "date": "2025-10-24T18:29:25.645Z",
    "summary": "Code mention in Uday_Sahu/Script1.py",
    "url": "https://github.com/Akshay120703/Project_Audio/blob/4067100affd3583a09610c0cffb0f52af5443390/Uday_Sahu/Script1.py",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "Otlhomame/llm-zoomcamp: huggingface-mistral-7b.ipynb",
    "date": "2025-10-24T18:29:25.645Z",
    "summary": "Code mention in 02-open-source/huggingface-mistral-7b.ipynb",
    "url": "https://github.com/Otlhomame/llm-zoomcamp/blob/26787f69ea6ee11db062a3d8fe27b5eca219699c/02-open-source/huggingface-mistral-7b.ipynb",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "MichielBontenbal/AI_advanced: 11878674-indian-elephant (1).jpg",
    "date": "2025-10-24T18:29:25.645Z",
    "summary": "Code mention in 11878674-indian-elephant (1).jpg",
    "url": "https://github.com/MichielBontenbal/AI_advanced/blob/234b2a210844323d3a122b725b6e024a495d50f5/11878674-indian-elephant%20(1).jpg",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "mattmerrick/llmlogs: mcpsharp.html",
    "date": "2025-10-24T18:29:25.645Z",
    "summary": "Code mention in mcp/mcpsharp.html",
    "url": "https://github.com/mattmerrick/llmlogs/blob/a56dc195e07ea19cfd7d3708353e25b37c629cdb/mcp/mcpsharp.html",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "microfiche/github-explore: 28",
    "date": "2025-10-24T18:29:25.645Z",
    "summary": "Code mention in history/2025/01/28",
    "url": "https://github.com/microfiche/github-explore/blob/7b1bb05a8c0b85b8a031f1c8c4cc4b25a3a37941/history/2025/01/28",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "microfiche/github-explore: 02",
    "date": "2025-10-24T18:29:25.645Z",
    "summary": "Code mention in history/2025/03/02",
    "url": "https://github.com/microfiche/github-explore/blob/7b1bb05a8c0b85b8a031f1c8c4cc4b25a3a37941/history/2025/03/02",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "microfiche/github-explore: 08",
    "date": "2025-10-24T18:29:25.645Z",
    "summary": "Code mention in history/2024/06/08",
    "url": "https://github.com/microfiche/github-explore/blob/7b1bb05a8c0b85b8a031f1c8c4cc4b25a3a37941/history/2024/06/08",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "microfiche/github-explore: 01",
    "date": "2025-10-24T18:29:25.645Z",
    "summary": "Code mention in history/2025/03/01",
    "url": "https://github.com/microfiche/github-explore/blob/7b1bb05a8c0b85b8a031f1c8c4cc4b25a3a37941/history/2025/03/01",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "microfiche/github-explore: 30",
    "date": "2025-10-24T18:29:25.645Z",
    "summary": "Code mention in history/2025/01/30",
    "url": "https://github.com/microfiche/github-explore/blob/7b1bb05a8c0b85b8a031f1c8c4cc4b25a3a37941/history/2025/01/30",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "microfiche/github-explore: 03",
    "date": "2025-10-24T18:29:25.645Z",
    "summary": "Code mention in history/2025/03/03",
    "url": "https://github.com/microfiche/github-explore/blob/7b1bb05a8c0b85b8a031f1c8c4cc4b25a3a37941/history/2025/03/03",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "microfiche/github-explore: 27",
    "date": "2025-10-24T18:29:25.645Z",
    "summary": "Code mention in history/2025/01/27",
    "url": "https://github.com/microfiche/github-explore/blob/7b1bb05a8c0b85b8a031f1c8c4cc4b25a3a37941/history/2025/01/27",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "microfiche/github-explore: 11",
    "date": "2025-10-24T18:29:25.645Z",
    "summary": "Code mention in history/2024/12/11",
    "url": "https://github.com/microfiche/github-explore/blob/7b1bb05a8c0b85b8a031f1c8c4cc4b25a3a37941/history/2024/12/11",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "microfiche/github-explore: 29",
    "date": "2025-10-24T18:29:25.645Z",
    "summary": "Code mention in history/2025/01/29",
    "url": "https://github.com/microfiche/github-explore/blob/7b1bb05a8c0b85b8a031f1c8c4cc4b25a3a37941/history/2025/01/29",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "microfiche/github-explore: 23",
    "date": "2025-10-24T18:29:25.645Z",
    "summary": "Code mention in history/2024/09/23",
    "url": "https://github.com/microfiche/github-explore/blob/7b1bb05a8c0b85b8a031f1c8c4cc4b25a3a37941/history/2024/09/23",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "microfiche/github-explore: 28",
    "date": "2025-10-24T18:29:25.645Z",
    "summary": "Code mention in history/2025/02/28",
    "url": "https://github.com/microfiche/github-explore/blob/7b1bb05a8c0b85b8a031f1c8c4cc4b25a3a37941/history/2025/02/28",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "microfiche/github-explore: 22",
    "date": "2025-10-24T18:29:25.645Z",
    "summary": "Code mention in history/2024/09/22",
    "url": "https://github.com/microfiche/github-explore/blob/7b1bb05a8c0b85b8a031f1c8c4cc4b25a3a37941/history/2024/09/22",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "microfiche/github-explore: 26",
    "date": "2025-10-24T18:29:25.645Z",
    "summary": "Code mention in history/2024/12/26",
    "url": "https://github.com/microfiche/github-explore/blob/7b1bb05a8c0b85b8a031f1c8c4cc4b25a3a37941/history/2024/12/26",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "microfiche/github-explore: 18",
    "date": "2025-10-24T18:29:25.645Z",
    "summary": "Code mention in history/2025/06/18",
    "url": "https://github.com/microfiche/github-explore/blob/7b1bb05a8c0b85b8a031f1c8c4cc4b25a3a37941/history/2025/06/18",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "microfiche/github-explore: 16",
    "date": "2025-10-24T18:29:25.645Z",
    "summary": "Code mention in history/2025/03/16",
    "url": "https://github.com/microfiche/github-explore/blob/7b1bb05a8c0b85b8a031f1c8c4cc4b25a3a37941/history/2025/03/16",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "Grumpified-OGGVCT/ollama_pulse: ingest.yml",
    "date": "2025-10-24T18:29:25.645Z",
    "summary": "Code mention in .github/workflows/ingest.yml",
    "url": "https://github.com/Grumpified-OGGVCT/ollama_pulse/blob/be5c6ed517dedbdea4fc8e4f8d7e89c63d7df9e2/.github/workflows/ingest.yml",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "Grumpified-OGGVCT/ollama_pulse: ingest.yml",
    "date": "2025-10-24T12:41:35.345Z",
    "summary": "Code mention in .github/workflows/ingest.yml",
    "url": "https://github.com/Grumpified-OGGVCT/ollama_pulse/blob/529c6579d61f2646efa5626fbf249b0da074c3d0/.github/workflows/ingest.yml",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "Grumpified-OGGVCT/ollama_pulse: ingest.yml",
    "date": "2025-10-24T08:26:41.505Z",
    "summary": "Code mention in .github/workflows/ingest.yml",
    "url": "https://github.com/Grumpified-OGGVCT/ollama_pulse/blob/77f1442a72bd18d0a21e0d59ba4b5b250fedcbef/.github/workflows/ingest.yml",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "Grumpified-OGGVCT/ollama_pulse: ingest.yml",
    "date": "2025-10-24T07:19:53.697Z",
    "summary": "Code mention in .github/workflows/ingest.yml",
    "url": "https://github.com/Grumpified-OGGVCT/ollama_pulse/blob/1419a7fb5c0084194379f2adc260f8142ceb3a9e/.github/workflows/ingest.yml",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "Grumpified-OGGVCT/ollama_pulse: ingest.yml",
    "date": "2025-10-24T06:29:05.440Z",
    "summary": "Code mention in .github/workflows/ingest.yml",
    "url": "https://github.com/Grumpified-OGGVCT/ollama_pulse/blob/3106266dc159d24718dcf6655c64bdbb67f5a7d2/.github/workflows/ingest.yml",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "Grumpified-OGGVCT/ollama_pulse: ingest.yml",
    "date": "2025-10-24T03:38:45.965Z",
    "summary": "Code mention in .github/workflows/ingest.yml",
    "url": "https://github.com/Grumpified-OGGVCT/ollama_pulse/blob/8591afd222e3108f9e65972d524558e4d03c861f/.github/workflows/ingest.yml",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "microfiche/github-explore: 28",
    "date": "2025-10-24T01:20:56.189Z",
    "summary": "Code mention in history/2025/01/28",
    "url": "https://github.com/microfiche/github-explore/blob/72fa7ba46b56bd45b9da50635f466623e5b4349c/history/2025/01/28",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "microfiche/github-explore: 02",
    "date": "2025-10-24T01:20:56.189Z",
    "summary": "Code mention in history/2025/03/02",
    "url": "https://github.com/microfiche/github-explore/blob/72fa7ba46b56bd45b9da50635f466623e5b4349c/history/2025/03/02",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "microfiche/github-explore: 08",
    "date": "2025-10-24T01:20:56.189Z",
    "summary": "Code mention in history/2024/06/08",
    "url": "https://github.com/microfiche/github-explore/blob/72fa7ba46b56bd45b9da50635f466623e5b4349c/history/2024/06/08",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "microfiche/github-explore: 01",
    "date": "2025-10-24T01:20:56.189Z",
    "summary": "Code mention in history/2025/03/01",
    "url": "https://github.com/microfiche/github-explore/blob/72fa7ba46b56bd45b9da50635f466623e5b4349c/history/2025/03/01",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "microfiche/github-explore: 30",
    "date": "2025-10-24T01:20:56.189Z",
    "summary": "Code mention in history/2025/01/30",
    "url": "https://github.com/microfiche/github-explore/blob/72fa7ba46b56bd45b9da50635f466623e5b4349c/history/2025/01/30",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "microfiche/github-explore: 03",
    "date": "2025-10-24T01:20:56.189Z",
    "summary": "Code mention in history/2025/03/03",
    "url": "https://github.com/microfiche/github-explore/blob/72fa7ba46b56bd45b9da50635f466623e5b4349c/history/2025/03/03",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "microfiche/github-explore: 27",
    "date": "2025-10-24T01:20:56.189Z",
    "summary": "Code mention in history/2025/01/27",
    "url": "https://github.com/microfiche/github-explore/blob/72fa7ba46b56bd45b9da50635f466623e5b4349c/history/2025/01/27",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "microfiche/github-explore: 11",
    "date": "2025-10-24T01:20:56.189Z",
    "summary": "Code mention in history/2024/12/11",
    "url": "https://github.com/microfiche/github-explore/blob/72fa7ba46b56bd45b9da50635f466623e5b4349c/history/2024/12/11",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "microfiche/github-explore: 29",
    "date": "2025-10-24T01:20:56.189Z",
    "summary": "Code mention in history/2025/01/29",
    "url": "https://github.com/microfiche/github-explore/blob/72fa7ba46b56bd45b9da50635f466623e5b4349c/history/2025/01/29",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "microfiche/github-explore: 23",
    "date": "2025-10-24T01:20:56.189Z",
    "summary": "Code mention in history/2024/09/23",
    "url": "https://github.com/microfiche/github-explore/blob/72fa7ba46b56bd45b9da50635f466623e5b4349c/history/2024/09/23",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "microfiche/github-explore: 28",
    "date": "2025-10-24T01:20:56.189Z",
    "summary": "Code mention in history/2025/02/28",
    "url": "https://github.com/microfiche/github-explore/blob/72fa7ba46b56bd45b9da50635f466623e5b4349c/history/2025/02/28",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "microfiche/github-explore: 22",
    "date": "2025-10-24T01:20:56.189Z",
    "summary": "Code mention in history/2024/09/22",
    "url": "https://github.com/microfiche/github-explore/blob/72fa7ba46b56bd45b9da50635f466623e5b4349c/history/2024/09/22",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "microfiche/github-explore: 26",
    "date": "2025-10-24T01:20:56.189Z",
    "summary": "Code mention in history/2024/12/26",
    "url": "https://github.com/microfiche/github-explore/blob/72fa7ba46b56bd45b9da50635f466623e5b4349c/history/2024/12/26",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "microfiche/github-explore: 18",
    "date": "2025-10-24T01:20:56.189Z",
    "summary": "Code mention in history/2025/06/18",
    "url": "https://github.com/microfiche/github-explore/blob/72fa7ba46b56bd45b9da50635f466623e5b4349c/history/2025/06/18",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "microfiche/github-explore: 16",
    "date": "2025-10-24T01:20:56.189Z",
    "summary": "Code mention in history/2025/03/16",
    "url": "https://github.com/microfiche/github-explore/blob/72fa7ba46b56bd45b9da50635f466623e5b4349c/history/2025/03/16",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "Grumpified-OGGVCT/ollama_pulse: ingest.yml",
    "date": "2025-10-24T01:20:56.189Z",
    "summary": "Code mention in .github/workflows/ingest.yml",
    "url": "https://github.com/Grumpified-OGGVCT/ollama_pulse/blob/e20a9aa7cfcd0d5bf2c09fe6e3f9099513797b89/.github/workflows/ingest.yml",
    "source": "github_code_search",
    "highlights": [
      "code",
      "turbo",
      "cloud"
    ],
    "turbo_score": 0.6
  },
  {
    "title": "shashank2122/Local-Voice",
    "date": "2025-10-24T20:11:15Z",
    "summary": "A real-time, offline voice assistant for Linux and Raspberry Pi. Uses local LLMs (via Ollama), speech-to-text (Vosk), and text-to-speech (Piper) for fast, wake-free voice interaction. No cloud. No APIs. Just Python, a mic, and your voice.",
    "url": "https://github.com/shashank2122/Local-Voice",
    "source": "github",
    "highlights": [
      "stars: 14",
      "language: Python"
    ],
    "turbo_score": 0.55
  },
  {
    "title": "PR-Agent fails to process large PRs with multiple model configurations",
    "date": "2025-09-24T16:37:14Z",
    "summary": "### Git provider\n\nGithub Cloud\n\n### System Info\n\n- **Platform**: macOS ARM64 running linux/amd64 Docker image\n- **PR Size**: 97,419 tokens\n- **Repository**: Private repository\n\n\n### Bug details\n\nPR-Agent fails with \"Failed to generate prediction\" errors across all tested model configurations, even w",
    "url": "https://github.com/qodo-ai/pr-agent/issues/2042",
    "source": "github_issues",
    "highlights": [
      "comments: 2",
      "state: open",
      "repo: pr-agent"
    ],
    "turbo_score": 0.45
  },
  {
    "title": "[PR] LLM cloud microservice",
    "date": "2025-10-24T02:05:38Z",
    "summary": "## \ud83d\udcdd Description\r\n**Please read the README.md to understand my thoughts on why I made this service independent and separate from our main django backend**. This is simply just a service we will use to get LLM's responses, all the processing AFTER we receive a LLM JSON response and such will still be",
    "url": "https://github.com/COSC-499-W2025/capstone-project-team-8/pull/67",
    "source": "github_prs",
    "highlights": [
      "comments: 0",
      "pull request",
      "repo: capstone-project-team-8"
    ],
    "turbo_score": 0.4
  },
  {
    "title": "[PR] Feat: Add Ollama Cloud API support",
    "date": "2025-10-23T21:40:35Z",
    "summary": "Adds support for Ollama's cloud API with API key authentication. The new api_key field (SecretStrInput) automatically shows/hides based on whether a cloud or local URL is configured. Unit tests added to verify header generation, authentication behavior, and API key field visibility logic for both cl",
    "url": "https://github.com/langflow-ai/langflow/pull/10389",
    "source": "github_prs",
    "highlights": [
      "comments: 1",
      "pull request",
      "repo: langflow"
    ],
    "turbo_score": 0.4
  },
  {
    "title": "\ud83e\udd14\ud83d\udcad How to use Ollama (gpt-oss) TURBO mode?",
    "date": "2025-10-21T08:43:23Z",
    "summary": "Hi, when using Ollama directly on the Ollama app (windows) there is the turbo mode. \nIs it possible to run turbo mode on ComfyUi somehow?",
    "url": "https://github.com/stavsap/comfyui-ollama/issues/118",
    "source": "github_issues",
    "highlights": [
      "comments: 5",
      "state: open",
      "repo: comfyui-ollama"
    ],
    "turbo_score": 0.4
  },
  {
    "title": "LLM-Anbindung",
    "date": "2025-10-20T13:54:48Z",
    "summary": "## Cloud-basierte LLM-L\u00f6sungen\n\n**1. Anthropic Claude API (empfohlen f\u00fcr euer Projekt)**\n- Pay-as-you-go Modell, keine Grundgeb\u00fchr\n- Claude Sonnet 4 bietet exzellente reasoning capabilities f\u00fcr strategische Entscheidungen\n- Beide k\u00f6nnen gleichzeitig \u00fcber API-Keys zugreifen\n- Kostenbeispiel: ~$3-15 p",
    "url": "https://github.com/CappedMonke/talk_of_the_town/issues/1",
    "source": "github_issues",
    "highlights": [
      "comments: 0",
      "state: open",
      "repo: talk_of_the_town"
    ],
    "turbo_score": 0.4
  },
  {
    "title": "\ud83c\udfaf Internal Bounty ($4000 USD): Complete LLM Integration System - Local Models + Cloud APIs (Gemini, Anthropic, OpenAI)",
    "date": "2025-10-14T00:42:47Z",
    "summary": "## \ud83d\udcb0 Bounty Amount: $4,000 USD\n\n## \ud83d\udccb Overview\n\nThis is an **internal bounty issue** for implementing a comprehensive LLM (Large Language Model) integration system into the go-blueprint CLI tool. The goal is to create a robust, production-ready solution that supports both local LLM models and cloud-b",
    "url": "https://github.com/MAVRICK-1/go-blueprint/issues/1",
    "source": "github_issues",
    "highlights": [
      "comments: 16",
      "state: open",
      "repo: go-blueprint"
    ],
    "turbo_score": 0.4
  },
  {
    "title": "Show HN: I made PromptMask, a local LLM-based privacy filter for cloud LLMs",
    "date": "2025-08-26T23:42:41Z",
    "summary": "I&#x27;m wary of sending private data to cloud AI services, but local models aren&#x27;t always powerful enough. So I built PromptMask, an open-source local-first privacy layer.<p>It uses a trusted lo",
    "url": "https://github.com/cxumol/promptmask",
    "source": "hackernews",
    "highlights": [
      "points: 4",
      "comments: 0"
    ],
    "turbo_score": 0.4
  },
  {
    "title": "[PR] Jsje",
    "date": "2025-10-24T21:06:03Z",
    "summary": "# Description\r\n\r\nThank you for opening a Pull Request!\r\nBefore submitting your PR, there are a few things you can do to make sure it goes smoothly:\r\n\r\n- [ ] Follow the [`CONTRIBUTING` Guide](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/CONTRIBUTING.md).\r\n- [ ] You are listed as the",
    "url": "https://github.com/arthrod/generative-ai/pull/7",
    "source": "github_prs",
    "highlights": [
      "comments: 2",
      "pull request",
      "repo: generative-ai"
    ],
    "turbo_score": 0.3
  },
  {
    "title": "TTWJOE/dr-x-nlp-pipeline",
    "date": "2025-10-24T19:57:48Z",
    "summary": "A fully offline NLP pipeline for extracting, chunking, embedding, querying, summarizing, and translating research documents using local LLMs. Inspired by the fictional mystery of Dr. X, the system supports multi-format files, local RAG-based Q&A, Arabic translation, and ROUGE-based summarization \u2014 all without cloud dependencies.",
    "url": "https://github.com/TTWJOE/dr-x-nlp-pipeline",
    "source": "github",
    "highlights": [
      "stars: 3",
      "language: Python"
    ],
    "turbo_score": 0.3
  },
  {
    "title": "[PR] chore(deps): update database & platform",
    "date": "2025-10-24T08:31:59Z",
    "summary": "This PR contains the following updates:\n\n| Package | Type | Update | Change |\n|---|---|---|---|\n| [cloudnative-pg](https://cloudnative-pg.io) ([source](https://redirect.github.com/cloudnative-pg/charts)) | HelmChart | patch | `0.26.0` -> `0.26.1` |\n| [docker.n8n.io/n8nio/n8n](https://n8n.io) ([sourc",
    "url": "https://github.com/Tim275/talos-homelab/pull/14",
    "source": "github_prs",
    "highlights": [
      "comments: 0",
      "pull request",
      "repo: talos-homelab"
    ],
    "turbo_score": 0.3
  },
  {
    "title": "ot4ank/auto-openwebui",
    "date": "2025-10-24T02:51:43Z",
    "summary": "A bash script to automate running Open WebUI on Linux systems with Ollama and Cloudflare via Docker",
    "url": "https://github.com/ot4ank/auto-openwebui",
    "source": "github",
    "highlights": [
      "stars: 0",
      "language: Shell"
    ],
    "turbo_score": 0.3
  },
  {
    "title": "[PR] Update",
    "date": "2025-10-23T20:50:36Z",
    "summary": "\n\n<!-- This is an auto-generated comment: release notes by coderabbit.ai -->\n## Summary by CodeRabbit\n\n* **New Features**\n  * Extensive new blog content covering cloud-native development, Kubernetes, DevOps practices, and infrastructure topics.\n  * Enhanced documentation with architecture diagrams a",
    "url": "https://github.com/humzamalak/dca-prep-kit/pull/1",
    "source": "github_prs",
    "highlights": [
      "comments: 1",
      "pull request",
      "repo: dca-prep-kit"
    ],
    "turbo_score": 0.3
  },
  {
    "title": "[PR] Add Ollama as an Embedding Provider",
    "date": "2025-10-23T20:22:26Z",
    "summary": "### Description\r\nThis PR introduces Ollama as an alternative embedding provider to Hugging Face, enabling local CPU/GPU embedding inference, enhancing data privacy, and reducing cloud dependency and cost. It also improves flexibility by allowing users to choose between cloud-based (Hugging Face) and",
    "url": "https://github.com/MariaDB/mcp/pull/39",
    "source": "github_prs",
    "highlights": [
      "comments: 1",
      "pull request",
      "repo: mcp"
    ],
    "turbo_score": 0.3
  },
  {
    "title": "Update FAQ in light of new Cloud models feature",
    "date": "2025-09-24T23:19:30Z",
    "summary": "Currently [Ollama FAQ says](https://github.com/ollama/ollama/blob/main/docs/faq.md#does-ollama-send-my-prompts-and-responses-back-to-ollamacom):\n\n> ## Does Ollama send my prompts and responses back to ollama.com?\n> \n> If you're running a model locally, your prompts and responses will always stay on ",
    "url": "https://github.com/ollama/ollama/issues/12404",
    "source": "github_issues",
    "highlights": [
      "comments: 0",
      "state: open",
      "repo: ollama"
    ],
    "turbo_score": 0.3
  },
  {
    "title": "Ollama Cloud Models",
    "date": "2025-09-23T07:57:18Z",
    "summary": "",
    "url": "https://ollama.com/blog/cloud-models",
    "source": "hackernews",
    "highlights": [
      "points: 2",
      "comments: 0"
    ],
    "turbo_score": 0.3
  },
  {
    "title": "Profile syncing between registered devices",
    "date": "2025-09-15T17:20:20Z",
    "summary": "In Ollama Windows application, do we have the ability to:\n1- upload used prompts to the cloud profile, to be synced to between devices, or visible online (read-only for sure).\n2- be able to share as read-only with colleagues, teams, or public.\n3- add grouping/categorization to the prompt history pag",
    "url": "https://github.com/ollama/ollama/issues/12292",
    "source": "github_issues",
    "highlights": [
      "comments: 4",
      "state: open",
      "repo: ollama"
    ],
    "turbo_score": 0.3
  },
  {
    "title": "How to Install DeepSeek on Your Cloud Server with Ollama LLM",
    "date": "2025-02-07T18:48:13Z",
    "summary": "",
    "url": "https://www.deployhq.com/blog/how-to-install-deepseek-on-your-cloud-server-with-ollama-llm",
    "source": "hackernews",
    "highlights": [
      "points: 2",
      "comments: 0"
    ],
    "turbo_score": 0.3
  },
  {
    "title": "From Ollama to OpenLLM: Running LLMs in the Cloud",
    "date": "2024-07-18T14:08:57Z",
    "summary": "",
    "url": "https://www.bentoml.com/blog/from-ollama-to-openllm-running-llms-in-the-cloud",
    "source": "hackernews",
    "highlights": [
      "points: 3",
      "comments: 0"
    ],
    "turbo_score": 0.3
  },
  {
    "title": "Show HN: Cloud-native Stack for Ollama - Build locally and push to deploy",
    "date": "2024-03-19T18:06:17Z",
    "summary": "",
    "url": "https://github.com/ollama-cloud/get-started",
    "source": "hackernews",
    "highlights": [
      "points: 21",
      "comments: 4"
    ],
    "turbo_score": 0.3
  }
]