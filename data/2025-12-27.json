[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo \u2013 CLI and Go library for pulling, running & chatting with Llama 2, Mistral, Gemma, etc. locally via a REST-ish API.",
    "source": "github",
    "date": "2024-04-18",
    "highlights": [
      "self-contained binary",
      "model registry",
      "OpenAI-compatible endpoints",
      "macOS/Linux/Windows"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "First-party Python client (PyPI: ollama) that wraps the Ollama REST API with sync/async helpers and streaming support.",
    "source": "github",
    "date": "2024-04-15",
    "highlights": [
      "pip install ollama",
      "async/await",
      "streaming chat",
      "embeddings endpoint"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript / TypeScript client (npm: ollama) for Node, Deno & browsers to talk to a local Ollama server.",
    "source": "github",
    "date": "2024-04-12",
    "highlights": [
      "npm install ollama",
      "TypeScript defs",
      "streaming responses",
      "browser compatible"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/partners/ollama",
    "summary": "LangChain integration package (PyPI: langchain-ollama) giving LLM, chat, embeddings and tool-calling components backed by Ollama.",
    "source": "github",
    "date": "2024-04-10",
    "highlights": [
      "pip install langchain-ollama",
      "tool calling",
      "RAG pipelines",
      "LCEL support"
    ]
  },
  {
    "title": "LlamaIndex Ollama integration",
    "url": "https://github.com/run-llama/llama_index/tree/main/llama-index-integrations/llms/llama-index-llms-ollama",
    "summary": "LlamaIndex LLM and embeddings drivers (PyPI: llama-index-llms-ollama & llama-index-embeddings-ollama) for local RAG stacks.",
    "source": "github",
    "date": "2024-04-08",
    "highlights": [
      "RAG",
      "embedding support",
      "pip installable",
      "vector-store friendly"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/llama-assistant/ollama-webui",
    "summary": "Open-source ChatGPT-style web UI (React + FastAPI) that talks to Ollama; supports multi-model chats, code highlighting, dark mode.",
    "source": "github",
    "date": "2024-04-05",
    "highlights": [
      "self-hosted",
      "markdown/code",
      "multi-chat",
      "docker ready"
    ]
  },
  {
    "title": "Ollama Discord bot",
    "url": "https://github.com/sawa-zen/ollama-discord-bot",
    "summary": "Simple TypeScript bot that lets a Discord server chat with any Ollama model via slash commands.",
    "source": "github",
    "date": "2024-04-01",
    "highlights": [
      "slash commands",
      "streaming replies",
      "easy config"
    ]
  },
  {
    "title": "ollama-cli (community)",
    "url": "https://github.com/jmorganca/ollama-cli",
    "summary": "Community Rust CLI that wraps the Ollama REST API with ergonomic prompts, conversation history and model info commands.",
    "source": "github",
    "date": "2024-03-28",
    "highlights": [
      "Rust binary",
      "conversation memory",
      "model introspection"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/fostermaier/ollama-copilot",
    "summary": "VS Code extension that turns any Ollama model into a local GitHub Copilot replacement with inline suggestions.",
    "source": "github",
    "date": "2024-03-25",
    "highlights": [
      "VS Code",
      "inline completions",
      "configurable model"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java / Kotlin SDK (Maven Central: ollama4j) providing typed clients, streaming chat, embeddings and tool-call builders for Ollama.",
    "source": "github",
    "date": "2024-03-22",
    "highlights": [
      "Java/Kotlin",
      "builder pattern",
      "streaming",
      "Maven Central"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/gbaptista/ollama-rb",
    "summary": "Ruby gem (ollama-rb) for chatting, embeddings and model management through the Ollama REST API.",
    "source": "github",
    "date": "2024-03-20",
    "highlights": [
      "gem install",
      "Ruby DSL",
      "streaming",
      "model utils"
    ]
  },
  {
    "title": "ollama-dart",
    "url": "https://github.com/marcotrumpet/ollama_dart",
    "summary": "Dart / Flutter package (pub.dev: ollama) to run local LLM chats inside mobile/desktop apps via Ollama.",
    "source": "github",
    "date": "2024-03-18",
    "highlights": [
      "Flutter",
      "Dart",
      "mobile ready",
      "streaming"
    ]
  },
  {
    "title": "ollama-csharp",
    "url": "https://github.com/awaescher/ollama-csharp",
    "summary": ".NET SDK (NuGet: OllamaSharp) with async chat, embeddings, model listing and tool-calling helpers.",
    "source": "github",
    "date": "2024-03-15",
    "highlights": [
      "NuGet",
      "async",
      "tool calling",
      "strong typing"
    ]
  },
  {
    "title": "Ollama Reddit community",
    "url": "https://www.reddit.com/r/ollama/",
    "summary": "Active subreddit for sharing models, troubleshooting, integrations and feature requests around Ollama.",
    "source": "reddit",
    "date": "2024-04-19",
    "highlights": [
      "community support",
      "model tips",
      "feature requests"
    ]
  },
  {
    "title": "Ollama on Hacker News",
    "url": "https://news.ycombinator.com/item?id=40123456",
    "summary": "Discussion thread comparing Ollama to llama.cpp, text-generation-webui and covering GPU offloading, Docker images and roadmap.",
    "source": "hackernews",
    "date": "2024-04-17",
    "highlights": [
      "performance notes",
      "roadmap hints",
      "Docker tips"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/otwld/ollama-helm",
    "summary": "Helm chart to deploy Ollama on Kubernetes with optional GPU node-selector, PVC and ingress.",
    "source": "github",
    "date": "2024-03-12",
    "highlights": [
      "Kubernetes",
      "GPU support",
      "Helm",
      "PVC"
    ]
  },
  {
    "title": "ollama-docker-compose",
    "url": "https://github.com/ollama/ollama/tree/main/docker",
    "summary": "Official Docker images and compose samples (CPU & GPU) for running Ollama in containers.",
    "source": "github",
    "date": "2024-04-16",
    "highlights": [
      "official image",
      "CUDA",
      "ROCm",
      "compose examples"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/deepset-ai/haystack-integrations/tree/main/integrations/ollama",
    "summary": "Haystack integration (PyPI: haystack-ai-ollama) using Ollama as both generator and embedder in Haystack 2.0 pipelines.",
    "source": "github",
    "date": "2024-03-10",
    "highlights": [
      "Haystack 2.0",
      "pipelines",
      "embeddings",
      "RAG"
    ]
  },
  {
    "title": "ollama-spring-boot-starter",
    "url": "https://github.com/sanmibuh/ollama-spring-boot-starter",
    "summary": "Spring Boot starter (Maven) that autoconfigures an Ollama client bean and YAML-based model/chat properties.",
    "source": "github",
    "date": "2024-03-08",
    "highlights": [
      "Spring Boot",
      "auto-config",
      "YAML",
      "Maven"
    ]
  },
  {
    "title": "ollama-n8n-node",
    "url": "https://github.com/ollama-n8n/community-node-ollama",
    "summary": "Community node for n8n workflow automation that enables no-code chat, embeddings and model ops via Ollama.",
    "source": "github",
    "date": "2024-03-05",
    "highlights": [
      "n8n",
      "no-code",
      "workflows",
      "community node"
    ]
  }
]