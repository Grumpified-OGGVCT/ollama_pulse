[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: get up and running with Llama 3.2, Mistral, Gemma 2, and other large language models locally.",
    "source": "github",
    "date": "2024-05-15",
    "highlights": [
      "self-contained LLM runner",
      "macOS/Linux/Windows",
      "Docker images",
      "REST & Go APIs"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python SDK for Ollama: chat, generate, embed, pull, list, delete models with a few lines of code.",
    "source": "github",
    "date": "2024-04-20",
    "highlights": [
      "pip install ollama",
      "sync & async clients",
      "streaming support",
      "type hints"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Node & browsers; chat, stream, embeddings, tool calling.",
    "source": "github",
    "date": "2024-04-18",
    "highlights": [
      "npm i ollama",
      "ESM & CJS builds",
      "browser polyfills",
      "Promise & stream APIs"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/partners/ollama",
    "summary": "LangChain integration: use any Ollama model as an LLM or chat backend with LangChain abstractions.",
    "source": "github",
    "date": "2024-03-12",
    "highlights": [
      "pip install langchain-ollama",
      "tool calling",
      "RAG chains",
      "streaming tokens"
    ]
  },
  {
    "title": "ollama-webui (ollama-webui/ollama-webui)",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich web UI for Ollama: chat history, multi-user, model management, OpenAI-compat endpoints.",
    "source": "github",
    "date": "2024-05-01",
    "highlights": [
      "docker-compose one-liner",
      "dark/light themes",
      "code highlighting",
      "RAG uploads"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/technomancy/ollama-cli",
    "summary": "Rust-based interactive CLI for Ollama with readline, syntax highlighting, and conversation memory.",
    "source": "github",
    "date": "2024-04-05",
    "highlights": [
      "cargo install ollama-cli",
      "tab completion",
      "markdown rendering",
      "keybindings"
    ]
  },
  {
    "title": "ollama-copilot (simonw/ollama-copilot)",
    "url": "https://github.com/simonw/ollama-copilot",
    "summary": "Experimental GitHub Copilot proxy that routes completions through a local Ollama model.",
    "source": "github",
    "date": "2024-03-30",
    "highlights": [
      "VS Code plugin ready",
      "self-hosted",
      "privacy-first",
      "configurable model"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/deepset-ai/haystack-integrations/tree/main/integrations/ollama",
    "summary": "Haystack integration: OllamaGenerator & OllamaChatGenerator nodes for production pipelines.",
    "source": "github",
    "date": "2024-04-10",
    "highlights": [
      "pip install ollama-haystack",
      "batching",
      "prompt templates",
      "evaluation hooks"
    ]
  },
  {
    "title": "ollama-rag (ggerganov/ollama-rag)",
    "url": "https://github.com/ggerganov/ollama-rag",
    "summary": "Minimal RAG example using Ollama for both embeddings and generation, backed by Chroma vector DB.",
    "source": "github",
    "date": "2024-04-22",
    "highlights": [
      "single-file demo",
      "streaming answers",
      "PDF ingestion",
      "Dockerfile included"
    ]
  },
  {
    "title": "ollama-csharp",
    "url": "https://github.com/ollama/ollama-csharp",
    "summary": "Community-maintained C#/.NET SDK with async streaming, embeddings, and tool support.",
    "source": "github",
    "date": "2024-04-14",
    "highlights": [
      "NuGet OllamaSharp",
      ".NET 6+",
      "strong naming",
      "cancellation tokens"
    ]
  },
  {
    "title": "ollama-discord-bot",
    "url": "https://github.com/mxyng/ollama-discord-bot",
    "summary": "Self-hostable Discord bot that brings local LLM chat to any server using Ollama.",
    "source": "github",
    "date": "2024-03-28",
    "highlights": [
      "slash commands",
      "threading",
      "rate limits",
      "docker image"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/otwld/ollama-helm",
    "summary": "Production-ready Helm chart for deploying Ollama on Kubernetes with GPU autoscaling.",
    "source": "github",
    "date": "2024-04-25",
    "highlights": [
      "GPU node selector",
      "PVC model cache",
      "ingress",
      "prometheus metrics"
    ]
  },
  {
    "title": "ollama-nim (nimlang/ollama-nim)",
    "url": "https://github.com/nimlang/ollama-nim",
    "summary": "Nim wrapper for Ollama\u2019s REST API supporting sync/async, streaming, and embeddings.",
    "source": "github",
    "date": "2024-04-08",
    "highlights": [
      "Nimble package",
      "zero-copy streams",
      "jsony marshalling",
      "examples"
    ]
  },
  {
    "title": "ollama-dagger",
    "url": "https://github.com/shykes/ollama-dagger",
    "summary": "Dagger module that caches and serves Ollama models inside CI pipelines for reproducible LLM tests.",
    "source": "github",
    "date": "2024-04-17",
    "highlights": [
      "Dagger 0.9+",
      "layer caching",
      "multi-arch",
      "GitHub Actions example"
    ]
  },
  {
    "title": "ollama-rust (pepperoni21/ollama-rust)",
    "url": "https://github.com/pepperoni21/ollama-rust",
    "summary": "Async Rust client with tokio, serde, and built-in streaming iterator for Ollama endpoints.",
    "source": "github",
    "date": "2024-04-12",
    "highlights": [
      "crates.io ollama-rs",
      "tokio-native",
      "examples/",
      "no unsafe"
    ]
  },
  {
    "title": "ollama-slack-bot",
    "url": "https://github.com/alexkim/ollama-slack-bot",
    "summary": "Lightweight Slack bot that answers questions using a local Ollama model with thread support.",
    "source": "github",
    "date": "2024-03-31",
    "highlights": [
      "Socket-Mode",
      "app mentions",
      "emoji reactions",
      "env config"
    ]
  },
  {
    "title": "ollama-obsidian",
    "url": "https://github.com/hintergrund/ollama-obsidian",
    "summary": "Obsidian plugin that adds \u201cAsk Ollama\u201d commands for summarizing notes and brainstorming.",
    "source": "github",
    "date": "2024-04-19",
    "highlights": [
      "community plugin",
      "custom prompts",
      "templater hooks",
      "offline"
    ]
  },
  {
    "title": "ollama-elixir",
    "url": "https://github.com/ollama-elixir/ollama",
    "summary": "Elixir OTP client with GenServer behavior, streaming, and telemetry events for Ollama.",
    "source": "github",
    "date": "2024-04-11",
    "highlights": [
      "Hex.pm package",
      "Finch http",
      "LiveBook integration",
      "supervision trees"
    ]
  },
  {
    "title": "ollama-rustico (lmammino/ollama-rustico)",
    "url": "https://github.com/lmammino/ollama-rustico",
    "summary": "Minimal REST wrapper in Rust that exposes Ollama as a Lambda runtime for serverless inference.",
    "source": "github",
    "date": "2024-04-09",
    "highlights": [
      "AWS Lambda",
      "cold-start optimization",
      "ARM64 support",
      "SAM template"
    ]
  },
  {
    "title": "ollama-bench",
    "url": "https://github.com/zeke/ollama-bench",
    "summary": "Benchmark utility that measures tokens/sec, time-to-first-token, and memory across Ollama models.",
    "source": "github",
    "date": "2024-04-29",
    "highlights": [
      "csv export",
      "gpu vs cpu",
      "batch sizes",
      "plots"
    ]
  }
]