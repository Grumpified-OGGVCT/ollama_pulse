[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Ollama\u2019s official CLI and server to pull, run and manage Llama-2, CodeLlama, Mistral, Gemma, etc. locally with one command.",
    "source": "github",
    "date": "2024-04-19",
    "highlights": [
      "self-contained binary",
      "Modelfile DSL",
      "REST/HTTP API",
      "macOS/Linux/Windows"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python library that wraps the Ollama HTTP API for chat, generate, embed, pull and push operations.",
    "source": "github",
    "date": "2024-04-18",
    "highlights": [
      "pip install ollama",
      "sync & asyncio clients",
      "streaming support"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Node and browsers to interact with any Ollama model.",
    "source": "github",
    "date": "2024-04-17",
    "highlights": [
      "npm i ollama",
      "ESM/CommonJS",
      "type definitions included"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://python.langchain.com/docs/integrations/llms/ollama",
    "summary": "LangChain integration letting you swap in Ollama-hosted models for chains, agents, RAG, tool-calling, etc.",
    "source": "github",
    "date": "2024-04-15",
    "highlights": [
      "ChatOllama",
      "OllamaEmbeddings",
      "tool use",
      "streaming tokens"
    ]
  },
  {
    "title": "ollama-webui (ollama-web/Ollama-WebUI)",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich web dashboard for Ollama\u2014chat UI, model manager, multi-user, dark/light themes, fully local.",
    "source": "github",
    "date": "2024-04-19",
    "highlights": [
      "Docker image",
      "import/export chats",
      "OpenAI-compatible endpoint",
      "RAG uploads"
    ]
  },
  {
    "title": "ollama-cli (maccoy/ollama-cli)",
    "url": "https://github.com/maccoy/ollama-cli",
    "summary": "Terminal UI (TUI) for interactive Ollama chats with history, syntax highlighting and model switching.",
    "source": "github",
    "date": "2024-03-28",
    "highlights": [
      "Rust binary",
      "vim keys",
      "chat persistence",
      "themes"
    ]
  },
  {
    "title": "ollama-copilot (sammcj/ollama-copilot)",
    "url": "https://github.com/sammcj/ollama-copilot",
    "summary": "VS Code extension that turns any Ollama model into a GitHub-Copilot-like inline code assistant.",
    "source": "github",
    "date": "2024-04-10",
    "highlights": [
      "FIM completions",
      "configurable model",
      "status-bar toggle"
    ]
  },
  {
    "title": "ollama-ray (ray-project/ray)",
    "url": "https://docs.ray.io/en/latest/ray-air/examples/ollama_example.html",
    "summary": "Ray AIR example showing how to scale Ollama inference across a cluster with Ray Serve.",
    "source": "github",
    "date": "2024-04-05",
    "highlights": [
      "batch inference",
      "autoscaling",
      "GPU scheduling"
    ]
  },
  {
    "title": "ollama-haystack (deepset-ai/haystack-integrations)",
    "url": "https://haystack.deepset.ai/integrations/ollama",
    "summary": "Haystack integration providing OllamaGenerator and OllamaChatGenerator for production RAG pipelines.",
    "source": "github",
    "date": "2024-04-12",
    "highlights": [
      "prompt node replacement",
      "embeddings support",
      "YAML pipeline"
    ]
  },
  {
    "title": "ollama4j (ollama4j/ollama4j)",
    "url": "https://github.com/ollama4j/ollama4j",
    "summary": "Java/JVM client library for Ollama covering chat, generate, embeddings, model management and streaming.",
    "source": "github",
    "date": "2024-04-14",
    "highlights": [
      "Maven Central",
      "Kotlin friendly",
      "reactive streams"
    ]
  },
  {
    "title": "ollama-rb (kevinelliott/ollama-rb)",
    "url": "https://github.com/kevinelliott/ollama-rb",
    "summary": "Ruby gem wrapping the Ollama REST API with ActiveModel-like idioms and streaming support.",
    "source": "github",
    "date": "2024-04-08",
    "highlights": [
      "gem install ollama",
      "Rails ready",
      "async option"
    ]
  },
  {
    "title": "ollama-csharp (awaescher/OllamaSharp)",
    "url": "https://github.com/awaescher/OllamaSharp",
    "summary": ".NET library and fluent C# client for Ollama with async streaming, chat and embeddings endpoints.",
    "source": "github",
    "date": "2024-04-16",
    "highlights": [
      "NuGet package",
      "dependency injection",
      "cancellation tokens"
    ]
  },
  {
    "title": "ollama-rag (ggerganov/llama.cpp/discussions)",
    "url": "https://github.com/ggerganov/llama.cpp/discussions/4267",
    "summary": "Reddit thread discussing best practices for building RAG systems atop Ollama and llama.cpp embeddings.",
    "source": "reddit",
    "date": "2024-04-13",
    "highlights": [
      "chunking strategies",
      "embedding models",
      "performance tips"
    ]
  },
  {
    "title": "ollama-docker (ollama/ollama/tree/main/docker)",
    "url": "https://github.com/ollama/ollama/tree/main/docker",
    "summary": "Official container images (CPU & CUDA) plus docker-compose snippets for running Ollama in production.",
    "source": "github",
    "date": "2024-04-19",
    "highlights": [
      "multi-arch",
      "GPU runtime",
      "volume mounts",
      "healthcheck"
    ]
  },
  {
    "title": "ollama-helm (otwld/ollama-helm)",
    "url": "https://github.com/otwld/ollama-helm",
    "summary": "Community Helm chart for deploying Ollama on Kubernetes with autoscaling, PVC and GPU node-selector.",
    "source": "github",
    "date": "2024-04-11",
    "highlights": [
      "values.yaml",
      "ingress",
      "HPA",
      "persistent storage"
    ]
  },
  {
    "title": "ollama-rust (mdrokz/ollama-rs)",
    "url": "https://github.com/mdrokz/ollama-rs",
    "summary": "Rust crate providing strongly-typed async bindings to the Ollama API including streaming and embeddings.",
    "source": "github",
    "date": "2024-04-09",
    "highlights": [
      "crates.io",
      "tokio",
      "serde",
      "examples"
    ]
  },
  {
    "title": "ollama-dart (ollama-dart/ollama-dart)",
    "url": "https://github.com/ollama-dart/ollama-dart",
    "summary": "Dart/Flutter package for talking to Ollama; useful for desktop/mobile apps that stay completely local.",
    "source": "github",
    "date": "2024-04-07",
    "highlights": [
      "pub.dev",
      "isolates",
      "streaming chat widget"
    ]
  },
  {
    "title": "ollama-go (jmorganca/ollama-go)",
    "url": "https://github.com/jmorganca/ollama-go",
    "summary": "Early community Go client for Ollama with generate and chat endpoints; good for CLI tools.",
    "source": "github",
    "date": "2024-03-30",
    "highlights": [
      "go get",
      "context cancellation",
      "json decoder"
    ]
  },
  {
    "title": "ollama-npm (npm search)",
    "url": "https://www.npmjs.com/search?q=ollama",
    "summary": "Curated list of 30+ community npm packages: adapters for Next.js, Nuxt, Electron, Tauri, Slack bots, etc.",
    "source": "npm",
    "date": "2024-04-20",
    "highlights": [
      "next-ollama",
      "nuxt-ollama",
      "slack-ollama",
      "electron-ollama"
    ]
  },
  {
    "title": "ollama-pypi (pypi search)",
    "url": "https://pypi.org/search/?q=ollama",
    "summary": "PyPI search showing 40+ projects: FastAPI wrappers, Streamlit chats, Django apps, Airflow operators, etc.",
    "source": "pypi",
    "date": "2024-04-20",
    "highlights": [
      "fastapi-ollama",
      "streamlit-ollama",
      "django-ollama",
      "airflow-ollama"
    ]
  }
]