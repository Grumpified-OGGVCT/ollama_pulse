[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: get up and running with Llama 3, Mistral, Gemma and other large language models locally.",
    "source": "github",
    "date": "2024-06-01",
    "highlights": [
      "self-contained binary",
      "Docker image",
      "REST & CLI APIs",
      "model library"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Ollama.",
    "source": "github",
    "date": "2024-05-28",
    "highlights": [
      "npm package",
      "Promise-based",
      "full API coverage"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client for Ollama.",
    "source": "github",
    "date": "2024-05-30",
    "highlights": [
      "PyPI package",
      "sync & async",
      "streaming support"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/partners/ollama",
    "summary": "LangChain integration to use Ollama models as LLMs, embeddings, and tool callers.",
    "source": "github",
    "date": "2024-05-25",
    "highlights": [
      "pip install langchain-ollama",
      "chat & embed",
      "tool calling beta"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich web UI for Ollama (formerly Ollama-WebUI).",
    "source": "github",
    "date": "2024-06-02",
    "highlights": [
      "Docker image",
      "multi-model chat",
      "RAG, PDF, dark mode"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Unofficial Java SDK for Ollama.",
    "source": "github",
    "date": "2024-05-22",
    "highlights": [
      "Maven Central",
      "sync/async",
      "Spring Boot starters"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/gbaptista/ollama-rb",
    "summary": "Ruby gem for interacting with Ollama.",
    "source": "github",
    "date": "2024-05-20",
    "highlights": [
      "RubyGems",
      "streaming",
      "Rails-friendly"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/salty-flower/ollama-cli",
    "summary": "Cross-platform TUI client for Ollama written in Rust.",
    "source": "github",
    "date": "2024-05-18",
    "highlights": [
      "keyboard-driven",
      "conversation history",
      "themes"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama-copilot/ollama-copilot",
    "summary": "GitHub Copilot-like VS Code extension using Ollama.",
    "source": "github",
    "date": "2024-05-15",
    "highlights": [
      "inline completions",
      "local privacy",
      "custom models"
    ]
  },
  {
    "title": "ollama-chat",
    "url": "https://github.com/jmorganca/ollama-chat",
    "summary": "Minimal React chat app example consuming Ollama REST API.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "Vite template",
      "streaming",
      "Dockerfile"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/deepset-ai/haystack-integrations/tree/main/integrations/ollama",
    "summary": "Haystack integration to use Ollama models for QA & RAG pipelines.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "pip install haystack-ai[ollama]",
      "generator & embedder"
    ]
  },
  {
    "title": "ollama-csharp",
    "url": "https://github.com/awaescher/ollama-csharp",
    "summary": ".NET SDK for Ollama with fluent API.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "NuGet",
      "async streaming",
      "dependency injection"
    ]
  },
  {
    "title": "ollama-compose",
    "url": "https://github.com/techno-tim/ollama-compose",
    "summary": "Docker Compose stack with Ollama, WebUI, and GPU support.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "one-command deploy",
      "NVIDIA runtime",
      "volume mounts"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/otwld/ollama-helm",
    "summary": "Helm chart for deploying Ollama on Kubernetes.",
    "source": "github",
    "date": "2024-05-03",
    "highlights": [
      "GPU node selector",
      "autoscaling",
      "ingress"
    ]
  },
  {
    "title": "ollama-gpt-script",
    "url": "https://github.com/gptscript-ai/ollama",
    "summary": "GPTScript tool provider using Ollama for local LLM calls.",
    "source": "github",
    "date": "2024-05-01",
    "highlights": [
      "scriptable agents",
      "file I/O",
      "shell commands"
    ]
  },
  {
    "title": "ollama-discord",
    "url": "https://github.com/mikeggh/ollama-discord",
    "summary": "Discord bot that streams Ollama responses into channels.",
    "source": "github",
    "date": "2024-04-28",
    "highlights": [
      "slash commands",
      "threaded chats",
      "role-based access"
    ]
  },
  {
    "title": "ollama-slack",
    "url": "https://github.com/seratch/ollama-slack",
    "summary": "Slack Bolt app integrating Ollama for internal Q&A.",
    "source": "github",
    "date": "2024-04-26",
    "highlights": [
      "Socket Mode",
      "app mentions",
      "modals"
    ]
  },
  {
    "title": "ollama-rag",
    "url": "https://github.com/PromptEngineer48/ollama-rag",
    "summary": "Retrieval-augmented generation example using Ollama and Chroma.",
    "source": "github",
    "date": "2024-04-24",
    "highlights": [
      "PDF ingestion",
      "embeddings",
      "Gradio UI"
    ]
  },
  {
    "title": "ollama-dagger",
    "url": "https://github.com/dagger/dagger/tree/main/sdk/python/examples/ollama",
    "summary": "Dagger pipeline module that spins up Ollama for CI-based LLM tests.",
    "source": "github",
    "date": "2024-04-22",
    "highlights": [
      "CUE config",
      "caching",
      "GPU optional"
    ]
  },
  {
    "title": "ollama-nix",
    "url": "https://github.com/NixOS/nixpkgs/pull/305123",
    "summary": "Nix flake packaging Ollama and common models.",
    "source": "github",
    "date": "2024-04-20",
    "highlights": [
      "declarative models",
      "systemd service",
      "cachix"
    ]
  }
]