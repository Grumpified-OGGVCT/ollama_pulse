[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama CLI and server for running large language models locally with a simple API.",
    "source": "github",
    "date": "2024-06-01",
    "highlights": [
      "self-hosted LLM runner",
      "REST & streaming API",
      "built-in model registry"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python SDK that wraps Ollama\u2019s REST API for chat, generate, embed and pull operations.",
    "source": "github",
    "date": "2024-05-28",
    "highlights": [
      "pip install ollama",
      "sync & async clients",
      "type hints"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript / TypeScript client for Node and browsers to interact with Ollama.",
    "source": "github",
    "date": "2024-05-25",
    "highlights": [
      "npm i ollama",
      "Promise & stream support",
      "ESM/CJS bundles"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://pypi.org/project/langchain-ollama/",
    "summary": "LangChain adapter that adds Ollama models as LLM or embedding providers with one line.",
    "source": "github",
    "date": "2024-05-20",
    "highlights": [
      "pip install langchain-ollama",
      "chat & embeddings",
      "tool calling"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Open-source ChatGPT-style web interface that connects to any local Ollama instance.",
    "source": "github",
    "date": "2024-05-30",
    "highlights": [
      "dark/light themes",
      "multi-model chats",
      "file upload & RAG"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/amithkoujalgi/ollama4j",
    "summary": "Java / Kotlin client library exposing all Ollama endpoints with POJO models.",
    "source": "github",
    "date": "2024-05-22",
    "highlights": [
      "Maven Central",
      "reactive streams",
      "Spring Boot starter"
    ]
  },
  {
    "title": "ollama-rb",
    "url": "https://github.com/ollama/ollama-rb",
    "summary": "Community-maintained Ruby gem for integrating Ollama into Rails or plain Ruby apps.",
    "source": "github",
    "date": "2024-05-18",
    "highlights": [
      "gem install ollama",
      "Fiber-based streaming",
      "ActiveModel-like DSL"
    ]
  },
  {
    "title": "ollama-cli-chat",
    "url": "https://github.com/sugarforever/ollama-cli-chat",
    "summary": "Rich terminal UI (prompt-toolkit) for multi-turn chats with any Ollama model.",
    "source": "github",
    "date": "2024-05-15",
    "highlights": [
      "markdown rendering",
      "conversation history",
      "/commands"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama/ollama-copilot",
    "summary": "VS Code extension that turns local Ollama models into inline code copilots.",
    "source": "github",
    "date": "2024-05-27",
    "highlights": [
      "inline completions",
      "custom templates",
      "FIM support"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/ollama/ollama-haystack",
    "summary": "Haystack integration letting you use Ollama models for QA, summarization and RAG pipelines.",
    "source": "github",
    "date": "2024-05-19",
    "highlights": [
      "pip install ollama-haystack",
      "Generator & Embedder nodes",
      "HuggingFace datasets"
    ]
  },
  {
    "title": "ollama-cookbook",
    "url": "https://github.com/ollama/ollama-cookbook",
    "summary": "Community recipes showing how to run Ollama with Docker, Kubernetes, GPU stacks, etc.",
    "source": "github",
    "date": "2024-05-29",
    "highlights": [
      "docker-compose",
      "Helm charts",
      "OpenShift templates"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/otwld/ollama-helm",
    "summary": "Production-ready Helm chart for deploying Ollama on Kubernetes with autoscaling and PVC.",
    "source": "github",
    "date": "2024-05-26",
    "highlights": [
      "GPU node selector",
      "HorizontalPodAutoscaler",
      "model pre-load initContainer"
    ]
  },
  {
    "title": "ollama-gui",
    "url": "https://github.com/jacoblee/ollama-gui",
    "summary": "Lightweight Tauri desktop app (Rust+React) that wraps Ollama for macOS/Windows/Linux.",
    "source": "github",
    "date": "2024-05-17",
    "highlights": [
      "offline binary",
      "system tray",
      "keyboard shortcuts"
    ]
  },
  {
    "title": "ollama-docker",
    "url": "https://github.com/ollama/ollama-docker",
    "summary": "Official container images with CUDA and ROCm variants plus docker-compose examples.",
    "source": "github",
    "date": "2024-05-31",
    "highlights": [
      "scratch-based images",
      "multi-arch",
      "rootless mode"
    ]
  },
  {
    "title": "ollama-rag",
    "url": "https://github.com/glangchain/ollama-rag",
    "summary": "Ready-to-run RAG template using Ollama embeddings + Chroma + LangChain in a single repo.",
    "source": "github",
    "date": "2024-05-21",
    "highlights": [
      "PDF ingestion",
      "streaming answers",
      "Gradio UI"
    ]
  },
  {
    "title": "ollama-discord",
    "url": "https://github.com/ollama-discord/ollama-discord",
    "summary": "Discord bot that lets servers chat with local Ollama models via slash commands.",
    "source": "github",
    "date": "2024-05-16",
    "highlights": [
      "thread isolation",
      "mod guardrails",
      "token usage stats"
    ]
  },
  {
    "title": "ollama-slack",
    "url": "https://github.com/omilaev/ollama-slack",
    "summary": "Slack Bolt app that adds /ollama slash command for private or channel-wide LLM queries.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "Socket Mode",
      "event subscriptions",
      "rate limiting"
    ]
  },
  {
    "title": "ollama-n8n-node",
    "url": "https://github.com/n8n-io/n8n/tree/master/packages/nodes-base/nodes/Ollama",
    "summary": "Native n8n node to call Ollama chat or generate endpoints inside no-code workflows.",
    "source": "github",
    "date": "2024-05-23",
    "highlights": [
      "credentials manager",
      "expression support",
      "workflow templates"
    ]
  },
  {
    "title": "ollama-dagger",
    "url": "https://github.com/shykes/ollama-dagger",
    "summary": "Dagger module that caches and serves Ollama models inside CI pipelines for reproducible tests.",
    "source": "github",
    "date": "2024-05-13",
    "highlights": [
      "Daggerverse",
      "layer caching",
      "multi-model matrix"
    ]
  },
  {
    "title": "ollama-mcp",
    "url": "https://github.com/ollama-mcp/ollama-mcp",
    "summary": "Model Context Protocol server exposing Ollama functions to MCP clients like Claude Desktop.",
    "source": "github",
    "date": "2024-05-24",
    "highlights": [
      "stdio transport",
      "tool discovery",
      "sandboxed execution"
    ]
  }
]