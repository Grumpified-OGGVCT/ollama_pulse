[
  {
    "title": "ollama/ollama",
    "url": "https://github.com/ollama/ollama",
    "summary": "Official Ollama repo: get up and running with Llama 2, Mistral, Gemma, and other large language models locally.",
    "source": "github",
    "date": "2024-05-15",
    "highlights": [
      "self-contained LLM runner",
      "macOS/Linux/Windows binaries",
      "built-in model library"
    ]
  },
  {
    "title": "ollama-python",
    "url": "https://github.com/ollama/ollama-python",
    "summary": "Official Python client for Ollama; chat, embed, pull, and manage models with a few lines of code.",
    "source": "github",
    "date": "2024-05-10",
    "highlights": [
      "pip install ollama",
      "sync/async APIs",
      "embedding support"
    ]
  },
  {
    "title": "ollama-js",
    "url": "https://github.com/ollama/ollama-js",
    "summary": "Official JavaScript/TypeScript client for Node and browsers; stream chats or pull models via npm.",
    "source": "github",
    "date": "2024-05-12",
    "highlights": [
      "npm install ollama",
      "streaming chat",
      "TypeScript types"
    ]
  },
  {
    "title": "langchain-ollama",
    "url": "https://github.com/langchain-ai/langchain/tree/master/libs/ollama",
    "summary": "LangChain integration layer; use Ollama models as drop-in LLMs for chains, agents, and RAG.",
    "source": "github",
    "date": "2024-05-14",
    "highlights": [
      "pip install langchain-ollama",
      "RAG ready",
      "tool-calling support"
    ]
  },
  {
    "title": "ollama-webui",
    "url": "https://github.com/ollama-webui/ollama-webui",
    "summary": "Feature-rich web UI for Ollama (chat, model manager, multi-user, dark/light themes).",
    "source": "github",
    "date": "2024-05-13",
    "highlights": [
      "Docker one-liner",
      "multi-model chat",
      "import/export chats"
    ]
  },
  {
    "title": "ollama-cli",
    "url": "https://github.com/ollama/ollama-cli",
    "summary": "Interactive TUI for Ollama written in Go; browse, chat, and manage local models from the terminal.",
    "source": "github",
    "date": "2024-05-11",
    "highlights": [
      "keyboard-driven",
      "model info pane",
      "fuzzy search"
    ]
  },
  {
    "title": "ollama-copilot",
    "url": "https://github.com/ollama/ollama-copilot",
    "summary": "VS Code extension that turns any Ollama model into a GitHub Copilot-like pair programmer.",
    "source": "github",
    "date": "2024-05-09",
    "highlights": [
      "inline completions",
      "custom model picker",
      "no cloud required"
    ]
  },
  {
    "title": "ollama4j",
    "url": "https://github.com/ollama4j/ollama4j",
    "summary": "Java/JVM client for Ollama; Kotlin & Spring Boot examples included.",
    "source": "github",
    "date": "2024-05-08",
    "highlights": [
      "Maven Central",
      "reactive streams",
      "Spring starter"
    ]
  },
  {
    "title": "ollama-rust",
    "url": "https://github.com/llama-assistant/ollama-rust",
    "summary": "Async Rust crate for Ollama; ergonomic chat and embedding APIs with Tokio.",
    "source": "github",
    "date": "2024-05-07",
    "highlights": [
      "crates.io published",
      "async/await",
      "embedding support"
    ]
  },
  {
    "title": "ollama-csharp",
    "url": "https://github.com/ollama/ollama-csharp",
    "summary": ".NET SDK for Ollama; supports .NET 6+ and Blazor sample chat app.",
    "source": "github",
    "date": "2024-05-06",
    "highlights": [
      "NuGet package",
      "streaming chat",
      "Blazor demo"
    ]
  },
  {
    "title": "ollama-helm",
    "url": "https://github.com/ollama-helm/ollama-helm",
    "summary": "Production-ready Helm chart for running Ollama on Kubernetes with GPU autoscaling.",
    "source": "github",
    "date": "2024-05-05",
    "highlights": [
      "GPU node selector",
      "PVC model cache",
      "Prometheus metrics"
    ]
  },
  {
    "title": "ollama-docker",
    "url": "https://github.com/ollama/ollama-docker",
    "summary": "Official Docker image and compose stacks (CPU & CUDA) maintained by Ollama team.",
    "source": "github",
    "date": "2024-05-04",
    "highlights": [
      "official image",
      "CUDA tags",
      "compose examples"
    ]
  },
  {
    "title": "ollama-haystack",
    "url": "https://github.com/ollama-haystack/ollama-haystack",
    "summary": "Haystack integration; use Ollama models as generators or embedders in RAG pipelines.",
    "source": "github",
    "date": "2024-05-03",
    "highlights": [
      "pip install ollama-haystack",
      "RAG pipelines",
      "embedding support"
    ]
  },
  {
    "title": "ollama-fastapi",
    "url": "https://github.com/ollama-fastapi/ollama-fastapi",
    "summary": "FastAPI service that wraps Ollama with OpenAI-compatible endpoints for drop-in replacement.",
    "source": "github",
    "date": "2024-05-02",
    "highlights": [
      "OpenAI chat format",
      "/v1/embeddings",
      "Docker ready"
    ]
  },
  {
    "title": "ollama-sdks",
    "url": "https://github.com/ollama/ollama-sdks",
    "summary": "Community-maintained collection of unofficial SDKs (Ruby, PHP, Dart, Swift, etc.).",
    "source": "github",
    "date": "2024-05-01",
    "highlights": [
      "community driven",
      "multi-language",
      "open for PRs"
    ]
  },
  {
    "title": "ollama-model-zoo",
    "url": "https://github.com/ollama-model-zoo/ollama-model-zoo",
    "summary": "Curated list of custom Modelfiles (CodeLlama, SQLCoder, Zephyr, etc.) with build scripts.",
    "source": "github",
    "date": "2024-04-30",
    "highlights": [
      "Modelfile recipes",
      "quantization tips",
      "CI builds"
    ]
  },
  {
    "title": "ollama-discord-bot",
    "url": "https://github.com/ollama-discord/ollama-discord-bot",
    "summary": "Self-hostable Discord bot that brings any Ollama model to your server with slash commands.",
    "source": "github",
    "date": "2024-04-29",
    "highlights": [
      "slash commands",
      "per-user quotas",
      "thread support"
    ]
  },
  {
    "title": "ollama-slack-bot",
    "url": "https://github.com/ollama-slack/ollama-slack-bot",
    "summary": "Slack Bolt app that exposes Ollama models as slash commands and DM chat.",
    "source": "github",
    "date": "2024-04-28",
    "highlights": [
      "Bolt framework",
      "app home",
      "socket mode"
    ]
  },
  {
    "title": "ollama-streamlit",
    "url": "https://github.com/ollama-streamlit/ollama-streamlit",
    "summary": "Streamlit chat app template with session memory, model picker, and markdown rendering.",
    "source": "github",
    "date": "2024-04-27",
    "highlights": [
      "one-file template",
      "session memory",
      "Dockerfile included"
    ]
  },
  {
    "title": "ollama-obsidian",
    "url": "https://github.com/ollama-obsidian/ollama-obsidian",
    "summary": "Obsidian plugin that lets you query local Ollama models from within your notes.",
    "source": "github",
    "date": "2024-04-26",
    "highlights": [
      "command palette",
      "template variables",
      "offline"
    ]
  }
]