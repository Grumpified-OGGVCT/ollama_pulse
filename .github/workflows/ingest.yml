name: Ollama Pulse Ingestion

on:
  schedule:
    - cron: '0 * * * *'  # Every hour at :00
  workflow_dispatch:
    inputs:
      run_parallel:
        description: 'Run ingestion scripts in parallel'
        required: false
        default: 'true'
        type: boolean

permissions:
  contents: write

concurrency:
  group: ollama-pulse-ingestion
  cancel-in-progress: true

jobs:
  ingest:
    runs-on: ubuntu-latest
    timeout-minutes: 20
    
    strategy:
      fail-fast: false
      matrix:
        script:
          - { name: 'official', file: 'ingest_official.py', critical: true }
          - { name: 'cloud', file: 'ingest_cloud.py', critical: true }
          - { name: 'community', file: 'ingest_community.py', critical: false }
          - { name: 'issues', file: 'ingest_issues.py', critical: false }
          - { name: 'tools', file: 'ingest_tools.py', critical: false }
          - { name: 'bounties', file: 'ingest_bounties.py', critical: false }
          - { name: 'nostr', file: 'ingest_nostr.py', critical: false }
          - { name: 'stackoverflow', file: 'ingest_stackoverflow.py', critical: false }
          - { name: 'model_registry', file: 'ingest_model_registry.py', critical: false }
          - { name: 'releases', file: 'ingest_releases.py', critical: false }
          - { name: 'devblogs', file: 'ingest_devblogs.py', critical: false }
          - { name: 'social_media', file: 'ingest_social_media.py', critical: false }
          - { name: 'manual', file: 'ingest_manual.py', critical: false }

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GH_PAT }}

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: requirements.txt

      - name: Cache ML models
        uses: actions/cache@v3
        with:
          path: ~/.cache/huggingface
          key: ${{ runner.os }}-huggingface-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-huggingface-

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt

      - name: CI Smoke Check
        if: matrix.script.critical == true
        env:
          OLLAMA_API_KEY: ${{ secrets.OLLAMA_API_KEY }}
        run: python scripts/ci_smoke_check.py

      - name: Run ingestion - ${{ matrix.script.name }}
        env:
          OLLAMA_API_KEY: ${{ secrets.OLLAMA_API_KEY }}
          DISCORD_BOT_TOKEN: ${{ secrets.DISCORD_BOT_TOKEN }}
        run: |
          echo "::group::Running ${{ matrix.script.file }}"
          START=$(date +%s)
          
          python scripts/${{ matrix.script.file }} || {
            if [ "${{ matrix.script.critical }}" == "true" ]; then
              echo "::error::Critical ingestion script failed: ${{ matrix.script.name }}"
              exit 1
            else
              echo "::warning::Non-critical ingestion script failed: ${{ matrix.script.name }}"
              exit 0
            fi
          }
          
          END=$(date +%s)
          DURATION=$((END - START))
          echo "::notice::${{ matrix.script.name }} completed in ${DURATION}s"
          echo "::endgroup::"
        continue-on-error: ${{ !matrix.script.critical }}

      - name: Upload ingestion artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ingestion-${{ matrix.script.name }}-${{ github.run_number }}
          path: data/${{ matrix.script.name }}/
          retention-days: 1
          if-no-files-found: warn

  aggregate:
    runs-on: ubuntu-latest
    needs: ingest
    if: always()
    timeout-minutes: 10

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GH_PAT }}

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Cache ML models
        uses: actions/cache@v3
        with:
          path: ~/.cache/huggingface
          key: ${{ runner.os }}-huggingface-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-huggingface-

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt

      - name: Download all ingestion artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: ingestion-*
          path: ./artifacts/
          merge-multiple: false
      
      - name: Merge artifacts into data directory
        run: |
          # Manually merge all artifacts into data/ directory
          for artifact_dir in artifacts/ingestion-*/; do
            if [ -d "$artifact_dir" ]; then
              echo "Merging $artifact_dir"
              cp -r "$artifact_dir"* data/ 2>/dev/null || true
            fi
          done
          
          # Show what we have
          echo "Data directory structure:"
          ls -la data/*/
          
          # Verify today's files exist
          TODAY=$(date -u '+%Y-%m-%d')
          for dir in official community tools bounties nostr stackoverflow models releases devblogs discord manual; do
            if [ -f "data/${dir}/${TODAY}.json" ]; then
              echo "Found: data/${dir}/${TODAY}.json"
            else
              echo "Missing: data/${dir}/${TODAY}.json (may be empty)"
            fi
          done

      - name: Aggregate data
        env:
          OLLAMA_API_KEY: ${{ secrets.OLLAMA_API_KEY }}
        run: |
          python scripts/aggregate.py || {
            echo "::error::Aggregation failed"
            exit 1
          }

      - name: Mine insights
        env:
          OLLAMA_API_KEY: ${{ secrets.OLLAMA_API_KEY }}
        run: |
          python scripts/mine_insights.py || {
            echo "::warning::Insight mining failed - continuing anyway"
            exit 0
          }
        continue-on-error: true

      - name: Commit and push data changes
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add data/
          
          if ! git diff --quiet || ! git diff --staged --quiet; then
            git commit -m "chore(data): hourly ingestion $(date -u '+%Y-%m-%d %H:%M UTC')"
            
            # Enhanced push with retry logic
            for i in {1..3}; do
              git pull --rebase origin main && git push origin main && break || {
                if [ $i -eq 3 ]; then
                  echo "::error::Failed to push after 3 attempts"
                  exit 1
                fi
                echo "::warning::Push failed, retry $i/3..."
                sleep 5
              }
            done
          else
            echo "::notice::No data changes to commit"
          fi

  turbo-cloud-deep:
    runs-on: ubuntu-latest
    needs: aggregate
    if: success()
    timeout-minutes: 10

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GH_PAT }}

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt

      - name: Fetch Ollama Cloud Details
        env:
          OLLAMA_API_KEY: ${{ secrets.OLLAMA_API_KEY }}
        run: |
          python scripts/ingest_cloud.py --filter=turbo --depth=full || {
            echo "::warning::Cloud deep scan failed"
            exit 0
          }
        continue-on-error: true

      - name: GitHub Repo Scan
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');

            try {
              const { data } = await github.rest.search.code({
                q: 'ollama turbo cloud lang:python',
                per_page: 50
              });

              const results = data.items.map(item => ({
                title: `${item.repository.full_name}: ${item.name}`,
                date: new Date().toISOString(),
                summary: `Code mention in ${item.repository.full_name}`,
                url: item.html_url,
                source: 'github_code_search',
                highlights: ['code', 'turbo', 'cloud']
              }));

              const today = new Date().toISOString().split('T')[0];
              const filename = `data/community/${today}.json`;

              let existing = [];
              if (fs.existsSync(filename)) {
                existing = JSON.parse(fs.readFileSync(filename, 'utf8'));
              }

              const combined = [...existing, ...results];
              const unique = Array.from(new Map(combined.map(e => [e.url, e])).values());

              fs.writeFileSync(filename, JSON.stringify(unique, null, 2));
              console.log(`Saved ${results.length} GitHub code search results`);
            } catch (error) {
              core.warning(`GitHub code search failed: ${error.message}`);
            }
        continue-on-error: true

      - name: Commit cloud search data
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add data/
          
          if ! git diff --quiet || ! git diff --staged --quiet; then
            git commit -m "chore(data): turbo cloud deep scan $(date -u '+%Y-%m-%d %H:%M UTC')"
            
            # Enhanced push with retry logic
            for i in {1..3}; do
              git pull --rebase origin main && git push origin main && break || {
                if [ $i -eq 3 ]; then
                  echo "::warning::Cloud scan push failed after 3 attempts - data will be retried next hour"
                  exit 0
                fi
                echo "::warning::Push failed, retry $i/3..."
                sleep 5
              }
            done
          fi
        continue-on-error: true
